[
  {
    "objectID": "ae/ae-01-A.html",
    "href": "ae/ae-01-A.html",
    "title": "AE 01: MTCars",
    "section": "",
    "text": "To learn more about the data, see here: https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars\n\nlibrary(tidyverse)\ndata(\"mtcars\")\n\n\nCreate a code chunk and run the summary command on the variable mpg.\n\n\nsummary(mtcars$mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.40   15.43   19.20   20.09   22.80   33.90 \n\n\n\nFill in the following code (replace the … below) to create a histogram of mpg from question 1.\n\n\nggplot(mtcars, aes(x= mpg)) + geom_histogram()\n\n\n\n\nDid it work? If not, you may need to library the ggplot2 package. do that in the code above!\n\nThat histogram is really boring…. fill in your same x and give it an informative title by filling the ” ” below.\n\n\nggplot(mtcars, aes(x= mpg)) + geom_histogram() + labs(title=\"Histogram of mpg\")\n\n\n\n\n\nLet’s explore if cars with or without a transmission get better mpg. Put am in the space for color and fill and run the code. Continue to put your variable in x = and write out a title.\n\n\nmtcars$am <- as.factor(mtcars$am) #This makes sure am is a factor\n\nggplot(mtcars, aes(x= mpg, color = am , fill = am )) + geom_histogram(binwidth = 1) + labs(title=\"Histogram of mpg by transmission\")\n\n\n\n\n\nLet’s add a density curve. Run the following code below. Play around with alpha and see how the graph changes.\n\n\nggplot(mtcars, aes(x= mpg , color = am , fill = am )) + geom_histogram(aes(y=..density..), position=\"identity\") + labs(title=\"MPG\") +\ngeom_density(alpha=0.6)\n\n\n\n\n\nLet’s rip the histogram apart and seperate by the variable am. Fill in your quantitative variable in x = and put your transmission variable in the … after facet_grid.\n\n\nggplot(mtcars, aes(x= mpg))+\n  geom_histogram(color=\"black\", fill=\"white\")+\n  facet_grid(~am)\n\n\n\n\n\nFor additional practice with the MT data set, please click here"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html",
    "href": "ae/ae-02-viz-data-types-A.html",
    "title": "ae-02 Data visualization",
    "section": "",
    "text": "We will be using functions from the tidyverse package. Please library the package before we begin. If R can’t find the package, you need to install the package using install.packages(“tidyverse)\n\nlibrary(tidyverse)\n\n\nstarwars <- read_csv(\"data/starwars.csv\")\n\nFor this analysis, we will data on the characters in the Stars Wars movie franchise."
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#getting-started",
    "href": "ae/ae-02-viz-data-types-A.html#getting-started",
    "title": "ae-02 Data visualization",
    "section": "Getting started",
    "text": "Getting started\nGet to know the data\nWe can use the glimpse function to get an overview (or “glimpse”) of the data.\n\nglimpse(starwars)\n\nRows: 87\nColumns: 14\n$ name       <chr> \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     <dbl> 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color <chr> \"other\", \"other\", \"other\", \"none\", \"brown/auburn\", \"brown/a…\n$ skin_color <chr> \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  <chr> \"blue\", \"yellow\", \"other\", \"yellow\", \"brown\", \"blue\", \"blue…\n$ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        <chr> \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     <chr> \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  <chr> \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    <chr> \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ vehicles   <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ starships  <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n\n\n\nHow many observations (rows) are in the data set? 87 rows\nHow many variables (columns) are in the data set? 14\nWhat does each row represent? Each column?\nGetting started with ggplot2\n\n\n\nggplot creates the initial base coordinate system, and we will add layers to that base. We first specify the data set we will use with data = starwars.\n\n\nggplot(data = starwars)\n\n\n\n\n\nThe mapping argument is paired with an aesthetic (aes), which tells us how the variables in our data set should be mapped to the visual properties of the graph. In ggplot2 , aesthetic means “something you can see”. Each aesthetic is a mapping between a visual cue and a variable. Let’s set the stage to explore the relationship between the height and mass of each Star Wars character.\n\n\nggplot(data = starwars, \n       mapping = aes(x = height , y = mass)) \n\n\n\n\n\nWhat type of variable is height?\nWhat type of variable is mass?\nWhat plot is most appropriate to explore the relationship between height and mass?\nThe geom_xx function specifies the type of plot we want to use to represent the data. In the code below, we use geom_point which creates a plot where each observation is represented by a point.\n\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass)) +\n  geom_point() \n\nWarning: Removed 28 rows containing missing values (geom_point)."
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-1",
    "href": "ae/ae-02-viz-data-types-A.html#step-1",
    "title": "ae-02 Data visualization",
    "section": "Step 1",
    "text": "Step 1\nModify the following plot to change the color of all points to \"pink\". Note: pink needs to be in quotes because it is not a variable mapped to from our data to our plot. Because it is not a variable being mapped to our plot, it does not go in aesthetic.\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass)) +\n  geom_point(color = \"pink\" ) \n\nWarning: Removed 28 rows containing missing values (geom_point).\n\n\n\n\n\n\nDo you notice anything interesting about these data?"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-1b",
    "href": "ae/ae-02-viz-data-types-A.html#step-1b",
    "title": "ae-02 Data visualization",
    "section": "Step 1B",
    "text": "Step 1B\nFor the sake of this activity, we are going to remove the extreme character.\n\n## Remove outlier \nstarwars <- subset(starwars, mass < 1000)"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-2",
    "href": "ae/ae-02-viz-data-types-A.html#step-2",
    "title": "ae-02 Data visualization",
    "section": "Step 2",
    "text": "Step 2\nAdd labels for the title and x and y axes. Change the _____ to informative labels. This is good practice. Often, you do not want to use the column headers as labels.\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass)) +\n  geom_point(color = \"pink\") + \n  labs(x = \"Height (in inches)\", \n       y = \"Mass\", \n       title = \"Height \\nvs Mass\")"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-3",
    "href": "ae/ae-02-viz-data-types-A.html#step-3",
    "title": "ae-02 Data visualization",
    "section": "Step 3",
    "text": "Step 3\nAn aesthetic is a visual property of one of the objects in your plot. Aesthetic options are:\n\nshape\ncolor\nsize\nfill\n\nModify the plot below, so the color of the points is based on hair_color. Note: When you add aesthetic options, they need to be seperated by a , . What happens if you put hair_color in geom_point?\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass, color = hair_color )) +\n  geom_point()\n\n\n\n\n\nDoes the relationship of characters’ height and mass change based on their hair color?"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-4",
    "href": "ae/ae-02-viz-data-types-A.html#step-4",
    "title": "ae-02 Data visualization",
    "section": "Step 4",
    "text": "Step 4\nModify the plot below, so the color of the points is based on hair_color and the size is based on birth_year.\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass, color = hair_color, size = birth_year)) +\n  geom_point(alpha = 1)\n\nWarning: Removed 23 rows containing missing values (geom_point)."
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-5",
    "href": "ae/ae-02-viz-data-types-A.html#step-5",
    "title": "ae-02 Data visualization",
    "section": "Step 5",
    "text": "Step 5\nUse facet_wrap to display the association between mass and height for different values of eye_color. Note: Eye color needs to be in quotes because it is not directly mapped from our data set in aesthetic.\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass)) +\n  geom_point() +\n  facet_wrap(\"eye_color\")"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-6",
    "href": "ae/ae-02-viz-data-types-A.html#step-6",
    "title": "ae-02 Data visualization",
    "section": "Step 6",
    "text": "Step 6\nUse facet_grid to display the association between mass and height for different combinations of eye_color and hair_color.\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass)) +\n  geom_point() +\n  facet_grid(c(\"eye_color\", \"hair_color\"))"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#step-7",
    "href": "ae/ae-02-viz-data-types-A.html#step-7",
    "title": "ae-02 Data visualization",
    "section": "Step 7",
    "text": "Step 7\nUse facet_grid to display the association between mass and height for different combinations of eye_color and hair_color with the color based on hair_color. Add labels for the title, x and y axes, and the color.\n\nggplot(data = starwars, \n       mapping = aes(x = height, y = mass, color = hair_color))+\n  geom_point() +\n  facet_grid(c(\"eye_color\", \"hair_color\")) +\n    labs(x = \"Height (in inches)\", \n       y = \"Mass\", \n       title = \"Height \\nvs Mass\",\n       color = \"Hair Color\"\n       )"
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#optional-try-it-on-your-own",
    "href": "ae/ae-02-viz-data-types-A.html#optional-try-it-on-your-own",
    "title": "ae-02 Data visualization",
    "section": "Optional (Try it on your own)",
    "text": "Optional (Try it on your own)\nSuppose now that you want to make a boxplot for the heights of all characters. What changes from the code above? Hint: Think about how many variables we are working with | Think about the type of plot we are making.\n\nggplot(starwars, \n       aes(x = height)) + \n       geom_boxplot()\n\n\n\n\nCopy your code from the previous code chunk and add appropriate labels.\n\nggplot(starwars, \n       aes(x = height)) + \n       geom_boxplot() + \n       labs(title = \"Height of all Characters\")\n\n\n\n\nDoes height change based on the sex of the character? Create side-by-side boxplots to answer the question. Hint: Use group and fill in the aesthetic options.\n\nggplot(data = starwars, \n       mapping = aes(x = height , group = sex, fill = sex )) +\n  geom_boxplot(show.legend = T) \n\n\n\n\nYes. It looks like the relationship between height differs based on the character’s sex. Character’s with no sex seem to be much shorter than the others, while also having the most variability."
  },
  {
    "objectID": "ae/ae-02-viz-data-types-A.html#render-commit-and-push",
    "href": "ae/ae-02-viz-data-types-A.html#render-commit-and-push",
    "title": "ae-02 Data visualization",
    "section": "render, commit, and push",
    "text": "render, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called “staging” the changes). Commit the changes you made using an simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "ae/ae-03-penguin-A.html",
    "href": "ae/ae-03-penguin-A.html",
    "title": "AE 03: Visualizing penguins",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-03-data-types-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Sunday, Sep 10 at 11:59pm.\nFor all analyses, we’ll use the tidyverse and palmerpenguins packages.\nThe dataset we will visualize is called penguins. Let’s glimpse() at it."
  },
  {
    "objectID": "ae/ae-03-penguin-A.html#single-variable",
    "href": "ae/ae-03-penguin-A.html#single-variable",
    "title": "AE 03: Visualizing penguins",
    "section": "Single variable",
    "text": "Single variable\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the a single variable is called univariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins.\n\nMake a histogram. Set an appropriate binwidth.\n\n\nggplot(penguins, \n       aes(x = body_mass_g)) +\n       geom_histogram(binwidth = 500)\n\n\n\n\n\nMake a boxplot.\n\n\nggplot(penguins, \n       aes(x = body_mass_g)) + \n  geom_boxplot()\n\n\n\n\n\nBased on these, determine if each of the following statements about the shape of the distribution is true or false.\n\nThe distribution of penguin weights in this sample is left skewed.\nThe distribution of penguin weights in this sample is unimodal (roughly symmetric)."
  },
  {
    "objectID": "ae/ae-03-penguin-A.html#two-variables",
    "href": "ae/ae-03-penguin-A.html#two-variables",
    "title": "AE 03: Visualizing penguins",
    "section": "Two variables",
    "text": "Two variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between two variables is called bivariate analysis.\n\n\nCreate visualizations of the distribution of weights of penguins by species. Note: aesthetic is a visual property of one of the objects in your plot. Aesthetic options are:\n\nshape\ncolor\nsize\nfill\n\n\nMake a single histogram. Set an appropriate binwidth.\n\n\nggplot(penguins, \n       aes(x = body_mass_g, fill = species )) +\n       geom_histogram(binwidth = 250, alpha = .5)\n\n\n\n\n\nUse multiple histograms via faceting, one for each species. Set an appropriate binwidth, add color as you see fit, and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = body_mass_g, fill = species )) +\n       geom_histogram(binwidth = 250, alpha = .5, show.legend = FALSE) + \n      facet_wrap(\"species\", ncol = 1)\n\n\n\n\n\nUse side-by-side box plots. Add color as you see fit and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g,  fill = species)) + \n       geom_boxplot(show.legend = F)\n\n\n\n\n\nUse density plots. Add color as you see fit.\n\n\nggplot(penguins, \n       aes(x = body_mass_g,  fill = species)) +\n       geom_density(alpha = .5)\n\n\n\n\n\nUse violin plots. Add color as you see fit and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g,  fill = species)) + \n  geom_violin(alpha = 0.5 , show.legend = F)\n\n\n\n\n\nMake a jittered scatter plot. Add color as you see fit and turn off legends if not needed.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n  geom_jitter(show.legend = FALSE)\n\n\n\n\n\nUse beeswarm plots. Add color as you see fit and turn off legends if not needed.\n\n\nlibrary(ggbeeswarm)\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n  geom_beeswarm(show.legend = FALSE)\n\n\n\n\n\nUse multiple geoms on a single plot. Be deliberate about the order of plotting. Change the theme and the color scale of the plot. Finally, add informative labels. Hint: scale_color_viridis: https://ggplot2.tidyverse.org/reference/scale_viridis.html theme: https://ggplot2.tidyverse.org/reference/ggtheme.html\n\n\nggplot(data = penguins, \n       mapping = aes(x = body_mass_g, y = species, color = species)) +\n  geom_boxplot(binwidth = 500) +\n  geom_jitter() +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(x= \"Weight\",\n       y = \"Species\", \n       title= \"Weight Disrtribution of Penguins\") +\n  theme(legend.position = \"None\")"
  },
  {
    "objectID": "ae/ae-03-penguin-A.html#multiple-variables",
    "href": "ae/ae-03-penguin-A.html#multiple-variables",
    "title": "AE 03: Visualizing penguins",
    "section": "Multiple variables",
    "text": "Multiple variables\n\n\n\n\n\n\nNote\n\n\n\nAnalyzing the relationship between three or more variables is called multivariate analysis.\n\n\n\nFacet the plot you created in the previous exercise by island. Adjust labels accordingly.\n\n\nggplot(data = penguins, \n       mapping = aes(x = body_mass_g, y = species, color = species)) +\n  geom_boxplot(binwidth = 500) +\n  geom_jitter() +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(x= \"Weight(g)\",\n       y = \"Species\", \n       title= \"Weight Disrtribution of Penguins\") +\n  theme(legend.position = \"None\") +\n  facet_wrap(\"island\")\n\n\n\n\nBefore you continue, let’s turn off all warnings the code chunks generate and resize all figures. We’ll do this by editing the YAML."
  },
  {
    "objectID": "ae/ae-03-penguin-A.html#visualizing-other-variables---your-turn-optional",
    "href": "ae/ae-03-penguin-A.html#visualizing-other-variables---your-turn-optional",
    "title": "AE 03: Visualizing penguins",
    "section": "Visualizing other variables - Your turn! Optional",
    "text": "Visualizing other variables - Your turn! Optional\n\nPick a single categorical variable from the data set and make a bar plot of its distribution.\n\n\nggplot(penguins, \n       aes(x = species)) +\n  geom_bar(show.legend = T) +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(\n    x = \"Species by Sex\",\n    title = \"Penguins by species\"\n  )\n\n\n\n\n\nPick two categorical variables and make a visualization to visualize the relationship between the two variables. Along with your code and output, provide an interpretation of the visualization.\n\n\nggplot(penguins, \n       aes(x = species, fill = sex)) +\n  geom_bar(show.legend = T) +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(\n    x = \"Species by Sex\",\n    title = \"Penguins by species and sex\"\n  )\n\n\n\n\nIt appears that there is little relationship between the type of species and sex of species. Across all three species, the sex for each species seems to be fairly proportional.\n\nMake another plot that uses at least three variables. At least one should be numeric and at least one categorical. In 1-2 sentences, describe what the plot shows about the relationships between the variables you plotted. Don’t forget to label your code chunk.\n\n\nggplot(penguins, \n       aes(x = species, y = body_mass_g, color = species)) +\n  geom_beeswarm(show.legend = FALSE) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5) +\n  facet_wrap(~island) +\n  scale_color_viridis_d(option = \"D\", end = 0.8) +\n  theme_minimal() +\n  labs(\n    x = \"Species\",\n    y = \"Body mass (g)\",\n    title = \"Body mass of penguins in Palmer Archipelago\",\n    subtitle = \"By species and island\"\n  )\n\n\n\n\nIt appears that the body mass of penguins depends on both the species of the penguin and the island the penguin is on. The Gentoo penguins on the Biscoe island are much larger than the others."
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html",
    "href": "ae/ae-04-wrangling-flights-A.html",
    "title": "AE 04: Wrangling flights",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-03-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Friday, Sep 16 at 11:59pm.\nTo demonstrate data wrangling we will use flights, a tibble in the nycflights13 R package. It includes characteristics of all flights departing from New York City (JFK, LGA, EWR) in 2013.\nThe data frame has over 336,000 observations (rows), 336776 observations to be exact, so we will not view the entire data frame. Instead we’ll use the commands below to help us explore the data.\nThe head() function returns “A tibble: 6 x 19” and then the first six rows of the flights data."
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#select",
    "href": "ae/ae-04-wrangling-flights-A.html#select",
    "title": "AE 04: Wrangling flights",
    "section": "select()",
    "text": "select()\n\nDemo: Make a data frame that only contains the variables dep_delay and arr_delay.\n\n\nflights |>\n  select(dep_delay, arr_delay)\n\n# A tibble: 336,776 × 2\n   dep_delay arr_delay\n       <dbl>     <dbl>\n 1         2        11\n 2         4        20\n 3         2        33\n 4        -1       -18\n 5        -6       -25\n 6        -4        12\n 7        -5        19\n 8        -3       -14\n 9        -3        -8\n10        -2         8\n# … with 336,766 more rows\n\n\n\nDemo: Make a data frame that keeps every variable except dep_delay.\n\n\nflights |>\n  select(-dep_delay)\n\n# A tibble: 336,776 × 18\n    year month   day dep_time sched_dep…¹ arr_t…² sched…³ arr_d…⁴ carrier flight\n   <int> <int> <int>    <int>       <int>   <int>   <int>   <dbl> <chr>    <int>\n 1  2013     1     1      517         515     830     819      11 UA        1545\n 2  2013     1     1      533         529     850     830      20 UA        1714\n 3  2013     1     1      542         540     923     850      33 AA        1141\n 4  2013     1     1      544         545    1004    1022     -18 B6         725\n 5  2013     1     1      554         600     812     837     -25 DL         461\n 6  2013     1     1      554         558     740     728      12 UA        1696\n 7  2013     1     1      555         600     913     854      19 B6         507\n 8  2013     1     1      557         600     709     723     -14 EV        5708\n 9  2013     1     1      557         600     838     846      -8 B6          79\n10  2013     1     1      558         600     753     745       8 AA         301\n# … with 336,766 more rows, 8 more variables: tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​arr_time, ³​sched_arr_time, ⁴​arr_delay\n\n\n\nDemo: Make a data frame that includes all variables between year through dep_delay (inclusive). These are all variables that provide information about the departure of each flight.\n\n\nflights |>\n  select(year:dep_delay)\n\n# A tibble: 336,776 × 6\n    year month   day dep_time sched_dep_time dep_delay\n   <int> <int> <int>    <int>          <int>     <dbl>\n 1  2013     1     1      517            515         2\n 2  2013     1     1      533            529         4\n 3  2013     1     1      542            540         2\n 4  2013     1     1      544            545        -1\n 5  2013     1     1      554            600        -6\n 6  2013     1     1      554            558        -4\n 7  2013     1     1      555            600        -5\n 8  2013     1     1      557            600        -3\n 9  2013     1     1      557            600        -3\n10  2013     1     1      558            600        -2\n# … with 336,766 more rows\n\n\n\nDemo: Use the select helper contains() to make a data frame that includes the variables associated with the arrival, i.e., contains the string \"arr\\_\" in the name.\n\n\nflights |>\n  select(contains(\"arr_\"))\n\n# A tibble: 336,776 × 3\n   arr_time sched_arr_time arr_delay\n      <int>          <int>     <dbl>\n 1      830            819        11\n 2      850            830        20\n 3      923            850        33\n 4     1004           1022       -18\n 5      812            837       -25\n 6      740            728        12\n 7      913            854        19\n 8      709            723       -14\n 9      838            846        -8\n10      753            745         8\n# … with 336,766 more rows"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#the-pipe",
    "href": "ae/ae-04-wrangling-flights-A.html#the-pipe",
    "title": "AE 04: Wrangling flights",
    "section": "The pipe",
    "text": "The pipe\nBefore working with more data wrangling functions, let’s formally introduce the pipe. The pipe, |>, is an operator (a tool) for passing information from one process to another. We will use |> mainly in data pipelines to pass the output of the previous line of code as the first input of the next line of code.\nWhen reading code “in English”, say “and then” whenever you see a pipe.\n\n\nYour turn (4 minutes): Run the following chunk and observe its output. Then, come up with a different way of obtaining the same output.\n\n\nflights |>\n  select(dep_delay, arr_delay) |>\n  head()\n\n# A tibble: 6 × 2\n  dep_delay arr_delay\n      <dbl>     <dbl>\n1         2        11\n2         4        20\n3         2        33\n4        -1       -18\n5        -6       -25\n6        -4        12"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#slice",
    "href": "ae/ae-04-wrangling-flights-A.html#slice",
    "title": "AE 04: Wrangling flights",
    "section": "slice()",
    "text": "slice()\n\nDemo: Display the first five rows of the flights data frame.\n\n\nflights |>\n  slice(1:5)\n\n# A tibble: 5 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     1     1      517         515       2     830     819      11 UA     \n2  2013     1     1      533         529       4     850     830      20 UA     \n3  2013     1     1      542         540       2     923     850      33 AA     \n4  2013     1     1      544         545      -1    1004    1022     -18 B6     \n5  2013     1     1      554         600      -6     812     837     -25 DL     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: Display the last two rows of the flights data frame.\n\n\nflights |>\n  slice((n()-1):n())\n\n# A tibble: 2 × 19\n   year month   day dep_time sched_dep…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n  <int> <int> <int>    <int>       <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n1  2013     9    30       NA        1159      NA      NA    1344      NA MQ     \n2  2013     9    30       NA         840      NA      NA    1020      NA MQ     \n# … with 9 more variables: flight <int>, tailnum <chr>, origin <chr>,\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>,\n#   time_hour <dttm>, and abbreviated variable names ¹​sched_dep_time,\n#   ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#arrange",
    "href": "ae/ae-04-wrangling-flights-A.html#arrange",
    "title": "AE 04: Wrangling flights",
    "section": "arrange()",
    "text": "arrange()\n\nDemo: Let’s arrange the data by departure delay, so the flights with the shortest departure delays will be at the top of the data frame.\n\nQuestion: What does it mean for the dep_delay to have a negative value?\n\nflights |>\n  arrange(dep_delay)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013    12     7     2040       2123     -43      40    2352      48 B6     \n 2  2013     2     3     2022       2055     -33    2240    2338     -58 DL     \n 3  2013    11    10     1408       1440     -32    1549    1559     -10 EV     \n 4  2013     1    11     1900       1930     -30    2233    2243     -10 DL     \n 5  2013     1    29     1703       1730     -27    1947    1957     -10 F9     \n 6  2013     8     9      729        755     -26    1002     955       7 MQ     \n 7  2013    10    23     1907       1932     -25    2143    2143       0 EV     \n 8  2013     3    30     2030       2055     -25    2213    2250     -37 MQ     \n 9  2013     3     2     1431       1455     -24    1601    1631     -30 9E     \n10  2013     5     5      934        958     -24    1225    1309     -44 B6     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: Now let’s arrange the data by descending departure delay, so the flights with the longest departure delays will be at the top.\n\n\nflights |>\n  arrange(desc(dep_delay))\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     9      641        900    1301    1242    1530    1272 HA     \n 2  2013     6    15     1432       1935    1137    1607    2120    1127 MQ     \n 3  2013     1    10     1121       1635    1126    1239    1810    1109 MQ     \n 4  2013     9    20     1139       1845    1014    1457    2210    1007 AA     \n 5  2013     7    22      845       1600    1005    1044    1815     989 MQ     \n 6  2013     4    10     1100       1900     960    1342    2211     931 DL     \n 7  2013     3    17     2321        810     911     135    1020     915 DL     \n 8  2013     6    27      959       1900     899    1236    2226     850 DL     \n 9  2013     7    22     2257        759     898     121    1026     895 DL     \n10  2013    12     5      756       1700     896    1058    2020     878 AA     \n# … with 336,766 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\n\nYour turn (5 minutes): Create a data frame that only includes the plane tail number (tailnum), carrier (carrier), and departure delay for the flight with the longest departure delay. What is the plane tail number (tailnum) for this flight?\n\n\nflights |>\n  select(tailnum, carrier, dep_delay) %>%\n  arrange(dep_delay) |>\n  slice(1)\n\n# A tibble: 1 × 3\n  tailnum carrier dep_delay\n  <chr>   <chr>       <dbl>\n1 N592JB  B6            -43"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#filter",
    "href": "ae/ae-04-wrangling-flights-A.html#filter",
    "title": "AE 04: Wrangling flights",
    "section": "filter()",
    "text": "filter()\n\nDemo: Filter the data frame by selecting the rows where the destination airport is RDU.\n\n\nflights |>\n  filter(dest == \"RDU\")\n\n# A tibble: 8,163 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1240       1235       5    1415    1415       0 MQ     \n 9  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n10  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n# … with 8,153 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\n\nDemo: We can also filter using more than one condition. Here we select all rows where the destination airport is RDU and the arrival delay is less than 0.\n\n\nflights |>\n  filter(dest == \"RDU\", arr_delay < 0)\n\n# A tibble: 4,232 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n10  2013     1     1     1800       1800       0    1945    1951      -6 B6     \n# … with 4,222 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\n\nWe can do more complex tasks using logical operators:\n\n\noperator\ndefinition\n\n\n\n<\nis less than?\n\n\n<=\nis less than or equal to?\n\n\n>\nis greater than?\n\n\n>=\nis greater than or equal to?\n\n\n==\nis exactly equal to?\n\n\n!=\nis not equal to?\n\n\nx & y\nis x AND y?\n\n\nx \\| y\nis x OR y?\n\n\nis.na(x)\nis x NA?\n\n\n!is.na(x)\nis x not NA?\n\n\nx %in% y\nis x in y?\n\n\n!(x %in% y)\nis x not in y?\n\n\n!x\nis not x?\n\n\n\nThe final operator only makes sense if x is logical (TRUE / FALSE).\n\n\nYour turn (4 minutes): Describe what the code is doing in words.\n\n\nflights |>\n  filter(\n    dest %in% c(\"RDU\", \"GSO\"),\n    arr_delay < 0 | dep_delay < 0\n    )\n\n# A tibble: 6,203 × 19\n    year month   day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n   <int> <int> <int>    <int>      <int>   <dbl>   <int>   <int>   <dbl> <chr>  \n 1  2013     1     1      800        810     -10     949     955      -6 MQ     \n 2  2013     1     1      832        840      -8    1006    1030     -24 MQ     \n 3  2013     1     1      851        851       0    1032    1036      -4 EV     \n 4  2013     1     1      917        920      -3    1052    1108     -16 B6     \n 5  2013     1     1     1024       1030      -6    1204    1215     -11 MQ     \n 6  2013     1     1     1127       1129      -2    1303    1309      -6 EV     \n 7  2013     1     1     1157       1205      -8    1342    1345      -3 MQ     \n 8  2013     1     1     1317       1325      -8    1454    1505     -11 MQ     \n 9  2013     1     1     1449       1450      -1    1651    1640      11 MQ     \n10  2013     1     1     1505       1510      -5    1654    1655      -1 MQ     \n# … with 6,193 more rows, 9 more variables: flight <int>, tailnum <chr>,\n#   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n#   minute <dbl>, time_hour <dttm>, and abbreviated variable names\n#   ¹​sched_dep_time, ²​dep_delay, ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#count",
    "href": "ae/ae-04-wrangling-flights-A.html#count",
    "title": "AE 04: Wrangling flights",
    "section": "count()",
    "text": "count()\n\nDemo: Create a frequency table of the destination locations for flights from New York.\n\n\nflights |>\n  count(dest)\n\n# A tibble: 105 × 2\n   dest      n\n   <chr> <int>\n 1 ABQ     254\n 2 ACK     265\n 3 ALB     439\n 4 ANC       8\n 5 ATL   17215\n 6 AUS    2439\n 7 AVL     275\n 8 BDL     443\n 9 BGR     375\n10 BHM     297\n# … with 95 more rows\n\n\n\nDemo: In which month was there the fewest number of flights? How many flights were there in that month?\n\n\nflights |>\n  count(month) |>\n  filter(n == min(n))\n\n# A tibble: 1 × 2\n  month     n\n  <int> <int>\n1     2 24951\n\n\n\n\nYour turn (5 minutes): On which date (month + day) was there the largest number of flights? How many flights were there on that day?\n\n\nflights |>\n  count(month, day) |>\n  filter(n == max(n))\n\n# A tibble: 1 × 3\n  month   day     n\n  <int> <int> <int>\n1    11    27  1014"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#mutate",
    "href": "ae/ae-04-wrangling-flights-A.html#mutate",
    "title": "AE 04: Wrangling flights",
    "section": "mutate()",
    "text": "mutate()\nUse mutate() to create a new variable.\n\nDemo: In the code chunk below, air_time (minutes in the air) is converted to hours, and then new variable mph is created, corresponding to the miles per hour of the flight.\n\n\nflights |>\n  mutate(\n    hours = air_time / 60,\n    mph = distance / hours\n    ) |>\n  select(air_time, distance, hours, mph)\n\n# A tibble: 336,776 × 4\n   air_time distance hours   mph\n      <dbl>    <dbl> <dbl> <dbl>\n 1      227     1400 3.78   370.\n 2      227     1416 3.78   374.\n 3      160     1089 2.67   408.\n 4      183     1576 3.05   517.\n 5      116      762 1.93   394.\n 6      150      719 2.5    288.\n 7      158     1065 2.63   404.\n 8       53      229 0.883  259.\n 9      140      944 2.33   405.\n10      138      733 2.3    319.\n# … with 336,766 more rows\n\n\n\n\nYour turn (4 minutes): Create a new variable to calculate the percentage of flights in each month. What percentage of flights take place in July?\n\n\nflights |>\n  count(month) |>\n  mutate(perc = n / sum(n) * 100) \n\n# A tibble: 12 × 3\n   month     n  perc\n   <int> <int> <dbl>\n 1     1 27004  8.02\n 2     2 24951  7.41\n 3     3 28834  8.56\n 4     4 28330  8.41\n 5     5 28796  8.55\n 6     6 28243  8.39\n 7     7 29425  8.74\n 8     8 29327  8.71\n 9     9 27574  8.19\n10    10 28889  8.58\n11    11 27268  8.10\n12    12 28135  8.35"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#summarize",
    "href": "ae/ae-04-wrangling-flights-A.html#summarize",
    "title": "AE 04: Wrangling flights",
    "section": "summarize()",
    "text": "summarize()\nsummarize() collapses the rows into summary statistics and removes columns irrelevant to the calculation.\nBe sure to name your columns!\n\nflights |>\n  summarize(mean_dep_delay = mean(dep_delay))\n\n# A tibble: 1 × 1\n  mean_dep_delay\n           <dbl>\n1             NA\n\n\nQuestion: Why did this code return NA?\nLet’s fix it!\n\nflights |>\n  summarize(mean_dep_delay = mean(dep_delay, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_dep_delay\n           <dbl>\n1           12.6"
  },
  {
    "objectID": "ae/ae-04-wrangling-flights-A.html#group_by",
    "href": "ae/ae-04-wrangling-flights-A.html#group_by",
    "title": "AE 04: Wrangling flights",
    "section": "group_by()",
    "text": "group_by()\ngroup_by() is used for grouped operations. It’s very powerful when paired with summarise() to calculate summary statistics by group.\nHere we find the mean and standard deviation of departure delay for each month.\n\nflights |>\n  group_by(month) |>\n  summarize(\n    mean_dep_delay = mean(dep_delay, na.rm = TRUE), \n    sd_dep_delay = sd(dep_delay, na.rm = TRUE)\n    )\n\n# A tibble: 12 × 3\n   month mean_dep_delay sd_dep_delay\n   <int>          <dbl>        <dbl>\n 1     1          10.0          36.4\n 2     2          10.8          36.3\n 3     3          13.2          40.1\n 4     4          13.9          43.0\n 5     5          13.0          39.4\n 6     6          20.8          51.5\n 7     7          21.7          51.6\n 8     8          12.6          37.7\n 9     9           6.72         35.6\n10    10           6.24         29.7\n11    11           5.44         27.6\n12    12          16.6          41.9\n\n\n\n\nYour turn (4 minutes): What is the median departure delay for each airports around NYC (origin)?\n\n\nflights |>\n  group_by(origin) |>\n  summarize(\n    med_dep_delay = median(dep_delay, na.rm = TRUE)\n    )\n\n# A tibble: 3 × 2\n  origin med_dep_delay\n  <chr>          <dbl>\n1 EWR               -1\n2 JFK               -1\n3 LGA               -3"
  },
  {
    "objectID": "ae/ae-05-joining-fisheries-A.html",
    "href": "ae/ae-05-joining-fisheries-A.html",
    "title": "AE 05: Joining fisheries",
    "section": "",
    "text": "library(tidyverse)\nlibrary(scales)\n\nfisheries <- read_csv(\"data/fisheries.csv\")\ncontinents <- read_csv(\"data/continents.csv\")"
  },
  {
    "objectID": "ae/ae-05-joining-fisheries-A.html#working-with-multiple-data-frames",
    "href": "ae/ae-05-joining-fisheries-A.html#working-with-multiple-data-frames",
    "title": "AE 05: Joining fisheries",
    "section": "Working with multiple data frames",
    "text": "Working with multiple data frames\nOften instead of being provided the data you need for your analysis in a single data frame, you will need to bring information from multiple datasets together into a data frame yourself. These datasets will be linked to each other via a column (usually an identifier, something that links the two datasets together) that you can use to join them together.\nThere are many possible types of joins. All have the format something_join(x, y).\n\nx <- tibble(\n  value = c(1, 2, 3),\n  xcol = c(\"x1\", \"x2\", \"x3\")\n  )\n\ny <- tibble(\n  value = c(1, 2, 4),\n  ycol = c(\"y1\", \"y2\", \"y4\")\n  )\n\nx\n\n# A tibble: 3 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n3     3 x3   \n\ny\n\n# A tibble: 3 × 2\n  value ycol \n  <dbl> <chr>\n1     1 y1   \n2     2 y2   \n3     4 y4   \n\n\nWe will demonstrate each of the joins on these small, toy datasets.\n\ninner_join(): join all rows from x where there are matching values in y\n\n\ninner_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n\n\n\nleft_join(): include all rows from x\n\n\nleft_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n\n\n\nright_join(): include all rows from y\n\n\nright_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 3 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     4 <NA>  y4   \n\n\n\nfull_join(): include all rows in x or y (use this one sparingly!!)\n\nfull_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 4 × 3\n  value xcol  ycol \n  <dbl> <chr> <chr>\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    <NA> \n4     4 <NA>  y4   \n\n\n\nsemi_join(): return all rows from x with match in y\n\n\nsemi_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 2 × 2\n  value xcol \n  <dbl> <chr>\n1     1 x1   \n2     2 x2   \n\n\n\nanti_join(): return all rows from x without a match in y\n\n\nanti_join(x, y)\n\nJoining, by = \"value\"\n\n\n# A tibble: 1 × 2\n  value xcol \n  <dbl> <chr>\n1     3 x3   \n\n\nQuestion: How do the join functions above know to join x and y by value? Hint: Examine the column names to find out.\n\nnames(x)\n\n[1] \"value\" \"xcol\" \n\nnames(y)\n\n[1] \"value\" \"ycol\""
  },
  {
    "objectID": "ae/ae-05-joining-fisheries-A.html#global-aquaculture-production",
    "href": "ae/ae-05-joining-fisheries-A.html#global-aquaculture-production",
    "title": "AE 05: Joining fisheries",
    "section": "Global aquaculture production",
    "text": "Global aquaculture production\nThe Fisheries and Aquaculture Department of the Food and Agriculture Organization of the United Nations collects data on fisheries production of countries.\nOur goal is to create a visualization of the mean share of aquaculture by continent.\nLet’s start by looking at the fisheries data frame.\n\nglimpse(fisheries)\n\nRows: 82\nColumns: 4\n$ country     <chr> \"Angola\", \"Argentina\", \"Australia\", \"Bangladesh\", \"Brazil\"…\n$ capture     <dbl> 486490, 755226, 174629, 1674770, 705000, 629950, 233190, 8…\n$ aquaculture <dbl> 655, 3673, 96847, 2203554, 581230, 172500, 2315, 200765, 9…\n$ total       <dbl> 487145, 758899, 271476, 3878324, 1286230, 802450, 235505, …\n\n\nWe have the countries, but our goal is to make a visualization by continent. Let’s take a look at the continents data frame.\n\nglimpse(continents)\n\nRows: 245\nColumns: 2\n$ country   <chr> \"Afghanistan\", \"Åland Islands\", \"Albania\", \"Algeria\", \"Ameri…\n$ continent <chr> \"Asia\", \"Europe\", \"Europe\", \"Africa\", \"Oceania\", \"Europe\", \"…\n\n\n\n\nYour turn (2 minutes):\n\nWhich variable(s) will we use to join the fisheries and continents data frames?\nWe want to keep all rows and columns from fisheries and add a column for corresponding continents. Which join function should we use?\n\n\n\nDemo: Join the two data frames and name assign the joined data frame back to fisheries.\n\n\nfisheries <- fisheries |>\n  left_join(continents)\n\nJoining, by = \"country\"\n\n\n\n\nDemo: Take a look at the updated fisheries data frame. There are some countries that were not in continents. First, identify which countries these are (they will have NA values for continent). Then, manually update the continent information for these countries using the case_when function. Finally, check that these updates have been made as intended and no countries are left without continent information.\n\n\nfisheries |>\n  filter(is.na(continent))\n\n# A tibble: 3 × 5\n  country                          capture aquaculture   total continent\n  <chr>                              <dbl>       <dbl>   <dbl> <chr>    \n1 Democratic Republic of the Congo  237372        3161  240533 <NA>     \n2 Hong Kong                         142775        4258  147033 <NA>     \n3 Myanmar                          2072390     1017644 3090034 <NA>     \n\nfisheries <- fisheries %>%\n  mutate(\n    continent = case_when(\n      country == \"Democratic Republic of the Congo\" ~ \"Africa\",\n      country == \"Hong Kong\" ~ \"Asia\",\n      country == \"Myanmar\" ~ \"Asia\",\n      TRUE ~ continent\n    )\n  )\n\nfisheries |>\n  filter(is.na(continent))\n\n# A tibble: 0 × 5\n# … with 5 variables: country <chr>, capture <dbl>, aquaculture <dbl>,\n#   total <dbl>, continent <chr>\n\n\n\n\nDemo: Add a new column to the fisheries data frame called aq_prop. We will calculate it as aquaculture / total. Save the resulting frame as fisheries.\n\n\nfisheries <- fisheries |>\n  mutate(aq_prop = aquaculture / total)\n\n\n\nYour turn (5 minutes): Now expand your calculations to also calculate the mean, minimum and maximum aquaculture proportion for continents in the fisheries data. Note that the functions for calculating minimum and maximum in R are min() and max() respectively.\n\n\nfisheries |>                              # start with fisheries data frame\n  group_by(continent) |>                  # group by continent\n  summarize(                              # calculate summary stats  \n    min_aq_prop  = min(aq_prop),\n    mean_aq_prop = mean(aq_prop),\n    max_aq_prop  = max(aq_prop)\n    )    \n\n# A tibble: 5 × 4\n  continent min_aq_prop mean_aq_prop max_aq_prop\n  <chr>           <dbl>        <dbl>       <dbl>\n1 Africa        0             0.0943       0.803\n2 Americas      0             0.192        0.529\n3 Asia          0             0.367        0.782\n4 Europe        0.00682       0.165        0.618\n5 Oceania       0.0197        0.150        0.357\n\n\n\n\nDemo: Create a new data frame called fisheries_summary that calculates minimum, mean, and maximum aquaculture proportion for each continent in the fisheries data.\n\n\nfisheries_summary <- fisheries |>         # start with fisheries data frame\n  group_by(continent) |>                  # group by continent\n  summarize(                              # calculate summary stats  \n    min_aq_prop  = min(aq_prop),\n    mean_aq_prop = mean(aq_prop),\n    max_aq_prop  = max(aq_prop)\n    )\n\n\n\nDemo: Then, determine which continent has the largest value of max_ap. Take the fisheries_summary data frame and order the results in descending order of mean aquaculture proportion.\n\n\nfisheries_summary |>            # start with fisheries_summary data frame\n  arrange(desc(mean_aq_prop))   # order in descending order of mean_aq_prop\n\n# A tibble: 5 × 4\n  continent min_aq_prop mean_aq_prop max_aq_prop\n  <chr>           <dbl>        <dbl>       <dbl>\n1 Asia          0             0.367        0.782\n2 Americas      0             0.192        0.529\n3 Europe        0.00682       0.165        0.618\n4 Oceania       0.0197        0.150        0.357\n5 Africa        0             0.0943       0.803\n\n\n\n\nDemo: Recreate the following plot using the data frame you have developed so far.\n\n\n\n\n\n\nggplot(fisheries_summary, \n       aes(y = fct_reorder(continent, mean_aq_prop), x = mean_aq_prop)) +\n  geom_col() +\n  scale_x_continuous(labels = label_percent(accuracy = 1)) +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Average share of aquaculture by continent\",\n    subtitle = \"out of total fisheries harvest, 2016\",\n    caption = \"Source: bit.ly/2VrawTt\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\nYour turn (optional): Change the theme of the plot and make any other changes you would like to improve it.\n\n\n# add your code here"
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors-A.html",
    "href": "ae/ae-05-pivoting-statsci-majors-A.html",
    "title": "AE 06: Pivoting StatSci Majors",
    "section": "",
    "text": "Our ultimate goal in this application exercise is to make the following data visualization.\n\n\n\n\n\n\nYour turn (3 minutes): Take a close look at the plot and describe what it shows in 2-3 sentences.\n\nThis plot describes the relationship between a graduation year and the number of majors graduating. This relationsip is broken down by degree type. It appears that the number of majors graduating’s relationship with graduation year changes by degree type, with BS and BS2 majors having more graduating in later years than the others."
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors-A.html#data",
    "href": "ae/ae-05-pivoting-statsci-majors-A.html#data",
    "title": "AE 06: Pivoting StatSci Majors",
    "section": "Data",
    "text": "Data\nThe data come from the Office of the University Registrar. They make the data available as a table that you can download as a PDF, but I’ve put the data exported in a CSV file for you. Let’s load that in.\n\nlibrary(tidyverse)\n\nstatsci <- read_csv(\"data/statsci.csv\")\n\nAnd let’s take a look at the data.\n\nstatsci\n\n# A tibble: 4 × 14\n   ...1  ...2 degree     `2011` `2012` `2013` `2014` `2015` `2016` `2017` `2018`\n  <dbl> <dbl> <chr>       <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1     1     1 Statistic…     NA      1     NA     NA      4      4      1     NA\n2     2     2 Statistic…      2      2      4      1      3      6      3      4\n3     3     3 Statistic…      2      6      1     NA      5      6      6      8\n4     4     4 Statistic…      5      9      4     13     10     17     24     21\n# … with 3 more variables: `2019` <dbl>, `2020` <dbl>, `2021` <dbl>\n\n\nThe dataset has 4 rows and 14 columns. The first column (variable) is the degree, and there are 4 possible degrees: BS (Bachelor of Science), BS2 (Bachelor of Science, 2nd major), AB (Bachelor of Arts), AB2 (Bachelor of Arts, 2nd major). The remaining columns show the number of students graduating with that major in a given academic year from 2011 to 2021.\n\n\nYour turn (4 minutes): Take a look at the plot we aim to make and sketch the data frame we need to make the plot. Determine what each row and each column of the data frame should be. Hint: We need data to be in columns to map to aesthetic elements of the plot.\n\nColumns: year, n , degree_type\nRows: Combination of year and degree type"
  },
  {
    "objectID": "ae/ae-05-pivoting-statsci-majors-A.html#pivoting",
    "href": "ae/ae-05-pivoting-statsci-majors-A.html#pivoting",
    "title": "AE 06: Pivoting StatSci Majors",
    "section": "Pivoting",
    "text": "Pivoting\n\n\nDemo: Pivot the statsci data frame longer such that each row represents a degree type / year combination and year and number of graduates for that year are columns in the data frame.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    values_to = \"n\"\n  )\n\n# A tibble: 52 × 3\n   degree                    year      n\n   <chr>                     <chr> <dbl>\n 1 Statistical Science (AB2) ...1      1\n 2 Statistical Science (AB2) ...2      1\n 3 Statistical Science (AB2) 2011     NA\n 4 Statistical Science (AB2) 2012      1\n 5 Statistical Science (AB2) 2013     NA\n 6 Statistical Science (AB2) 2014     NA\n 7 Statistical Science (AB2) 2015      4\n 8 Statistical Science (AB2) 2016      4\n 9 Statistical Science (AB2) 2017      1\n10 Statistical Science (AB2) 2018     NA\n# … with 42 more rows\n\n\n\n\nQuestion: What is the type of the year variable? Why? What should it be?\n\nIt’s a character (chr) variable since the information came from the columns of the original data frame and R cannot know that these character strings represent years. The variable type should be numeric.\n\nDemo: Start over with pivoting, and this time also make sure year is a numerical variable in the resulting data frame.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  )\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\n# A tibble: 52 × 3\n   degree                     year     n\n   <chr>                     <dbl> <dbl>\n 1 Statistical Science (AB2)    NA     1\n 2 Statistical Science (AB2)    NA     1\n 3 Statistical Science (AB2)  2011    NA\n 4 Statistical Science (AB2)  2012     1\n 5 Statistical Science (AB2)  2013    NA\n 6 Statistical Science (AB2)  2014    NA\n 7 Statistical Science (AB2)  2015     4\n 8 Statistical Science (AB2)  2016     4\n 9 Statistical Science (AB2)  2017     1\n10 Statistical Science (AB2)  2018    NA\n# … with 42 more rows\n\n\n\n\nQuestion: What does an NA mean in this context? Hint: The data come from the university registrar, and they have records on every single graduates, there shouldn’t be anything “unknown” to them about who graduated when.\n\nNAs should actually be 0s.\n\n\nDemo: Add on to your pipeline that you started with pivoting and convert NAs in n to 0s.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n))\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\n# A tibble: 52 × 3\n   degree                     year     n\n   <chr>                     <dbl> <dbl>\n 1 Statistical Science (AB2)    NA     1\n 2 Statistical Science (AB2)    NA     1\n 3 Statistical Science (AB2)  2011     0\n 4 Statistical Science (AB2)  2012     1\n 5 Statistical Science (AB2)  2013     0\n 6 Statistical Science (AB2)  2014     0\n 7 Statistical Science (AB2)  2015     4\n 8 Statistical Science (AB2)  2016     4\n 9 Statistical Science (AB2)  2017     1\n10 Statistical Science (AB2)  2018     0\n# … with 42 more rows\n\n\n\n\nDemo: In our plot the degree types are BS, BS2, AB, and AB2. This information is in our dataset, in the degree column, but this column also has additional characters we don’t need. Create a new column called degree_type with levels BS, BS2, AB, and AB2 (in this order) based on degree. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    )\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\n# A tibble: 52 × 4\n   major               degree_type  year     n\n   <chr>               <fct>       <dbl> <dbl>\n 1 Statistical Science AB2            NA     1\n 2 Statistical Science AB2            NA     1\n 3 Statistical Science AB2          2011     0\n 4 Statistical Science AB2          2012     1\n 5 Statistical Science AB2          2013     0\n 6 Statistical Science AB2          2014     0\n 7 Statistical Science AB2          2015     4\n 8 Statistical Science AB2          2016     4\n 9 Statistical Science AB2          2017     1\n10 Statistical Science AB2          2018     0\n# … with 42 more rows\n\n\n\n\nYour turn (5 minutes): Now we start making our plot, but let’s not get too fancy right away. Create the following plot, which will serve as the “first draft” on the way to our Goal. Do this by adding on to your pipeline from earlier.\n\n\n\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line()\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\nWarning: Removed 8 rows containing missing values (geom_point).\n\n\nWarning: Removed 8 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\nYour turn (4 minutes): What aspects of the plot need to be updated to go from the draft you created above to the Goal plot at the beginning of this application exercise.\n\nx-axis scale: need to go from 2011 to 2021 in increments of 2 years\nline colors\naxis labels: title, subtitle, x, y, caption\ntheme\nlegend position and border\n\n\nDemo: Update x-axis scale such that the years displayed go from 2011 to 2021 in increments of 2 years. Do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2))\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\nWarning: Removed 8 rows containing missing values (geom_point).\n\n\nWarning: Removed 8 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\nDemo: Update line colors using the following level / color assignments. Once again, do this by adding on to your pipeline from earlier.\n\n“BS” = “cadetblue4”\n“BS2” = “cadetblue3”\n“AB” = “lightgoldenrod4”\n“AB2” = “lightgoldenrod3”\n\n\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\", \n               \"BS2\" = \"cadetblue3\", \n               \"AB\" = \"lightgoldenrod4\", \n               \"AB2\" = \"lightgoldenrod3\"))\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\nWarning: Removed 8 rows containing missing values (geom_point).\n\n\nWarning: Removed 8 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\nYour turn (4 minutes): Update the plot labels (title, subtitle, x, y, and caption) and use theme_minimal(). Once again, do this by adding on to your pipeline from earlier.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2021\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal()\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\nWarning: Removed 8 rows containing missing values (geom_point).\n\n\nWarning: Removed 8 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\nDemo: Finally, adding to your pipeline you’ve developed so far, move the legend into the plot, make its background white, and its border gray. Set fig-width: 7 and fig-height: 5 for your plot in the chunk options.\n\n\nstatsci |>\n  pivot_longer(\n    cols = -degree,\n    names_to = \"year\",\n    names_transform = as.numeric,\n    values_to = \"n\"\n  ) |>\n  mutate(n = if_else(is.na(n), 0, n)) |>\n  separate(degree, sep = \" \\\\(\", into = c(\"major\", \"degree_type\")) |>\n  mutate(\n    degree_type = str_remove(degree_type, \"\\\\)\"),\n    degree_type = fct_relevel(degree_type, \"BS\", \"BS2\", \"AB\", \"AB2\")\n    ) |>\n  ggplot(aes(x = year, y = n, color = degree_type)) +\n  geom_point() +\n  geom_line() +\n  scale_x_continuous(breaks = seq(2011, 2021, 2)) +\n  scale_color_manual(\n    values = c(\"BS\" = \"cadetblue4\",\n               \"BS2\" = \"cadetblue3\",\n               \"AB\" = \"lightgoldenrod4\",\n               \"AB2\" = \"lightgoldenrod3\")) +\n  labs(\n    x = \"Graduation year\",\n    y = \"Number of majors graduating\",\n    color = \"Degree type\",\n    title = \"Statistical Science majors over the years\",\n    subtitle = \"Academic years 2011 - 2021\",\n    caption = \"Source: Office of the University Registrar\\nhttps://registrar.duke.edu/registration/enrollment-statistics\"\n  ) +\n  theme_minimal() +\n  theme(\n    legend.position = c(0.2, 0.8),\n    legend.background = element_rect(fill = \"white\", color = \"gray\")\n    )\n\nWarning in f(names[[col]]): NAs introduced by coercion\n\n\nWarning: Removed 8 rows containing missing values (geom_point).\n\n\nWarning: Removed 8 row(s) containing missing values (geom_path)."
  },
  {
    "objectID": "ae/ae-06-hotels-types-classes-A.html",
    "href": "ae/ae-06-hotels-types-classes-A.html",
    "title": "AE 07: Hotel bookings",
    "section": "",
    "text": "Important\n\n\n\nGo to the course GitHub organization and locate the repo titled ae-07-YOUR_GITHUB_USERNAME to get started.\nThis AE is due Saturday, Sep 25 at 11:59pm."
  },
  {
    "objectID": "ae/ae-06-hotels-types-classes-A.html#packages",
    "href": "ae/ae-06-hotels-types-classes-A.html#packages",
    "title": "AE 07: Hotel bookings",
    "section": "Packages",
    "text": "Packages\nWe will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nskimr: For summarizing the entire data frame at once.\n\nscales: For better axis labels.\n\nTo be productive in R, you need to be familiar with the major types and the operations on these types. Each R object has a un underlying “type”, which determines the set of possible values for that object. You can find the type of an object using the typeof function.\nlogical: a logical value.\ninteger: an integer (positive or negative). Many R programmers do not use this mode since every integer value can be represented as a double.\ndouble: a real number stored in “double-precision floatint point format.”\ncomplex: a complex number\ncharacter: a sequence of characters, called a “string” in other programming languages\nlist: a list of named values\nNULL: a special type with only one possible value, known as NULL\nMore information can be found here: https://statsandr.com/blog/data-types-in-r/"
  },
  {
    "objectID": "ae/ae-06-hotels-types-classes-A.html#why-this-matters",
    "href": "ae/ae-06-hotels-types-classes-A.html#why-this-matters",
    "title": "AE 07: Hotel bookings",
    "section": "Why This Matters",
    "text": "Why This Matters\nWe are going to revisit the mtcars data set. Run ?mtcars to see the definition of each variable.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(skimr)\n\nmtcars07 <- read_csv(\"data/mtcars07.csv\" , col_types = NULL)\n\n\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n3-min Run the code below to create side-by-side boxplots of the number of mpg cars get versus the type of Engine they have.\n\nmtcars |>\nggplot(\n  aes(x = vs, y = mpg)\n) +\n  geom_boxplot()\n\nWarning: Continuous x aesthetic -- did you forget aes(group=...)?\n\n\n\n\n\nWhy doesn’t this work?\nAnswer Here\nEdit the code below to fix the issue.\n\nmtcars |>\n  mutate(vs = as.factor(vs)) |>\nggplot(\n  aes(x = vs, y = mpg)\n) +\n  geom_boxplot()\n\n\n\n\nNow, calculate the mean number of carburetors for the 32 cars in the data set.\n\n\n\nWhy doesn’t this work? Fix the code so you can answer the question."
  },
  {
    "objectID": "ae/ae-06-hotels-types-classes-A.html#type-coercion",
    "href": "ae/ae-06-hotels-types-classes-A.html#type-coercion",
    "title": "AE 07: Hotel bookings",
    "section": "Type coercion",
    "text": "Type coercion\n\n\nDemo: Determine the type of the following vector. And then, change the type to numeric.\n\nx <- c(\"1\", \"2\", \"3\")\ntypeof(x)\n\n[1] \"character\"\n\nas.numeric(x)\n\n[1] 1 2 3\n\n\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\ny <- c(\"a\", \"b\", \"c\")\ntypeof(y)\n\n[1] \"character\"\n\nas.numeric(y)\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA\n\n\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\nz <- c(\"1\", \"2\", \"three\")\ntypeof(z)\n\n[1] \"character\"\n\nas.numeric(z)\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA\n\n\n\n\nDemo: Suppose you conducted a survey where you asked people how many cars their household owns collectively. And the answers are as follows:\n\nsurvey_results <- tibble(cars = c(1, 2, \"three\"))\nsurvey_results\n\n# A tibble: 3 × 1\n  cars \n  <chr>\n1 1    \n2 2    \n3 three\n\n\nThis is annoying because of that third survey taker who just had to go and type out the number instead of providing as a numeric value. So now you need to update the cars variable to be numeric. You do the following\n\nsurvey_results |>\n  mutate(cars = as.numeric(cars))\n\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3    NA\n\n\nAnd now things are even more annoying because you get a warning NAs introduced by coercion that happened while computing cars = as.numeric(cars) and the response from the third survey taker is now an NA (you lost their data). Fix your mutate() call to avoid this warning.\n\nsurvey_results |>\n  mutate(\n    cars = if_else(cars == \"three\", \"3\", cars),\n    cars = as.numeric(cars)\n    )\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3     3\n\n\n\n\nYour turn: First, guess the type of the vector. Then, check if you guessed right. I’ve done the first one for you, you’ll see that it’s helpful to check the type of each element of the vector first.\n\nc(1, 1L, \"C\")\n\n\n\n\n        v1 <- c(1, 1L, \"C\")\n\n        # to help you guess\n        typeof(1)\n\n[1] \"double\"\n\n        typeof(1L)\n\n[1] \"integer\"\n\n        typeof(\"C\")\n\n[1] \"character\"\n\n        # to check after you guess\n        typeof(v1)\n\n[1] \"character\"\n\n\n-   `c(1L / 0, \"A\")`\n\n        v2 <- c(1L / 0, \"A\")\n\n        # to help you guess\n        typeof(1L)\n\n[1] \"integer\"\n\n        typeof(0)\n\n[1] \"double\"\n\n        typeof(1L / 0)\n\n[1] \"double\"\n\n        typeof(\"A\")\n\n[1] \"character\"\n\n        # to check after you guess\n        typeof(v2)\n\n[1] \"character\"\n\n\n\nc(1:3, 5)\n\n\n        v3 <- c(1:3, 5)\n\n        # to help you guess\n        typeof(1:3)\n\n[1] \"integer\"\n\n        typeof(5)\n\n[1] \"double\"\n\n        # to check after you guess\n        typeof(v3)\n\n[1] \"double\"\n\n\n-   `c(3, \"3+\")`\n\n        v4 <- c(3, \"3+\")\n\n        # to help you guess\n        typeof(3)\n\n[1] \"double\"\n\n        typeof(\"3+\")\n\n[1] \"character\"\n\n        # to check after you guess\n        typeof(v4)\n\n[1] \"character\"\n\n\n-   `c(NA, TRUE)`\n\n        v5 <- c(NA, TRUE)\n\n        # to help you guess\n        typeof(NA)\n\n[1] \"logical\"\n\n        typeof(TRUE)\n\n[1] \"logical\"\n\n        # to check after you guess\n        typeof(v5)\n\n[1] \"logical\""
  },
  {
    "objectID": "ae/ae-06-hotels-types-classes-A.html#hotel-bookings",
    "href": "ae/ae-06-hotels-types-classes-A.html#hotel-bookings",
    "title": "AE 07: Hotel bookings",
    "section": "Hotel bookings",
    "text": "Hotel bookings\n\nhotels <- read_csv(\"data/hotels.csv\" , col_types = NULL)\n\nWarning: One or more parsing issues, see `problems()` for details\n\nproblems()\n\nAfter reading in the data set, you should see a Warning message. What does that message say? Explain the output of problems() in your own words.\nTake a look at the the following visualization. How are the months ordered? What would be a better order? Then, reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\n Hints:\n– use fct_relevel to order months\n– use case_when to fix the input error\n– calculate mean adr for each group for plot\n– use theme_minimal\n\nhotels |>\n  mutate(\n  arrival_date_month = fct_relevel(arrival_date_month, \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n              \"July\", \"August\", \"September\", \"October\", \"November\", \"December\")) |>\n  mutate(adr = case_when(\n    is.na(adr) ~ 124,\n    TRUE ~ as.numeric(adr)\n  )) |>\n  group_by(hotel, arrival_date_month) |>\n  summarise(mean_adr = mean(adr)) |>       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n  ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n  ) +\n  scale_y_continuous(labels = label_dollar())\n\n`summarise()` has grouped output by 'hotel'. You can override using the\n`.groups` argument.\n\n\n\n\n\nStretch goal: If you finish the above task before time is up, change the above code so that the y-axis labels are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help."
  },
  {
    "objectID": "ae/ae-07-data-types-classes-A.html",
    "href": "ae/ae-07-data-types-classes-A.html",
    "title": "AE 07: Data types and classes",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nskimr: For summarizing the entire data frame at once.\n\nscales: For better axis labels.\n\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(scales)"
  },
  {
    "objectID": "ae/ae-07-data-types-classes-A.html#type-coercion",
    "href": "ae/ae-07-data-types-classes-A.html#type-coercion",
    "title": "AE 07: Data types and classes",
    "section": "Type coercion",
    "text": "Type coercion\n\n\nDemo: Determine the type of the following vector. And then, change the type to numeric.\n\nx <- c(\"1\", \"2\", \"3\")\ntypeof(x)\n\n[1] \"character\"\n\nas.numeric(x)\n\n[1] 1 2 3\n\n\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\ny <- c(\"a\", \"b\", \"c\")\ntypeof(y)\n\n[1] \"character\"\n\nas.numeric(y)\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA\n\n\n\n\nDemo: Once again, determine the type of the following vector. And then, change the type to numeric. What’s different than the previous exercise?\n\nz <- c(\"1\", \"2\", \"three\")\ntypeof(z)\n\n[1] \"character\"\n\nas.numeric(z)\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA\n\n\n\n\nDemo: Suppose you conducted a survey where you asked people how many cars their household owns collectively. And the answers are as follows:\n\nsurvey_results <- tibble(cars = c(1, 2, \"three\"))\nsurvey_results\n\n# A tibble: 3 × 1\n  cars \n  <chr>\n1 1    \n2 2    \n3 three\n\n\nThis is annoying because of that third survey taker who just had to go and type out the number instead of providing as a numeric value. So now you need to update the cars variable to be numeric. You do the following\n\nsurvey_results |>\n  mutate(cars = as.numeric(cars))\n\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3    NA\n\n\nAnd now things are even more annoying because you get a warning NAs introduced by coercion that happened while computing cars = as.numeric(cars) and the response from the third survey taker is now an NA (you lost their data). Fix your mutate() call to avoid this warning.\n\nsurvey_results |>\n  mutate(\n    cars = if_else(cars == \"three\", \"3\", cars),\n    cars = as.numeric(cars)\n    )\n\n# A tibble: 3 × 1\n   cars\n  <dbl>\n1     1\n2     2\n3     3\n\n\n\n\nYour turn: First, guess the type of the vector. Then, check if you guessed right. I’ve done the first one for you, you’ll see that it’s helpful to check the type of each element of the vector first.\n\n\nc(1, 1L, \"C\")\n\nv1 <- c(1, 1L, \"C\")\n\n# to help you guess\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"C\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v1)\n\n[1] \"character\"\n\n\n\n\nc(1L / 0, \"A\")\n\nv2 <- c(1L / 0, \"A\")\n\n# to help you guess\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(0)\n\n[1] \"double\"\n\ntypeof(1L / 0)\n\n[1] \"double\"\n\ntypeof(\"A\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v2)\n\n[1] \"character\"\n\n\n\n\nc(1:3, 5)\n\nv3 <- c(1:3, 5)\n\n# to help you guess\ntypeof(1:3)\n\n[1] \"integer\"\n\ntypeof(5)\n\n[1] \"double\"\n\n# to check after you guess\ntypeof(v3)\n\n[1] \"double\"\n\n\n\n\nc(3, \"3+\")\n\nv4 <- c(3, \"3+\")\n\n# to help you guess\ntypeof(3)\n\n[1] \"double\"\n\ntypeof(\"3+\")\n\n[1] \"character\"\n\n# to check after you guess\ntypeof(v4)\n\n[1] \"character\"\n\n\n\n\nc(NA, TRUE)\n\nv5 <- c(NA, TRUE)\n\n# to help you guess\ntypeof(NA)\n\n[1] \"logical\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n# to check after you guess\ntypeof(v5)\n\n[1] \"logical\""
  },
  {
    "objectID": "ae/ae-07-data-types-classes-A.html#hotel-bookings",
    "href": "ae/ae-07-data-types-classes-A.html#hotel-bookings",
    "title": "AE 07: Data types and classes",
    "section": "Hotel bookings",
    "text": "Hotel bookings\n\n# From TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\n\nhotels <- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\nQuestion: Take a look at the the following visualization. How are the months ordered? What would be a better order?\n\n\n\n\nDemo: Reorder the months on the x-axis (levels of arrival_date_month) in a way that makes more sense. You will want to use a function from the forcats package, see https://forcats.tidyverse.org/reference/index.html for inspiration and help.\n\nhotels |>\n  group_by(hotel, arrival_date_month) |>   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr), .groups = \"drop\") |>       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n  ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n  )\n\n\n\n\nStretch goal: If you finish the above task before time is up, change the y-axis label so the values are shown with dollar signs, e.g. $80 instead of 80. You will want to use a function from the scales package, see https://scales.r-lib.org/reference/index.html for inspiration and help.\n\nhotels |>\n  group_by(hotel, arrival_date_month) |>   # group by hotel type and arrival month\n  summarise(mean_adr = mean(adr), .groups = \"drop\") |>       # calculate mean adr for each group\n  ggplot(aes(\n    x = arrival_date_month,                 # x-axis = arrival_date_month\n    y = mean_adr,                           # y-axis = mean_adr calculated above\n    group = hotel,                          # group lines by hotel type\n    color = hotel)                          # and color by hotel type\n  ) +\n  geom_line() +                             # use lines to represent data\n  theme_minimal() +                         # use a minimal theme\n  labs(\n    x = \"Arrival month\",                 # customize labels\n    y = \"Mean ADR (average daily rate)\",\n    title = \"Comparison of resort and city hotel prices across months\",\n    subtitle = \"Resort hotel prices soar in the summer while ciry hotel prices remain relatively constant throughout the year\",\n    color = \"Hotel type\"\n  ) +\n  scale_y_continuous(labels = label_dollar())"
  },
  {
    "objectID": "ae/ae-08-data-import-A.html",
    "href": "ae/ae-08-data-import-A.html",
    "title": "AE 08: Data import",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\nreadxl: For importing data from Excel.\n\n\nlibrary(tidyverse)\nlibrary(readxl)"
  },
  {
    "objectID": "ae/ae-08-data-import-A.html#nobel-winners",
    "href": "ae/ae-08-data-import-A.html#nobel-winners",
    "title": "AE 08: Data import",
    "section": "Nobel winners",
    "text": "Nobel winners\n\n\nDemo: Load the data from the data folder and assign it to nobel. Confirm that this new object appears in your Environment tab.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nRows: 935 Columns: 26\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (21): firstname, surname, category, affiliation, city, country, gender,...\ndbl   (3): id, year, share\ndate  (2): born_date, died_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nYour turn (4 minutes): Split the data into two – nobel laureates in STEM fields (category should be Physics, Medicine, Chemistry, or Economics) and nobel laureates in non-STEM fields. Name these two new objects appropriately. Remember: Use concise and evocative names. Confirm that these new objects appear in your Environment tab and that the sum of the number of observations in the two new data frames add to the number of observations in the original data frame.\n\n# define stem fields\nstem_fields <- c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\")\n\n# stem laureates\nnobel_stem <- nobel %>%\n  filter(category %in% stem_fields)\n\n# non-steam laureates\nnobel_nonstem <- nobel %>%\n  filter(!(category %in% stem_fields))\n\n\n\nDemo: Write out the two new datasets you created into the data folder:\n\nwrite_csv(nobel_stem, file = \"data/nobel-stem.csv\")\nwrite_csv(nobel_nonstem, file = \"data/nobel-nonstem.csv\")"
  },
  {
    "objectID": "ae/ae-08-data-import-A.html#sales",
    "href": "ae/ae-08-data-import-A.html#sales",
    "title": "AE 08: Data import",
    "section": "Sales",
    "text": "Sales\nSales data are stored in an Excel file that looks like the following:\n\n\n\n\n\n\nDemo: Read in the Excel file called sales.xlsx from the data/ folder such that it looks like the following.\n\n\nsales <- read_excel(\n  \"data/sales.xlsx\", \n  skip = 3,\n  col_names = c(\"id\", \"n\")\n  )\n\n\n\nDemo - Stretch goal: Manipulate the sales data such such that it looks like the following.\n\n\nsales2 <- sales |>\n  mutate(\n    is_brand_name = str_detect(id, \"Brand\"),\n    brand = if_else(is_brand_name, id, NULL)\n  ) |>\n  fill(brand) |>\n  filter(!is_brand_name) |>\n  select(brand, id, n)\n\n\n\n\n\nQuestion: Why should we bother with writing code for reading the data in by skipping columns and assigning variable names as well as cleaning it up in multiple steps instead of opening the Excel file and editing the data in there to prepare it for a clean import?\nBecause the code allows us to struggle once and re-use for future datasets and leaves a transparent trail of our modifications while manipulating the data in Excel directly is neither reproducible nor reusable."
  },
  {
    "objectID": "ae/ae-08-data-import-A.html#optional",
    "href": "ae/ae-08-data-import-A.html#optional",
    "title": "AE 08: Data import",
    "section": "Optional",
    "text": "Optional"
  },
  {
    "objectID": "ae/ae-09-brexit-A.html",
    "href": "ae/ae-09-brexit-A.html",
    "title": "AE 09: Data Ethics",
    "section": "",
    "text": "In September 2019, YouGov survey asked 1,639 GB adults the following question:\n\nIn hindsight, do you think Britain was right/wrong to vote to leave EU?\n\nRight to leave\n\nWrong to leave\n\nDon’t know\n\n\nThe data from the survey is in data/brexit.csv.\n\nbrexit <- read_csv(\"data/brexit.csv\")\n\nIn this application exercise we tell different stories with the same data.\nExercise 1 - Free scales\nCreate a segmented bar plot facet by region to explore counts of votes to the question Was Britain right/wrong to leave EU.\nNext, use scales = \"free_x\" as an argument to the facet_wrap() function. How does the visualisation change? How is the story this visualisation telling different than the story the original plot tells?\n\nggplot(brexit, aes(y = opinion, fill = opinion)) +\n  geom_bar() +\n    facet_wrap(~region,\n    nrow = 1, labeller = label_wrap_gen(width = 12),\n    scales = \"free_x\"\n  ) +\n  guides(fill = \"none\") +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    x = NULL, y = NULL\n  ) +\n  scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  )) +\n  theme_minimal()\n\n\n\n\nAnswer Here\nThe visualization changes, as the x-axis changes based on the sample size within each facet. It visually is harder to see what is going on, and it appears to suggest, for example, London’s “Wrong” votes are similar to North, despite having drastically different sample sizes.\nExercise 2 - Comparing proportions across facets\nFirst, calculate the proportion of wrong, right, and don’t know answers in each category and then plot these proportions (rather than the counts) and then improve axis labeling. How is the story this visualisation telling different than the story the original plot tells? Hint: You’ll need the scales package to improve axis labeling.\n\nbrexit |>\n  group_by(region, opinion) |>\n  summarize(n = n()) |>\n  mutate(freq = n / sum(n)) |>\n  ggplot() + \n  geom_bar(aes(y = opinion, x = freq, fill = opinion), stat = \"identity\") +\n  facet_wrap(~ region, nrow = 1) +\n  scale_x_continuous(limits = c(0,1)) +\n  theme_bw() +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    y = NULL, x = \"Proportion\"\n  ) + \n    scale_fill_manual(values = c(\n    \"Wrong\" = \"#ef8a62\",\n    \"Right\" = \"#67a9cf\",\n    \"Don't know\" = \"gray\"\n  ))\n\n`summarise()` has grouped output by 'region'. You can override using the\n`.groups` argument.\n\n\n\n\n\nAnswer Here\nThe x-axis is now proportions.\nExercise 3 - Comparing proportions across bars\nRecreate the same visualisation from the previous exercise, this time dodging the bars for opinion proportions for each region, rather than faceting by region and then improve the legend. How is the story this visualisation telling different than the story the previous plot tells?\n\nbrexit |>\n  group_by(region, opinion) |>\n  summarize(n = n()) |>\n  mutate(freq = n / sum(n)) |>\n  ggplot() + \n  geom_bar(\n    aes(y = opinion, x = freq, fill = region), \n    position = \"dodge\", stat = \"identity\"\n  ) +\n  scale_x_continuous(limits = c(0,1)) +\n  theme_bw() +\n  labs(\n    title = \"Was Britain right/wrong to vote to leave EU?\",\n    subtitle = \"YouGov Survey Results, 2-3 September 2019\",\n    caption = \"Source: bit.ly/2lCJZVg\",\n    y = NULL, x = \"Proportion\", \n    fill = \"Region\"\n  ) \n\n`summarise()` has grouped output by 'region'. You can override using the\n`.groups` argument.\n\n\n\n\n\nAnswer Here\nThis visualization tells the story of within opinion vs within region like the others."
  },
  {
    "objectID": "ae/ae-10-data-ethics-A.html",
    "href": "ae/ae-10-data-ethics-A.html",
    "title": "ae-10-data-ethics-suggested-answers",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.1\n✔ readr   2.1.2     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\nSee https://scales.r-lib.org/reference/index.html for inspiration and help with scales.\nIn September 2019, YouGov survey asked 1,639 GB adults the following question:\nThe data from the survey is in data/brexit.csv.\nIn this application exercise we will explore how different axes can tell different stories of data."
  },
  {
    "objectID": "ae/ae-10-data-ethics-A.html#optional",
    "href": "ae/ae-10-data-ethics-A.html#optional",
    "title": "ae-10-data-ethics-suggested-answers",
    "section": "Optional",
    "text": "Optional\nExercise 3 - adding visual uncertanity\nThe Effect of Vitamin C on Tooth Growth in Guinea Pigs: The response is the length of odontoblasts (cells responsible for tooth growth) in 60 guinea pigs. Each animal received one of three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, orange juice or ascorbic acid (a form of vitamin C and coded as VC).\nDemo Make a line plot to show the length of tooth growth by the dose of vitamin C they received. Include error bars that range 1 SD away from the estimate in both directions.\n\nToothGrowth <- read_csv(\"data/ToothGrowth.csv\")\n\nRows: 6 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): supp\ndbl (3): dose, len, sd\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nToothGrowth |>\nggplot(aes(x=dose, y=len, group=supp, color=supp)) + \n  geom_line() +\n  geom_point()+\n  geom_errorbar(aes(ymin= len - sd, ymax= len + sd), width=.2, #create sd bars here\n                 position=position_dodge(0.05))"
  },
  {
    "objectID": "ae/ae-11-dse-bias-privacy-A.html",
    "href": "ae/ae-11-dse-bias-privacy-A.html",
    "title": "AE 11: Data science ethics",
    "section": "",
    "text": "Consider the following scenario: There appears to be an increase in bicycle accidents around the school before and after class. You have been tasked with collecting data to help protect the health of your peers and improve your community. What data might you collect and how? What responsibility do you have to protect that data?\nSpecifically:\n\nwhich data would you collect\n\nClass Answers - Location, weather, severity\n\nhow would you collect the data\n\nClass Answers - Traffic cameras, hospital reports, weather reports\n\nhow would you keep data private.\n\nClass Answers - Not collect personal information, de-identify information"
  },
  {
    "objectID": "ae/ae-11-dse-bias-privacy-A.html#optional",
    "href": "ae/ae-11-dse-bias-privacy-A.html#optional",
    "title": "AE 11: Data science ethics",
    "section": "Optional",
    "text": "Optional\nPart 4 - Stochastic parrots\nYour turn (10 minutes):\n\nRead the following title and abstract.\n\n\nOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 (Bender et. al., 2021)\nThe past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.\n\n\nHave you used a natural language model before? Describe your use.\nWhat is meant by “stochastic parrots” in the paper title?"
  },
  {
    "objectID": "ae/ae-11-dse-bias-privacy.html",
    "href": "ae/ae-11-dse-bias-privacy.html",
    "title": "AE 11: Data science ethics",
    "section": "",
    "text": "Consider the following scenario: There appears to be an increase in bicycle accidents around the school before and after class. You have been tasked with collecting data to help protect the health of your peers and improve your community. What data might you collect and how? What responsibility do you have to protect that data?\nSpecifically:\n\nwhich data would you collect\n\nClass Answers - Location, weather, severity\n\nhow would you collect the data\n\nClass Answers - Traffic cameras, hospital reports, weather reports\n\nhow would you keep data private.\n\nClass Answers - Not collect personal information, de-identify information"
  },
  {
    "objectID": "ae/ae-11-dse-bias-privacy.html#optional",
    "href": "ae/ae-11-dse-bias-privacy.html#optional",
    "title": "AE 11: Data science ethics",
    "section": "Optional",
    "text": "Optional\nPart 4 - Stochastic parrots\nYour turn (10 minutes):\n\nRead the following title and abstract.\n\n\nOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜 (Bender et. al., 2021)\nThe past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.\n\n\nHave you used a natural language model before? Describe your use.\nWhat is meant by “stochastic parrots” in the paper title?"
  },
  {
    "objectID": "ae/ae-12-chronicle-A.html",
    "href": "ae/ae-12-chronicle-A.html",
    "title": "Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle.R R script. Save the resulting data frame in the data folder.\nSuggested scraping code can be found here."
  },
  {
    "objectID": "ae/ae-12-chronicle-A.html#part-2---data-analysis",
    "href": "ae/ae-12-chronicle-A.html#part-2---data-analysis",
    "title": "Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\n\nYour turn (1 minute): Load the data you saved into the data folder and name it chronicle.\n\n\nchronicle <- read_csv(\"data/chronicle.csv\")\n\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\nchronicle |>\n  count(author, sort = TRUE)\n\n# A tibble: 69 × 2\n   author                        n\n   <chr>                     <int>\n 1 Anthony Salgado               3\n 2 Billy Cao                     3\n 3 Community Editorial Board     3\n 4 Heidi Smith                   3\n 5 Linda Cao                     3\n 6 Luke A. Powery                3\n 7 Monday Monday                 3\n 8 Sonia Green                   3\n 9 Viktoria Wulff-Andersen       3\n10 Abdel Shehata                 2\n# … with 59 more rows\n\n\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\nchronicle |>\n  count(date) |>\n  ggplot(aes(x = date, y = n, group = 1)) +\n  geom_line()\n\n\n\n\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\n\nchronicle |>\n  mutate(\n    title = str_to_lower(title),\n    climate = if_else(str_detect(title, \"climate\"), \"mentioned\", \"not mentioned\")\n    ) |>\n  count(climate) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  <chr>         <int> <dbl>\n1 mentioned         3  0.03\n2 not mentioned    97  0.97\n\n\n\n\nYour turn (5 minutes): What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\nchronicle |>\n  mutate(\n    title = str_to_lower(title),\n    abstract = str_to_lower(abstract),\n    climate = if_else(\n      str_detect(title, \"climate\") | str_detect(abstract, \"climate\"), \n      \"mentioned\", \n      \"not mentioned\"\n      )\n    ) |>\n  count(climate) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  <chr>         <int> <dbl>\n1 mentioned         4  0.04\n2 not mentioned    96  0.96\n\n\n\n\nTime permitting: Come up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-12-chronicle.html",
    "href": "ae/ae-12-chronicle.html",
    "title": "Opinion articles in The Chronicle",
    "section": "",
    "text": "This will be done in the chronicle-scrape.R R script. Save the resulting data frame in the data folder."
  },
  {
    "objectID": "ae/ae-12-chronicle.html#part-2---data-analysis",
    "href": "ae/ae-12-chronicle.html#part-2---data-analysis",
    "title": "Opinion articles in The Chronicle",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\n\n\n\nYour turn (1 minute): Load the data you saved into the data folder and name it chronicle.\n\n\n# add code here\n\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\n# add code here\n\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\n# add code here\n\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\n\n# add code here\n\n\n\nYour turn (5 minutes): What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\n# add code here\n\n\n\nTime permitting: Come up with another question and try to answer it using the data.\n\n\n# add code here"
  },
  {
    "objectID": "ae/ae-13-starter-A.html",
    "href": "ae/ae-13-starter-A.html",
    "title": "The Chronicle Analysis + Functions and Iteration",
    "section": "",
    "text": "#Warm Up\nTo convert temperatures in degrees Fahrenheit to Celsius, subtract 32 and multiply by .5556 (or 5/9). Write a function below to do this:"
  },
  {
    "objectID": "ae/ae-13-starter-A.html#part-2---data-analysis",
    "href": "ae/ae-13-starter-A.html#part-2---data-analysis",
    "title": "The Chronicle Analysis + Functions and Iteration",
    "section": "Part 2 - Data analysis",
    "text": "Part 2 - Data analysis\nLet’s start by loading the packages we will need:\n\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(lubridate)\n\n\nchronicle <- read_csv(\"data/chronicle.csv\")\n\n\n\nYour turn (3 minutes): Who are the most prolific authors of the 100 most recent opinion articles in The Chronicle?\n\n\nchronicle |> \n  count(author, sort = T)\n\n# A tibble: 69 × 2\n   author                        n\n   <chr>                     <int>\n 1 Anthony Salgado               3\n 2 Billy Cao                     3\n 3 Community Editorial Board     3\n 4 Heidi Smith                   3\n 5 Linda Cao                     3\n 6 Luke A. Powery                3\n 7 Monday Monday                 3\n 8 Sonia Green                   3\n 9 Viktoria Wulff-Andersen       3\n10 Abdel Shehata                 2\n# … with 59 more rows\n\n\n\n\nDemo: Draw a line plot of the number of opinion articles published per day in The Chronicle.\n\n\nchronicle |>\n  count(date) |> \n  ggplot(\n    aes(x = date, y = n)) + \n  geom_line()\n\n\n\n\n\n\nDemo: What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title?\n\nHint: https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html (Look at the Locale Sensitive section)\nHint: Think about creating a new variable\n\nchronicle |>\n  mutate(\n    title = str_to_lower(title),\n    climate = if_else(str_detect(title, \"climate\"), \"mentioned\", \"not mentioned\")\n  ) |>\n  count(climate) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  climate           n  prop\n  <chr>         <int> <dbl>\n1 mentioned         3  0.03\n2 not mentioned    97  0.97\n\n\n\n\nTogether What percent of the most recent 100 opinion articles in The Chronicle mention “climate” in their title or abstract?\n\n\nchronicle |>\n  mutate(\n    title = str_to_lower(title),\n    abstract = str_to_lower(abstract),\n    climate = if_else(\n      \nstr_detect(title, \"climate\") | str_detect(abstract, \"climate\"),\n\"mentioned\" , \"not mentioned\")\n    \n) |>\n  count(climate) |>\n  mutate(prop = n / sum(n))\n\n#Amazon Candle\n A researcher is interested in the manufacturing process of this candle. Specifically, they are interested in if it’s potency has become less over time. In this exercise, our goal is to plot the number of reviews mentioning “no scent” or “no smell” per week. For the purpose of this exercise, we will only use the first 10 pages of reviews.\nGo to the link here\nThink critically about how we would scrape the titles of the review, the review itself, and where/when the review was given from. Next, run the following code to do so below:\n\npage <- read_html(\"https://www.amazon.com/Yankee-Candle-Large-Apple-Pumpkin/product-reviews/B008P8YTU6/ref=cm_cr_getr_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=1&sortBy=recent\")\n\ntitles <- page |>\n  html_nodes(\"#cm_cr-review_list .celwidget .a-row:nth-child(2)\") |>\n  html_text2()\n\nreviews <- page |>\n  html_nodes(\".a-spacing-small.review-data\") |>\n  html_text2()\n\ncountries_dates <- page |>\n  html_nodes(\"#cm_cr-review_list .review-date\") |>\n  html_text2()\n  \n#Build data set\namazon <- tibble(\n  title = titles,\n  review = reviews,\n  country_date = countries_dates\n)\n\n##Write function\n– Why do we need a function?\nAdd your response here.\n\nscrape_review <- function(url){\n  Sys.sleep(2)\n  \n  page <- read_html(url)\n  \ntitles <- page |>\n  html_nodes(\"#cm_cr-review_list .celwidget .a-row:nth-child(2)\") |>\n  html_text2()\n\nreviews <- page |>\n  html_nodes(\".a-spacing-small.review-data\") |>\n  html_text2()\n\ncountries_dates <- page |>\n  html_nodes(\"#cm_cr-review_list .review-date\") |>\n  html_text2()\n  \ntibble(\n  title = titles,\n  review = reviews,\n  country_date = countries_dates\n)\n\n}\n\n##Test your function\n\n# page 1\nscrape_review(\"https://www.amazon.com/Yankee-Candle-Large-Apple-Pumpkin/product-reviews/B008P8YTU6/ref=cm_cr_getr_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=1&sortBy=recent\")\n\n# A tibble: 10 × 3\n   title                                                      review     count…¹\n   <chr>                                                      <chr>      <chr>  \n 1 5.0 out of 5 stars SMELLS GREAT                            This pump… \"Revie…\n 2 1.0 out of 5 stars Very little scent, not worth the price  What is i… \"Revie…\n 3 3.0 out of 5 stars Arrived with glass smashed              I have or… \"Revie…\n 4 5.0 out of 5 stars Amazing value                           I love ya… \"Revie…\n 5 1.0 out of 5 stars Not stored properly; melted             I ordered… \"Revie…\n 6 1.0 out of 5 stars NO SMELL!! VERY DISSATISFIED!!          Used it f… \"Revie…\n 7 1.0 out of 5 stars BUYER BEWARE/ THIS IS NOT YANKEE CANDLE I bought … \"Revie…\n 8 1.0 out of 5 stars zero scent                              this is n… \"Revie…\n 9 2.0 out of 5 stars Disappointed                            I love th… \"Revie…\n10 2.0 out of 5 stars Arrived melted                          The candl… \"Revie…\n# … with abbreviated variable name ¹​country_date\n\n# page 2\nscrape_review(\"https://www.amazon.com/Yankee-Candle-Large-Apple-Pumpkin/product-reviews/B008P8YTU6/ref=cm_cr_getr_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=2&sortBy=recent\")\n\n# A tibble: 10 × 3\n   title                                                          review count…¹\n   <chr>                                                          <chr>  <chr>  \n 1 5.0 out of 5 stars SMELLS GOOD!                                I don… \"Revie…\n 2 1.0 out of 5 stars Cannot be used : melted when arrived        Likel… \"Revie…\n 3 1.0 out of 5 stars Not a Yankees Candle                        There… \"Revie…\n 4 1.0 out of 5 stars No scent whatsoever                         I sup… \"Revie…\n 5 5.0 out of 5 stars Wonderful candle                            Got t… \"Revie…\n 6 1.0 out of 5 stars I really wanted to like it, but…            It tu… \"Revie…\n 7 4.0 out of 5 stars Smells good.                                Would… \"Revie…\n 8 5.0 out of 5 stars Damaged                                     Candl… \"Revie…\n 9 1.0 out of 5 stars Wrong Scent Wood wick candle!! False adver… I don… \"Revie…\n10 5.0 out of 5 stars Good scent                                  Smell… \"Revie…\n# … with abbreviated variable name ¹​country_date\n\n# page 3\nscrape_review(\"https://www.amazon.com/Yankee-Candle-Large-Apple-Pumpkin/product-reviews/B008P8YTU6/ref=cm_cr_getr_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=3&sortBy=recent\")\n\n# A tibble: 10 × 3\n   title                                                          review count…¹\n   <chr>                                                          <chr>  <chr>  \n 1 4.0 out of 5 stars Average candle                              \"This… Review…\n 2 5.0 out of 5 stars A Softer and Warmer scent than you might e… \"The … Review…\n 3 2.0 out of 5 stars Barely has any scent                        \"I'd … Review…\n 4 1.0 out of 5 stars No emana ningún olor                        \"Esta… Review…\n 5 5.0 out of 5 stars Nice scent last long nice to give as a Chr… \"Gift… Review…\n 6 4.0 out of 5 stars Smell wasn't strong                         \"Scen… Review…\n 7 5.0 out of 5 stars Beautiful!                                  \"I've… Review…\n 8 1.0 out of 5 stars Came ruined                                 \"Melt… Review…\n 9 5.0 out of 5 stars This is the only one buy                    \"Make… Review…\n10 5.0 out of 5 stars Can't go wrong with a classic!              \"I lo… Review…\n# … with abbreviated variable name ¹​country_date\n\n\n– What changes across URLs?\nAdd your response here.\nYou can use the paste() and paste0() functions in R to concatenate elements of a vector into a single string. The paste0() function concatenates strings using no space as the default separator.\nUse this information to create a list of urls for the first 10 pages of the amazon review.\n\nyc_urls <- paste0(\"https://www.amazon.com/Yankee-Candle-Large-Apple-Pumpkin/product-reviews/B008P8YTU6/ref=cm_cr_getr_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=\", 1:10, \"&sortBy=recent\" )\n\nWe have a function. We have a lot of urls. How do we iterate?\nAdd your response here.\n\nyc_reviews_all <- map_dfr(yc_urls , scrape_review)\n\nWe have the data! Let’s clean it up. We need to get the date in working order and createad week variable. We also need to create a variable that detects if “no scent” or “no smell” is mentioned.\nBelow, document what each line of code is doing.\n\nyc_reviews <- yc_reviews_all |>\n  mutate(\n    date = mdy(country_date), \n    week = week(date), \n    review = str_to_lower(review),\n    title = str_to_lower(title),\n    no_scent = case_when(\n      str_detect(review, \"no scent\") | str_detect(title, \"no scent\") ~ \"mentioned\",\n      str_detect(review, \"no smell\") | str_detect(title, \"no smell\") ~ \"mentioned\",\n      TRUE ~ \"not mentioned\"\n    )\n  )\n\nUsing the code above, make a line graph by week for the number of reviews that contained “no scent” or “no smell”.\n\n# add-code-here\n\n\n\nYour turn (3 minutes): Outline how this exercise could be expanded to make a plot like this one that compares number of reviews mentioning no scent/smell and number of COVID cases.\n\nAdd your response here."
  },
  {
    "objectID": "ae/ae-14-starter-A.html",
    "href": "ae/ae-14-starter-A.html",
    "title": "Modeling Introduction",
    "section": "",
    "text": "library(tidyverse)\nFor this activity, we will be working with a Fish data set. This data set is a record of 2 common different fish species in fish market sales. Documentation of the variables can be seen below:\nWe are going to investigate the relationship between a fish’s height and weight. Below, create an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\nStart from the bottom and go up Identify the first and last point and draw a line through most the others\nIs there a relationship between fish height and weight?\nPredict\nAt 10cm, we estimate a weight of 375 grams At 15cm, we estimate a weight of 600 grams At 20cm, we estimate a weight of 975 grams\nR probably created a line that best fit the data….but how and what does that mean?\nThe difference between what we observe and what our model predicts\nNow we know how the line is fit…. so what’s the line?\n\\(\\hat{weight}\\) = 1.96 + 0.2310 \\(\\hat{weight}\\) = 1.96 + 0.2315 \\(\\hat{weight}\\) = 1.96 + 0.23*20\n$$\n= 1.96 +0.23*height\n$$"
  },
  {
    "objectID": "ae/ae-14-starter-A.html#correlation",
    "href": "ae/ae-14-starter-A.html#correlation",
    "title": "Modeling Introduction",
    "section": "Correlation",
    "text": "Correlation\nWe can also assess correlation between two quantitative variables.\nWhat is correlation? What is correlation bounded by?\nStrength and direction of a linear relationship\nr = [-1, 1]\nWhat is the correlation between Height and Weight?\n\nfish |>\n  select(Height, Weight) |>\n  cor()\n\n          Height    Weight\nHeight 1.0000000 0.9537966\nWeight 0.9537966 1.0000000\n\n\nAre you good at guessing? Give it a try!\nhttps://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html"
  },
  {
    "objectID": "ae/ae-14-starter-A.html#modeling-a-third-variable",
    "href": "ae/ae-14-starter-A.html#modeling-a-third-variable",
    "title": "Modeling Introduction",
    "section": "Modeling a third variable",
    "text": "Modeling a third variable\nDoes the relationship change by species? Plot two separate straight lines by Bream and Roach species of fish below.\n\nfish |> \n  ggplot(\n    aes(x = Height, y = Weight, color = Species)\n  ) + \n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs( \n    title = \"Fish Height by Weight\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n\nWe can fit more models than just a straight line. Change the following code below to read method = loess. What is different from the plot created before?\n\nThe line isn’t straight!\n\nfish |>\n  ggplot(\n    aes(x = Height, y = Width)\n  ) + \n  geom_point() + \n  geom_smooth(method = \"loess\") +\n  labs(\n    title = \"Fish by Height and Width\"\n  )"
  },
  {
    "objectID": "ae/ae-15-A.html",
    "href": "ae/ae-15-A.html",
    "title": "Regression with a Single Predictor",
    "section": "",
    "text": "Before getting started, make sure that these two packages are installed:\npalmerpenguins and tidymodels\nToday, we will be studying penguins. Please read the following context and take a glimpse at the data set before we get started.\nThis data set comprising various measurements of three different penguin species, namely Adelie, Gentoo, and Chinstrap. The rigorous study was conducted in the islands of the Palmer Archipelago, Antarctica. These data were collected from 2007 to 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data set is called penguins.\nWe want to understand more about a penguin’s body mass. First, we are going to investigate the relationship between a penguin’s flipper length and their body mass.\nbody mass"
  },
  {
    "objectID": "ae/ae-15-A.html#model-these-data",
    "href": "ae/ae-15-A.html#model-these-data",
    "title": "Regression with a Single Predictor",
    "section": "Model these Data",
    "text": "Model these Data\n\nWrite the population model below that explains the relationship between body mass and flipper length. Hint: You can type equations within dollar sign code chunks seen below.\n\n$$\nbeta\n <- put a hat on \\\n<- this is beta\n{ }\n$$\n\nNow, fit the linear regression model and display the results. Write the estimated model output below.\n\n\ntest <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm, data = penguins) |>\n  tidy()\n\n$$\n = -5781 + 49.7*(flipper) \\\nBodyMass = _o + _1*flipper + _i\n$$\n\nInterpret the slope and the intercept in the context of the data.\n\nSlope: “A 1 unit increase in x” “on average”\nFor a 1 mm increase in flipper length, we expect on average an estimated 49.7 gram increase is body mass.\nIntercept: When flipper length is 0, we estimate on average a body mass of -5791 grams.\n\nWhat is the estimated body mass for a penguin with a flipper length of 210?\n\n = -5781 + 49.7*(200)\n = -5781 + 49.7*(100)\n\nWhat is the estimated body mass for a penguin with a flipper length of 100?"
  },
  {
    "objectID": "ae/ae-15-A.html#next-question",
    "href": "ae/ae-15-A.html#next-question",
    "title": "Regression with a Single Predictor",
    "section": "Next Question",
    "text": "Next Question\n\nNow, we will investigate another question. A different researcher wants to look at body weight of penguins based on the island they were recorded on. What’s different between this question and the last? Hint: Think about the variable type.\n\nOur explanatory variable is now categorical\n\nMake an appropriate visualization to investigate this relationship below. Additionally, calculate the mean body mass by island below.\n\n\npenguins |> \n  ggplot(\n    aes(y = body_mass_g, x = island)\n  ) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values (geom_point).\n\n\n\n\n\n\nChange the geom of your previous plot to geom_point. Use this plot to think about how R models these data.\n\nThe minimize the residuals within each group, our model should go through the mean! Not only does this minimize the residual sums of squares, but it also logically is our best guessed for a random penguin body mass.\n\nNow, fit the linear regression model and display the results. Write the estimated model output below.\n\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ island, data = penguins) |>\n  tidy()\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  <chr>              <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\n\nInterpret each coefficient below in the context of the problem.\nWhat is the estimated body weight of a penguin on Dream island?\n\nThe estimated body mass of a penguin, on average, that is located on the dream island is (4716 - 1003)g.\n\nWhat is the estimated body weight of a penguin on Biscoe island?\n\nThe estimated body mass of a penguin, on average, that is located on the Biscoe islad is 4716 g."
  },
  {
    "objectID": "ae/ae-15-A.html#optional",
    "href": "ae/ae-15-A.html#optional",
    "title": "Regression with a Single Predictor",
    "section": "Optional",
    "text": "Optional\nAsk your own question and explore it!"
  },
  {
    "objectID": "ae/ae-16-A.html",
    "href": "ae/ae-16-A.html",
    "title": "Regression with a Single Predictor",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\nlibrary(plotly)\nlibrary(widgetframe)\nToday, we will expand our understanding of models by continuing to learn about penguins. In the last class, we modeled body mass by flipper length, and in a separate model, modeled body mass by island. Could it be possible that the estimated body mass of a penguin changes by both their flipper length AND by the island they are on?\nReview: Take a glimpse at the data set before we get started. The data set is called penguins.\nNow, fit a model to assess the relationship between our response variable body mass, and our explanatory variables flipper length and island. Produce the summary output. Write out the estimate regression equation below.\n$$ \\\nDream = 1 if Dream; 0 else \\ Torgersen = 1 if Torgersen; 0 else $$\nIs this an additive model or an interaction model? Additive model\nLet’s visualize what these estimates represent.\n– Interpret the slope coefficient for flipper length in the context of the problem\nFor every 1 mm increase in flipper length, we estimate on average a 44.5 g increase in body mass, after holding all other variables constant\n– Predict the body mass of a penguin with a flipper length of 200 on the Dream island\n$$\n$$\nReview: Look at the plot you created. What assumption does the additive model make about the slopes between flipper length and body mass for each of the three islands?\nThe additive model assumes the same slope between body mass and flipper length for all three islands."
  },
  {
    "objectID": "ae/ae-16-A.html#interaciton-model",
    "href": "ae/ae-16-A.html#interaciton-model",
    "title": "Regression with a Single Predictor",
    "section": "Interaciton Model",
    "text": "Interaciton Model\nWhat changes in the R code when fitting an interaction model instead of an additive model in R? We change the + to a *\n– Now fit the interaction model. Display the summary output and write out the estimate regression equation below.\n\n  linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm * island, data = penguins) |>\n  tidy()\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  <chr>                                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                        -5464.     431.      -12.7  2.51e-30\n2 flipper_length_mm                     48.5      2.05     23.7  1.66e-73\n3 islandDream                         3551.     969.        3.66 2.89e- 4\n4 islandTorgersen                     3218.    1680.        1.92 5.62e- 2\n5 flipper_length_mm:islandDream        -19.4      4.94     -3.93 1.03e- 4\n6 flipper_length_mm:islandTorgersen    -17.4      8.73     -1.99 4.69e- 2\n\n\n$$\n = -5464 + 48.5flipper + 3551Dream + 3218Torgersen - 19.4Dreamflipper - 17.4Torgersen*flipper\n$$\nLet’s visualize what these estimates represent.\n\n#Code to get predicted values \nmodel2 <- lm(body_mass_g ~ flipper_length_mm*island, data = penguins)\np2 <- predict(model2)\n\nclean_penguins2 <- penguins |> \n  drop_na(flipper_length_mm)\n\nclean_penguins <- cbind(p2, clean_penguins)\n\n\n#Code to visualize model output\n\nclean_penguins2 |>\n  ggplot(\n    aes(x = flipper_length_mm, y = body_mass_g, color = island)\n  ) + \n  geom_point(alpha = 0.2) + \n  geom_line(\n    aes(y = p2), \n    linetype = \"dashed\",\n    lwd = 1.5\n    \n  ) + \n  labs( \n    x = \"Flipper Length mm\", \n    y = \"Body Mass g\", \n    title = \"Interaction Model\",\n    color = \"Island\")\n\n\n\n\n– Interpret the interaction term for flipper length and Dream island in the context of the problem.\nThe rate of change between estimated body mass and flipper length, on average is different between dream island and biscoe island.\n– Predict the body mass of a penguin with a flipper length of 200 on the Dream island\n$$\n = -5464 + 48.5200 + 35511 + 32180 - 19.41flipper - 17.40*200\n$$"
  },
  {
    "objectID": "ae/ae-16-A.html#how-can-we-choose",
    "href": "ae/ae-16-A.html#how-can-we-choose",
    "title": "Regression with a Single Predictor",
    "section": "How can we choose?",
    "text": "How can we choose?\nOccam’s Razor - Don’t overcomplicate the situation. We prefer the simplest best model.\n\nglance(model1)$r.squared\n\n[1] 0.7742334\n\nglance(model2)$r.squared\n\n[1] 0.7857486\n\nglance(model1)$adj.r.squared\n\n[1] 0.7722296\n\nglance(model2)$adj.r.squared\n\n[1] 0.7825604\n\n\n– What is R-squared? What is adjusted R-squared?\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables)."
  },
  {
    "objectID": "ae/ae-16-A.html#two-quantitative-explanatory-variables",
    "href": "ae/ae-16-A.html#two-quantitative-explanatory-variables",
    "title": "Regression with a Single Predictor",
    "section": "Two Quantitative Explanatory Variables",
    "text": "Two Quantitative Explanatory Variables\nNow, let’s explore body mass, and it’s relationship to bill length and flipper length.\n– Brainstorm, how could we visualize this?\nNote: This code is beyond the scope of this course!\n\nquanplot <- plot_ly(penguins, \n                    x = ~ flipper_length_mm, y = ~ bill_length_mm, z = ~body_mass_g,\n                    marker = list(size = 3, color = \"lightgray\" , alpha = 0.5, \n                                  line = list(color = \"gray\" , width = 2))) |>\n                      add_markers() |>\n                      plotly::layout(scene = list(\n                        xaxis = list(title = \"Flipper (mm)\"),\n                        yaxis = list(title = \"Bill (mm)\"), \n                        zaxis = list(title = \"Body Mass (g)\")\n                      )) |>\n                    config(displayModeBar = FALSE)\n                  frameWidget(quanplot)\n\n– Fit the additive model below. Interpret the coefficient for flipper in context of the problem.\n\n  linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(body_mass_g ~ flipper_length_mm + bill_length_mm, data = penguins) |>\n  tidy()\n\n# A tibble: 3 × 5\n  term              estimate std.error statistic  p.value\n  <chr>                <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)       -5737.      308.      -18.6  7.80e-54\n2 flipper_length_mm    48.1       2.01     23.9  7.56e-75\n3 bill_length_mm        6.05      5.18      1.17 2.44e- 1\n\n\nHolding all other variables constant, for every one mm increase in flipper length, we expect on average a 48.1 mm increase in estimated body mass.\nWhat if I want to fit an interaction model with these two quantitative variables?\nIt looks really similar to what we’ve done before! Try it out!"
  },
  {
    "objectID": "ae/exam-review.html",
    "href": "ae/exam-review.html",
    "title": "Exam Review",
    "section": "",
    "text": "We will use the following two packages in this application exercise.\n\n\ntidyverse: For data import, wrangling, and visualization.\n\n\nlibrary(tidyverse)\n\nFor the remaining time, we will practice data wrangling with dplyr. We will be using the Student Exams data set. This is fictional data. The dataset is not from a real context, and the data set does not represent real people. The purpose of this data set is to teach data science and practice using R functions.\n\nstudentexams <- read_csv(\"data/StudentsPerformance.csv\")\n\nRows: 1000 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): gender, race/ethnicity, parental level of education, lunch, test pr...\ndbl (3): math score, reading score, writing score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nFirst, let’s take a glimpse at our data.\n\nglimpse(studentexams)\n\nRows: 1,000\nColumns: 8\n$ gender                        <chr> \"female\", \"female\", \"female\", \"male\", \"m…\n$ `race/ethnicity`              <chr> \"group B\", \"group C\", \"group B\", \"group …\n$ `parental level of education` <chr> \"bachelor's degree\", \"some college\", \"ma…\n$ lunch                         <chr> \"standard\", \"standard\", \"standard\", \"fre…\n$ `test preparation course`     <chr> \"none\", \"completed\", \"none\", \"none\", \"no…\n$ `math score`                  <dbl> 72, 69, 90, 47, 76, 71, 88, 40, 64, 38, …\n$ `reading score`               <dbl> 72, 90, 95, 57, 78, 83, 95, 43, 64, 60, …\n$ `writing score`               <dbl> 74, 88, 93, 44, 75, 78, 92, 39, 67, 50, …\n\n\nIdentify the variable names. Identify their type.\nInline code example There are 1000 number of rows in the data set and 8 columns in the data set.\nSome variable names have spaces. This won’t work. Let’s clean these up using rename.\nrename() changes the name of columns.\n\nstudentexams <- rename(studentexams, math_score = `math score`,\n                                     reading_score = `reading score`, \n                                     writing_score = `writing score`,\n                                  parental_level_of_education = `parental level of education`)\n\nfilter() :chooses rows based on column values.\nFilter these data so that it only contains rows where math scores are at or equal to 70.\nThen, filter the data to only look at student performance if they received standard lunch.\n\nstudentexams |>\n  filter(math_score >= 70)\n\n# A tibble: 409 × 8\n   gender `race/ethnicity` parental_leve…¹ lunch test …² math_…³ readi…⁴ writi…⁵\n   <chr>  <chr>            <chr>           <chr> <chr>     <dbl>   <dbl>   <dbl>\n 1 female group B          bachelor's deg… stan… none         72      72      74\n 2 female group B          master's degree stan… none         90      95      93\n 3 male   group C          some college    stan… none         76      78      75\n 4 female group B          associate's de… stan… none         71      83      78\n 5 female group B          some college    stan… comple…      88      95      92\n 6 male   group A          some college    stan… comple…      78      72      70\n 7 male   group C          high school     stan… none         88      89      86\n 8 male   group D          bachelor's deg… free… comple…      74      71      80\n 9 male   group A          master's degree free… none         73      74      72\n10 male   group C          high school     stan… none         70      70      65\n# … with 399 more rows, and abbreviated variable names\n#   ¹​parental_level_of_education, ²​`test preparation course`, ³​math_score,\n#   ⁴​reading_score, ⁵​writing_score\n\nstudentexams |> \n  filter(lunch == \"standard\")\n\n# A tibble: 645 × 8\n   gender `race/ethnicity` parental_leve…¹ lunch test …² math_…³ readi…⁴ writi…⁵\n   <chr>  <chr>            <chr>           <chr> <chr>     <dbl>   <dbl>   <dbl>\n 1 female group B          bachelor's deg… stan… none         72      72      74\n 2 female group C          some college    stan… comple…      69      90      88\n 3 female group B          master's degree stan… none         90      95      93\n 4 male   group C          some college    stan… none         76      78      75\n 5 female group B          associate's de… stan… none         71      83      78\n 6 female group B          some college    stan… comple…      88      95      92\n 7 male   group C          associate's de… stan… none         58      54      52\n 8 male   group D          associate's de… stan… none         40      52      43\n 9 female group B          high school     stan… none         65      81      73\n10 male   group A          some college    stan… comple…      78      72      70\n# … with 635 more rows, and abbreviated variable names\n#   ¹​parental_level_of_education, ²​`test preparation course`, ³​math_score,\n#   ⁴​reading_score, ⁵​writing_score\n\n\nWhy does == work here but not in the homework? Check Sakai for a more detailed explanation!\nmutate() changes the values of columns and creates new columns. Let’s use this with if else to create a new variable. Create a new variable called math_pass. Have it display yes if the student received a 70 or higher on their math exam. If they did not, have it say no.\nHint: Think of if else as:\nIf this / Then this / Else this /\n\nstudentexams |> \n  mutate(\n    math_pass = if_else(math_score >= 70, \"Yes\", \"No\")\n  )\n\n# A tibble: 1,000 × 9\n   gender `race/ethnicity` paren…¹ lunch test …² math_…³ readi…⁴ writi…⁵ math_…⁶\n   <chr>  <chr>            <chr>   <chr> <chr>     <dbl>   <dbl>   <dbl> <chr>  \n 1 female group B          bachel… stan… none         72      72      74 Yes    \n 2 female group C          some c… stan… comple…      69      90      88 No     \n 3 female group B          master… stan… none         90      95      93 Yes    \n 4 male   group A          associ… free… none         47      57      44 No     \n 5 male   group C          some c… stan… none         76      78      75 Yes    \n 6 female group B          associ… stan… none         71      83      78 Yes    \n 7 female group B          some c… stan… comple…      88      95      92 Yes    \n 8 male   group B          some c… free… none         40      43      39 No     \n 9 male   group D          high s… free… comple…      64      64      67 No     \n10 female group B          high s… free… none         38      60      50 No     \n# … with 990 more rows, and abbreviated variable names\n#   ¹​parental_level_of_education, ²​`test preparation course`, ³​math_score,\n#   ⁴​reading_score, ⁵​writing_score, ⁶​math_pass\n\n\nNow, use mutate to make gender a factor.\n\nstudentexams|>\n  mutate(gender = as.factor(gender))\n\n# A tibble: 1,000 × 8\n   gender `race/ethnicity` parental_leve…¹ lunch test …² math_…³ readi…⁴ writi…⁵\n   <fct>  <chr>            <chr>           <chr> <chr>     <dbl>   <dbl>   <dbl>\n 1 female group B          bachelor's deg… stan… none         72      72      74\n 2 female group C          some college    stan… comple…      69      90      88\n 3 female group B          master's degree stan… none         90      95      93\n 4 male   group A          associate's de… free… none         47      57      44\n 5 male   group C          some college    stan… none         76      78      75\n 6 female group B          associate's de… stan… none         71      83      78\n 7 female group B          some college    stan… comple…      88      95      92\n 8 male   group B          some college    free… none         40      43      39\n 9 male   group D          high school     free… comple…      64      64      67\n10 female group B          high school     free… none         38      60      50\n# … with 990 more rows, and abbreviated variable names\n#   ¹​parental_level_of_education, ²​`test preparation course`, ³​math_score,\n#   ⁴​reading_score, ⁵​writing_score\n\n\nselect() changes whether or not a column is included.\nslice() chooses rows based on location.\nNow, only display the first 5 rows of the three exam score columns.\n\nstudentexams |>\n  select(math_score, reading_score, writing_score) |>\n  slice(1:5)\n\n# A tibble: 5 × 3\n  math_score reading_score writing_score\n       <dbl>         <dbl>         <dbl>\n1         72            72            74\n2         69            90            88\n3         90            95            93\n4         47            57            44\n5         76            78            75\n\n\nNote: You can combine with functions like head and tail to look at data too!\ngroup_by() perform calculations separately for each value of a variable\nsummarise() collapses a group into a single row\nNow, group students by their parental level of education and calculate their mean math score. Arrange this in descending order.\n\nstudentexams |>\n  group_by(parental_level_of_education) |>\n  summarise(mean_math = mean(math_score)) |>\n  arrange(desc(mean_math))\n\n# A tibble: 6 × 2\n  parental_level_of_education mean_math\n  <chr>                           <dbl>\n1 master's degree                  69.7\n2 bachelor's degree                69.4\n3 associate's degree               67.9\n4 some college                     67.1\n5 some high school                 63.5\n6 high school                      62.1"
  },
  {
    "objectID": "ae/exam-review.html#your-turn",
    "href": "ae/exam-review.html#your-turn",
    "title": "Exam Review",
    "section": "Your turn!",
    "text": "Your turn!\nAsk a question about these data and answer it. Create appropriate plots to help answer your question."
  },
  {
    "objectID": "computing-access.html",
    "href": "computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "If this is your first time accessing the containers, click on reserve STA198-199 on the Reservations available menu on the right. You only need to do this once, and when you do, you’ll see this container moved to the My reservations menu on the left.\nNext, click on STA198-199 under My reservations to access the RStudio instance you’ll use for the course."
  },
  {
    "objectID": "computing-cheatsheets.html",
    "href": "computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://www.rstudio.com/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references."
  },
  {
    "objectID": "computing-troubleshooting.html",
    "href": "computing-troubleshooting.html",
    "title": "Computing troubleshooting",
    "section": "",
    "text": "If you’re having difficulty launching an RStudio session from your reserved container, go to status.oit.duke.edu and scroll down to Teaching and Learning Tools. Under this heading you’ll find an entry called Container Manager (CMGR Coursework Containers)."
  },
  {
    "objectID": "computing-troubleshooting.html#tips-for-not-rendering",
    "href": "computing-troubleshooting.html#tips-for-not-rendering",
    "title": "Computing troubleshooting",
    "section": "Tips for not rendering",
    "text": "Tips for not rendering\nThese are questions to ask yourself / check if you are having trouble rendering your document.\n– Are my code chunk labels weird? To create a code chunk label, you need the following #| label: at the start of your code chunk. If you have spaces in the name you put, or if you are using special characters, you may not be able to render your document. Note: if you want to make a comment, use # only.\n– Does your code run? If you have errors in your code, you will also have errors when rendering the document.\n– Did you put View() in a code chunk? We don’t use View often, but we need to be aware that any function that calls for an external viewer will break the render."
  },
  {
    "objectID": "computing-troubleshooting.html#tips-for-not-seeing-my-changes-in-git",
    "href": "computing-troubleshooting.html#tips-for-not-seeing-my-changes-in-git",
    "title": "Computing troubleshooting",
    "section": "Tips for not seeing my changes in Git",
    "text": "Tips for not seeing my changes in Git\n– Are you in the right project? You can see the project you are working in in the top right corner of your screen. This MUST be the project that you cloned for the exam / assignment / lab. Do not use the files tab to go search for a file outside of your project repo."
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Go to your Files tab, check the box next to the file you want to download, then click on the blue gear icon on the Files tab to reveal the drop down menu, and select Export… If you have selected multiple files to export, RStudio will zip them up into a single zip file for you. If you’ve selected just a single file, it will only download that. The downloaded file will go to wherever files you download off the internet goes on your computer (usually your Downloads folder)."
  },
  {
    "objectID": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "href": "course-faq.html#how-can-i-submit-my-assignment-to-gradescope",
    "title": "FAQ",
    "section": "How can I submit my assignment to Gradescope?",
    "text": "How can I submit my assignment to Gradescope?\nThe instructions for submitting your assignment to Gradescope can be found here. In a nutshell, you’ll upload your PDF and them mark the page(s) where each question can be found. It’s OK if a question spans multiple pages, just mark them all. It’s also OK if a page includes multiple questions."
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "href": "course-faq.html#can-i-use-a-local-install-of-r-and-rstudio-instead-of-using-the-rstudio-containers",
    "title": "FAQ",
    "section": "Can I use a local install of R and RStudio instead of using the RStudio containers?",
    "text": "Can I use a local install of R and RStudio instead of using the RStudio containers?\nThe short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.2.1: https://cran.r-project.org/\nDownload and install the preview build of RStudio: https://www.rstudio.com/products/rstudio/download/preview/\nInstall Git: https://happygitwithr.com/install-git.html\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here."
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "RStudio containers\n🔗 on Duke Container Manager\n\n\n\n\nCourse GitHub organization\n🔗 on GitHub\n\n\nGradescope\n🔗 on Sakai\n\n\nGradebook\n🔗 on Sakai\n\n\nOffice hours\n🔗 on Google docs\n\n\nClass recording request form\n🔗 on Google forms\n\n\nTexbooks\n🔗 R for Data Science\n🔗 Introduction to Modern Statistics\n\n\nPackage documentation\n🔗 ggplot2: ggplot2.tidyverse.org\n🔗 dplyr: dplyr.tidyverse.org\n🔗 tidyr: tidyr.tidyverse.org\n🔗 forcats: forcats.tidyverse.org\n🔗 stringr: stringr.tidyverse.org\n🔗 lubridate: lubridate.tidyverse.org\n🔗 readr: readr.tidyverse.org\n🔗 readxl: readxl.tidyverse.org"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "Intro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language. No statistical or computing background is necessary. Not open to students who have taken a 100-level Statistical Science course, Statistical Science 210, or a Statistical Science course numbered 300 or above."
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nFrench Science 2231\nMon & Wed 3:30 - 4:45 pm\n\n\nLab 06\nPerkins Link 087 (Classroom 3)\nThur 10:15 - 11:30 am\n\n\nLab 07\nPerkins Link 087 (Classroom 3)\nThur 12:00 - 1:15 pm\n\n\nLab 08\nPerkins Link 087 (Classroom 3)\nThur 1:45 - 3:00 pm\n\n\nLab 09\nPerkins Link 087 (Classroom 3)\nThur 3:30 - 4:45 pm\n\n\nLab 10\nPerkins Link 087 (Classroom 3)\nThur 5:15 - 6:30 pm"
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help."
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone."
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here."
  },
  {
    "objectID": "course-support.html#slack",
    "href": "course-support.html#slack",
    "title": "Course support",
    "section": "Slack",
    "text": "Slack\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Slack is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts on Slack before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!"
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to Slack), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Dr. Elijah Meyer at elijah.meyer@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917."
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times.  Duke encourages all students to access these resources.\n\nCAPS: Duke Counseling & Pyschological Services (CAPS) helps Duke Students enhance strengths and develop abilities to successfully live, grow and learn in their personal and academic lives. CAPS recognizes that we are living in unprecedented times and that the changes, challenges and stressors brought on by the COVID-19 pandemic have impacted everyone, often in ways that are tax our well-being. CAPS offers many services to Duke undergraduate students, including brief individual and group counseling, couples counseling and more. CAPS staff also provides outreach to student groups, particularly programs supportive of at-risk populations, on a wide range of issues impacting them in various aspects of campus life. CAPS provides services to students via Telehealth. To initiate services, you can contact their front desk at 919-660-1000.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu.\nTwo-Click Support: Duke Student Government and DukeReach partnership that connects students to help in just two clicks: https://bit.ly/TwoClickSupport."
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited."
  },
  {
    "objectID": "course-support.html#assistance-with-zoom-or-sakai",
    "href": "course-support.html#assistance-with-zoom-or-sakai",
    "title": "Course support",
    "section": "Assistance with Zoom or Sakai",
    "text": "Assistance with Zoom or Sakai\nFor technical help with Sakai or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Sakai here.\nNote that we will be making minimal use of Sakai in this course (primarily for announcements and grade book). All assignment submission will take place on GitHub and conversation on Slack.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person."
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download a PDF copy of the syllabus."
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office hours",
    "text": "Office hours\nClick here for the instructor and TA office hours locations and Zoom links. You are welcomed to attend the office hours for any STA 199 TA, regardless of section."
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\nAll books are freely available online.\n\n\n\nR for Data Science, 2e\nGrolemund, Wickham\nO’Reilly, 2nd edition, 2022\nHard copy only available of 1st edition\n\n\nIntroduction to Modern Statistics\nÇetinkaya-Rundel, Hardin\nOpenIntro Inc., 1st Edition, 2021\nHard copy available on Amazon"
  },
  {
    "objectID": "course-syllabus.html#course-learning-objectives",
    "href": "course-syllabus.html#course-learning-objectives",
    "title": "Syllabus",
    "section": "Course learning objectives",
    "text": "Course learning objectives\nBy the end of the semester, you will…\n\nlearn to explore, visualize, and analyze data in a reproducible and shareable manner\ngain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization\nwork on problems and case studies inspired by and based on real-world questions and data\nlearn to effectively communicate results through written assignments and project presentation"
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "Syllabus",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard as well as the practices specific to this course.\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive. Please update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website, UPDATE LINK.\nAnnouncements will be emailed through Sakai Announcements periodically. Please check your email regularly to ensure you have the latest announcements for the course.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on Ed Discussion. There is a chance another student has already asked a similar question, so please check the other posts in Ed Discussion before adding a new question. If you know the answer to a question posted in the discussion forum, I encourage you to respond!\n\nCheck out the Help tab for more resources.\n\n\nEmail\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 199” in the subject line. Barring extenuating circumstances, I will respond to STA 199 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday."
  },
  {
    "objectID": "course-syllabus.html#activities-assessment",
    "href": "course-syllabus.html#activities-assessment",
    "title": "Syllabus",
    "section": "Activities & Assessment",
    "text": "Activities & Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. They are designed to follow the Prepare, Practice, Perform format.\n\nPrepare: Includes short videos, reading assignments, and lectures to introduce new concepts and ensure a basic comprehension of the material. The goal is to help you prepare for the in-class activities during lecture.\nPractice: Includes in-class application exercises where you will begin to the concepts and methods introduced in the prepare assignment. the activities will graded for completion, as they are designed for you to gain experience with the statistical and computing techniques before working on graded assignments.\nPerform: Includes labs, homework, exams, and the project. These assignments build upon the prepare and practice assignments and are the opportunity for you to demonstrate your understanding of the course material and how it is applied to analyze real-world data.\n\n\nLectures (Prepare)\nPart of the class time will be lectures that introduce new concepts or review topics from the preparation videos. Lectures will not repeat everything in the videos, they will instead highlight important and known to be complex concepts and will be supplemented with live coding activities. You are expected to attend every lecture. Lectures will be recorded and made available to students with an excused absence upon request.\n\n\nApplication exercises (Practice)\nA majority of the in-class lectures will be dedicated to working on Application Exercises (AEs). These exercises which give you an opportunity to practice apply the statistical concepts and code introduced in the prepare assignment. These AEs are due within three days of the corresponding lecture period. Specifically, AEs from Monday lectures are due Thursday by 11:59p ET, and AEs from Wednesday lectures are due Saturday by 11:59p ET.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of at least 80% of AEs will result in full credit for AEs in the final course grade.\nIn addition to AEs will be periodic activities help build a learning community. These will be short, fun activities that will help everyone in the class connect throughout the semester.\n\n\nLabs (Perform)\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nThe lowest lab grade will be dropped at the end of the semester.\n\n\nHomework (Perform)\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nOne homework assignment will be dedicated to a statistics experience. The statistics experience is an opportunity to engage with statistics and data science outside of the classroom through podcasts, books, seminars, data analysis competitions, and other activities. As you complete these experiences, the goal is to consider how the material you’re learning in the course connects with society more broadly.\nThe lowest homework grade will be dropped at the end of the semester.\n\n\nExams (Perform)\nThere will be two, take-home, open-note exams. Through these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analysis and computational tasks related to the content in the prepare, practice, and perform assignments. More details about the content and structure of the exams will be discussed during the semester.\n\n\nProject (Perform)\nThe purpose of the project is to apply what you’ve learned throughout the semester to analyze an interesting data-driven research question. The project will be completed with your lab teams, and each team will present their work in video and in writing during the final exam period. More information about the project will be provided during the semester."
  },
  {
    "objectID": "course-syllabus.html#grading",
    "href": "course-syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nHomework\n30% (5% x 6)\n\n\nLabs\n14% (2% x 7)\n\n\nProject\n15%\n\n\nExam 01\n18%\n\n\nExam 02\n18%\n\n\nApplication Exercises\n2.5%\n\n\nTeamwork\n2.5%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n>= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n< 60"
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nYou may discuss individual homework and lab assignments with other students; however, you may not directly share (or copy) code or write up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write up with another team. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nReusing code: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. If you directly use code from an outside source (or use it as inspiration), you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically result in a 0 for the assignment and will be reported to the Office of Student Conduct for further action.\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\n\n\nLate work\n\nHomework and labs may be submitted up to 3 days late. There will be a 5% deduction for each 24-hour period the assignment is late.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThe late work policy for exams will be provided with the exam instructions.\nThe late work policy for the project will be provided with the project instructions.\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email the head TA before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let Dr. Çetinkaya-Rundel know if you need help contacting your academic dean.\n\n\nRegrade requests\nRegrade requests must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nNo grades will be changed after the project presentations.\n\n\nClass recording requests\nLectures will be recorded on Panopto and will be made available to students with an excused absence upon request. Videos shared with such students will be available for a week. To request a particular lecture’s video, please fill out the form at INSERT LINK. Please also make sure that any official documentation, such as STINFs, Dean’s excuses, NOVAPs, and quarantine/removal from class notices from student health are also uploaded to the form.\n\n\nAttendance policy\n\nCOVID Symptoms, Exposure, or Infection: Student health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919-681-9355). Learn more about current university policy related to COVID-19 at https://coronavirus.duke.edu. To keep the university community’s safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\nInclement weather: In the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work.  Asynchronous catch-up methods may apply.\nReligious accommodations: Students are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: https://trinity.duke.edu/undergraduate/academic-policies/religious-holidays."
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nAug 29: Classes begin\nSep 9: Drop/add ends\nOct 10-11: Fall break\nNov 11: Last day to withdraw with W\nNov 23-25: Thanksgiving recess\nDec 9: Classes end\nDec 10-13: Reading period\nDec 14-19: Final exams\n\nFor more important dates, see the full Duke Academic Calendar."
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Dr. Elijah Meyer (he/him) - Hello! I’m very excited to work with you all this semester. I’ve earned a Master’s degree in statistics and a Ph.D. in statistics with a focus in education from Montana State University. My early research is in sports statistics, with an emphasis on spatial data visualizations to enhance sports strategy. My Ph.D. work is in how to best support graduate student instructors and early career teachers to use active learning in their classrooms.\nPrior to my time at Duke, I’ve taught multiple sections of Introductory and Intermediate Statistics at Montana State, developed their Intermediate Statistics online course, and helped integrate R into the Introductory Statistics curricula. I prioritize community, communication, and respect in my classroom. I want to provide a space where we can freely talk about the material, embrace mistakes, and learn together throughout the semester.\nWhen I’m not in the books, I enjoy playing disc golf, tennis, basketball, and anything else that gets me outside and active. I’m looking forward to meeting you all and having a great semester!\n\n\n\nOffice hours\nLocation\n\n\n\n\nTue 10:00 AM - 12:00 PM\nOld Chemistry Building 208 / Zoom (Password: 5MYp7A)"
  },
  {
    "objectID": "course-team.html#lab-group-information",
    "href": "course-team.html#lab-group-information",
    "title": "Teaching team",
    "section": "Lab Group Information",
    "text": "Lab Group Information\nhttps://github.com/sta199-f22-2/teams/blob/main/teams.csv\nIf you see anything wrong with your information, please reach out to Elijah."
  },
  {
    "objectID": "course-team.html#teaching-assistants",
    "href": "course-team.html#teaching-assistants",
    "title": "Teaching team",
    "section": "Teaching assistants",
    "text": "Teaching assistants\n\n\n\nName\nRole\nLab section\nOffice hours\n\n\n\n\nKonnie Huang (konnie.huang@duke.edu)\nIn Class TA\n\nWed 10:00PM - 11:00AM & Thur 5:00PM - 6:00PM / Zoom\n\n\nEli Gnesin (eli.gnesin@duke.edu)\nLab Leader\nThur 10:15AM - 11:30AM\n(in-person only) Thur 9:00AM - 10:00PM & 12:00 pm - 1:00 pm in Old Chem 203B\n\n\nYibin Zhang (yibin.zhang@duke.edu)\nLab Helper\nThur 10:15AM - 11:30AM\nWed 6:00PM - 8:00PM / Zoom\n\n\nCaitrin Murphy (caitrin.murphy@duke.edu)\nLab Leader\nThur 12:00PM - 1:15PM\nWed 2:00PM - 3:00PM in Old Chem 203B & Thur 7:00PM - 8:00PM / Zoom\n\n\nZheyuan Liu (zheyuan.liu@duke.edu)\nLab Helper\nThur 12:00PM - 1:15PM\nTue 1:00PM - 2:00PM & Thur 2:00PM - 3:00 PM / Zoom\n\n\nChristine (Yueming) Shen (yueming.shen@duke.edu)\nLab Leader / Head TA\nThur 1:45PM - 3:00PM (in-person only)\nThur 3-5pm (in-person only) in Old Chem 203B\n\n\nAlonso Guerrero Castañeda (alonso.guerrero@duke.edu)\nLab Helper\nThur 1:45PM - 3:00PM\nMon 6:00PM - 7:00PM in Old Chem 203B & Thur 6:00PM - 7:00PM / Zoom\n\n\nYouran Wu (youran.wu@duke.edu)\nLab Leader\nThur 3:30PM - 4:45PM\nFri 5:00PM - 7:00PM Zoom\n\n\nChase Mathis (chase.mathis@duke.edu)\nLab Helper\nThur 3:30PM - 4:45PM\nSun 1:00 PM - 3:00 PM in in Old Chem 203B / Zoom\n\n\nKateryna (Kat) Husar (kat.husar@duke.edu)\nLab Leader\nThur 5:15PM - 6:30PM\nTue (in-person only) 12:00PM - 1:00PM & Wed 5:00PM - 6:00PM (Zoom) / in Old Chem 203B & Zoom\n\n\nIsabella Swigart (isabella.swigart@duke.edu)\nLab Helper\nThur 5:15PM - 6:30PM\nTue 4:00 PM - 5:30 PM & Tue 1:00PM - 1:30PM / Zoom"
  },
  {
    "objectID": "hw/hw-1.html",
    "href": "hw/hw-1.html",
    "title": "HW 1 - Data visualization",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Thursday, Sep 15 at 11:59pm."
  },
  {
    "objectID": "hw/hw-1.html#packages",
    "href": "hw/hw-1.html#packages",
    "title": "HW 1 - Data visualization",
    "section": "Packages",
    "text": "Packages\n\nlibrary(tidyverse)\nlibrary(openintro)"
  },
  {
    "objectID": "hw/hw-1.html#guidelines-tips",
    "href": "hw/hw-1.html#guidelines-tips",
    "title": "HW 1 - Data visualization",
    "section": "Guidelines + tips",
    "text": "Guidelines + tips\nAs we’ve discussed in lecture, your plots should include an informative title, axes should be labeled, and careful consideration should be given to aesthetic choices.\nRemember that continuing to develop a sound workflow for reproducible data analysis is important as you complete this homework and other assignments in this course. There will be periodic reminders in this assignment to remind you to knit, commit, and push your changes to GithHub. You should have at least 3 commits with meaningful commit messages by the end of the assignment.\n\n\n\n\n\n\nNote\n\n\n\nNote: Do not let R output answer the question for you unless the question specifically asks for just a plot. For example, if the question asks for the number of columns in the data set, please type out the number of columns. You are subject to lose points if you do not."
  },
  {
    "objectID": "hw/hw-1.html#workflow-formatting",
    "href": "hw/hw-1.html#workflow-formatting",
    "title": "HW 1 - Data visualization",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse code style guidelines.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-1.html#data-1-duke-forest-houses",
    "href": "hw/hw-1.html#data-1-duke-forest-houses",
    "title": "HW 1 - Data visualization",
    "section": "Data 1: Duke Forest houses",
    "text": "Data 1: Duke Forest houses\n\n\n\n\n\n\nNote\n\n\n\nUse this dataset for Exercises 1 and 2.\n\n\nFor the following two exercises you will work with data on houses that were sold in the Duke Forest neighborhood of Durham, NC in November 2020. The duke_forest dataset comes from the openintro package. You can see a list of the variables on the package website or by running ?duke_forest in your console."
  },
  {
    "objectID": "hw/hw-1.html#exercise-1",
    "href": "hw/hw-1.html#exercise-1",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 1",
    "text": "Exercise 1\nSuppose you’re helping some family friends who are looking to buy a house in Duke Forest. As they browse Zillow listings, they realize some houses have garages and others don’t, and they wonder: Does having a garage make a difference?\nLuckily, you can help them answer this question with data visualization!\n\nMake histograms of the prices of houses in Duke Forest based on whether they have a garage.\n\nIn order to do this, you will first need to create a new variable called garage (with levels \"Garage\" and \"No garage\").\nBelow is the code for creating this new variable. Here, we mutate() the duke_forest data frame to add a new variable called garage which takes the value \"Garage\" if the text string \"Garage\" is detected in the parking variable and takes the test string \"No garage\" if not.\n\n\n\n\nduke_forest |>\n  mutate(garage = if_else(str_detect(parking, \"Garage\"),   \"Garage\", \"No garage\"))\n\n\nThen, facet by garage and use different colors for the two facets.\nChoose an appropriate binwidth and decide whether a legend is needed, and turn it off if not.\nInclude informative title and axis labels.\nFinally, include a brief (2-3 sentence) narrative comparing the distributions of prices of Duke Forest houses that do and don’t have garages. Your narrative should touch on whether having a garage “makes a difference” in terms of the price of the house.\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#exercise-2",
    "href": "hw/hw-1.html#exercise-2",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 2",
    "text": "Exercise 2\nIt’s expected that within any given marker larger houses will be priced higher. It’s also expected that the age of the house will have an effect on the price. However in some markets new houses might be more expensive while in others new construction might mean “no character” and hence be less expensive. So your family friends ask: “In Duke Forest, do houses that are bigger and more expensive tend to be newer ones than those that are smaller and cheaper?”\nOnce again, data visualization skills to the rescue!\n\nCreate a scatter plot to exploring the relationship between price and area, conditioning for year_built.\nUse geom_smooth() with the argument se = FALSE to add a smooth curve fit to the data and color the points by year_built.\nInclude informative title, axis, and legend labels.\nDiscuss each of the following claims (1-2 sentences per claim). Your discussion should touch on specific things you observe in your plot as evidence for or against the claims.\n\nClaim 1: Larger houses are priced higher.\nClaim 2: Newer houses are priced higher.\nClaim 3: Bigger and more expensive houses tend to be newer ones than smaller and cheaper ones.\n\n\n\n\nNow is a good time to render, commit, and push.\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#data-2-brfss",
    "href": "hw/hw-1.html#data-2-brfss",
    "title": "HW 1 - Data visualization",
    "section": "Data 2: BRFSS",
    "text": "Data 2: BRFSS\n\n\n\n\n\n\nNote\n\n\n\nUse this dataset for Exercises 3 to 5.\n\n\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is the nation’s premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services. Established in 1984 with 15 states, BRFSS now collects data in all 50 states as well as the District of Columbia and three U.S. territories. BRFSS completes more than 400,000 adult interviews each year, making it the largest continuously conducted health survey system in the world.\nSource: cdc.gov/brfss\n\nIn the following exercises we will work with data from the 2020 BRFSS survey. The originally come from here, though we will work with a random sample of responses and a small number of variables from the data provided. These have already been sampled for you and the dataset you’ll use can be found in the data folder of your repo. It’s called brfss.csv.\n\nbrfss <- read_csv(\"data/brfss.csv\")"
  },
  {
    "objectID": "hw/hw-1.html#exercise-3",
    "href": "hw/hw-1.html#exercise-3",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nHow many rows are in the brfss dataset? What does each row represent?\nHow many columns are in the brfss dataset? Indicate the type of each variable.\nInclude the code and resulting output used to support your answer.\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-4",
    "href": "hw/hw-1.html#exercise-4",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 4",
    "text": "Exercise 4\nDo people who smoke more tend to have worse health conditions?\n\nUse a segmented bar chart to visualize the relationship between smoking (smoke_freq) and general health (general_health). Decide on which variable to represent with bars and which variable to fill the color of the bars by.\nPay attention to the order of the bars and, if need be, use the fct_relevel function to reorder the levels of the variables.\n\nBelow is sample code for releveling general_health. Here we first convert general_health to a factor (how R stores categorical data) and then order the levels from Excellent to Poor.\n\n\n\n\nbrfss |>\n  mutate(\n    general_health = as.factor(general_health),\n    general_health = fct_relevel(general_health, \"Excellent\", \"Very good\", \"Good\", \"Fair\", \"Poor\")\n  )\n\n\nInclude informative title, axis, and legend labels.\nComment on the motivating question based on evidence from the visualization: Do people who smoke more tend to have worse health conditions?\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-5",
    "href": "hw/hw-1.html#exercise-5",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 5",
    "text": "Exercise 5\nHow are sleep and general health associated?\n\nCreate a visualization displaying the relationship between sleep and general_health.\nInclude informative title and axis labels.\nModify your plot to use a different theme than the default.\nComment on the motivating question based on evidence from the visualization: How are sleep and general health associated?\n\n\n Now is a good time to render, commit, and push."
  },
  {
    "objectID": "hw/hw-1.html#exercise-6",
    "href": "hw/hw-1.html#exercise-6",
    "title": "HW 1 - Data visualization",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nFill in the blanks:\n\nThe gg in the name of the package ggplot2 stands for ___.\nIf you map the same continuous variable to both x and y aesthetics in a scatterplot, you get a straight ___ line. (Choose between “vertical”, “horizontal”, or “diagonal”.)\n\n\nCode style: Fix up the code style by spaces and line breaks where needed. Briefly describe your fixes. (Hint: You can refer to the Tidyverse style guide.)\n\n\nggplot(data=mpg,mapping=aes(x=drv,fill=class))+geom_bar() +scale_fill_viridis_d()\n\n\nRead ?facet_wrap. What does nrow do? What does ncol do? What other options control the layout of the individual panels? Why doesn’t facet_grid() have nrow and ncol arguments?\n\n\n Render, commit, and push one last time.\nMake sure that you commit and push all changed documents and your Git pane is completely empty before proceding."
  },
  {
    "objectID": "hw/hw-1.html#submission",
    "href": "hw/hw-1.html#submission",
    "title": "HW 1 - Data visualization",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-1.html#grading",
    "href": "hw/hw-1.html#grading",
    "title": "HW 1 - Data visualization",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 7 points\nExercise 2: 9 points\nExercise 3: 5 points\nExercise 4: 9 points\nExercise 5: 7 points\nExercise 6: 8 points\nWorkflow + formatting: 5 points\nTotal: 50 points"
  },
  {
    "objectID": "hw/hw-2.html",
    "href": "hw/hw-2.html",
    "title": "HW 2 - Data wrangling",
    "section": "",
    "text": "The first step in the process of turning information into knowledge process is to summarize and describe the raw information - the data. In this assignment we explore data on college majors and earnings, specifically the data begin the FiveThirtyEight story “The Economic Guide To Picking A College Major”.\nThese data originally come from the American Community Survey (ACS) 2010-2012 Public Use Microdata Series. While this is outside the scope of this assignment, if you are curious about how raw data from the ACS were cleaned and prepared, see the code FiveThirtyEight authors used.\nWe should also note that there are many considerations that go into picking a major. Earnings potential and employment prospects are two of them, and they are important, but they don’t tell the whole story. Keep this in mind as you analyze the data."
  },
  {
    "objectID": "hw/hw-2.html#workflow-formatting",
    "href": "hw/hw-2.html#workflow-formatting",
    "title": "HW 2 - Data wrangling",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse code style guidelines.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-2.html#packages",
    "href": "hw/hw-2.html#packages",
    "title": "HW 2 - Data wrangling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization and the scales package for better formatting of labels on visualizations.\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "hw/hw-2.html#data",
    "href": "hw/hw-2.html#data",
    "title": "HW 2 - Data wrangling",
    "section": "Data",
    "text": "Data\nThe data originally come from the fivethirtyeight package but we’ll use versions of the data that have been slightly modified to better suit this assignment. You can load the two datasets we’ll be using for this analysis with the following:\n\nmajor_income_undergrad <- read_csv(\"data/major_income_undergrad.csv\")\nmajor_income_grad <- read_csv(\"data/major_income_grad.csv\")\n\nYou can also take a quick peek at your data frames and view their dimensions with the glimpse function.\n\nglimpse(major_income_undergrad)\n\nRows: 172\nColumns: 12\n$ major_code                            <dbl> 5601, 6004, 6211, 2201, 2001, 32…\n$ major                                 <chr> \"Construction Services\", \"Commer…\n$ major_category                        <chr> \"Industrial Arts & Consumer Serv…\n$ undergrad_total                       <dbl> 86062, 461977, 179335, 37575, 53…\n$ undergrad_employed                    <dbl> 73607, 347166, 145597, 29738, 43…\n$ undergrad_employed_fulltime_yearround <dbl> 62435, 250596, 113579, 23249, 34…\n$ undergrad_unemployed                  <dbl> 3928, 25484, 7409, 1661, 3389, 5…\n$ undergrad_unemployment_rate           <dbl> 0.05066099, 0.06838588, 0.048422…\n$ undergrad_p25th                       <dbl> 47000, 34000, 35000, 29000, 3600…\n$ undergrad_median                      <dbl> 65000, 48000, 50000, 41600, 5200…\n$ undergrad_p75th                       <dbl> 98000, 71000, 75000, 60000, 7800…\n$ undergrad_sharewomen                  <dbl> 0.09071251, 0.69036529, 0.651659…\n\nglimpse(major_income_grad)\n\nRows: 172\nColumns: 11\n$ major_code                       <dbl> 5601, 6004, 6211, 2201, 2001, 6206, 1…\n$ major                            <chr> \"Construction Services\", \"Commercial …\n$ major_category                   <chr> \"Industrial Arts & Consumer Services\"…\n$ grad_total                       <dbl> 9173, 53864, 24417, 5411, 9109, 19099…\n$ grad_employed                    <dbl> 7098, 40492, 18368, 3590, 7512, 15157…\n$ grad_employed_fulltime_yearround <dbl> 6511, 29553, 14784, 2701, 5622, 12304…\n$ grad_unemployed                  <dbl> 681, 2482, 1465, 316, 466, 8324, 473,…\n$ grad_unemployment_rate           <dbl> 0.08754339, 0.05775585, 0.07386679, 0…\n$ grad_p25th                       <dbl> 110000, 89000, 100000, 85000, 83700, …\n$ grad_median                      <dbl> 75000, 60000, 65000, 47000, 57000, 80…\n$ grad_p75th                       <dbl> 53000, 40000, 45000, 24500, 40600, 50…\n\n\nThese two datasets have a trove of information. Three variables are common to both datasets:\n\n\nmajor_code: Major code, FO1DP in ACS PUMS\n\nmajor: Major description\n\nmajor_category: Category of major from Carnevale et al\n\nThe remaining variables start with either grad_ or undergrad_ suffix, depending on which dataset they are in. The descriptions of these variables is as follows.\n\n\n*_total: Total number of people with major\n\n*_sample_size: Sample size (unweighted) of full-time, year-round ONLY (used for earnings)\n\n*_employed: Number employed (ESR == 1 or 2)\n\n*_employed_fulltime_yearround: Employed at least 50 weeks (WKW == 1) and at least 35 hours (WKHP >= 35)\n\n*_unemployed: Number unemployed (ESR == 3)\n\n*_unemployment_rate: Unemployed / (Unemployed + Employed)\n\n*_p25th: 25th percentile of earnings\n\n*_median: Median earnings of full-time, year-round workers\n\n*_p75th: 75th percentile of earnings\n\nFinally, undergrad_sharewomen is the proportion of women with the major, and we only have this information for undergraduates.\nLet’s think about some questions we might want to answer with these data:\n\nWhich major has the lowest unemployment rate?\nWhich major has the highest percentage of women?\nHow do the distributions of median income compare across major categories?\nHow much are college graduates making?\nHow do incomes of those with a graduate degree compare to those with an undergraduate degree?\n\nIn the following exercises we aim to answer these questions."
  },
  {
    "objectID": "hw/hw-2.html#exercise-1",
    "href": "hw/hw-2.html#exercise-1",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhich majors have the lowest unemployment rate? Answer the question using a single data wrangling pipeline and focusing on undergraduates (major_income_undergrad). The output should be a tibble with the columns major, and unemployment_rate, with the major with the lowest unemployment rate on top, and displaying the majors with the lowest 5 unemployment rates. Include a sentence listing the majors and the unemployment rates (as percentages)."
  },
  {
    "objectID": "hw/hw-2.html#exercise-2",
    "href": "hw/hw-2.html#exercise-2",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhich majors have the highest percentage of women? Answer the question using a single data wrangling pipeline and focusing on undergraduates (major_income_undergrad). The output should be a tibble with the columns major, and undergrad_sharewomen, with the major with the highest proportion of women on top, and displaying the majors with the highest 5 proportions of women. Include a sentence listing the majors and the percentage of women with the major.\n\n\n\n\nRender, commit (with a descriptive and concise commit message), and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-3",
    "href": "hw/hw-2.html#exercise-3",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 3",
    "text": "Exercise 3\nHow much are college graduates making? For this exercise, focus on undergraduates (major_income_undergrad).\n\n\nPlot the distribution of all median incomes using a histogram with an appropriate binwidth.\n\n\n\n\n\nCalculate the mean and median for median income. Based on the shape of the histogram, determine which of these summary statistics is useful for describing the distribution.\n\n\n\n\nDescribe the distribution of median incomes of college graduates across various majors based on your histogram from part (a) and incorporating the statistic you chose in part (b) to help your narrative. Hint: Mention shape, center, spread, any unusual observations.\n\n\nNow is a good time to render, commit (with a descriptive and concise commit message), and push again. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-4",
    "href": "hw/hw-2.html#exercise-4",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 4",
    "text": "Exercise 4\nHow do the distributions of median income compare across major categories? For this exercise, focus on undergraduates (major_income_undergrad).\n\n\nCalculate a the minimum, median, and maximum median income per major category as well as the number of majors in each category. Your summary statistics should be in decreasing order of median median income.\n\n\n\n\n\nCreate box plots of the distribution of median income by major category.\n\nThe variable major_category should be on the y-axis and undergrad_median on the x-axis.\nThe order of the boxes in your plot should match the order in your summary table from part (a).\nUse color to enhance your plot, and turn off any legends providing redundant information.\nStyle the x-axis labels such that the values are shown in thousands, e.g., 20000 should show up as $20K.\n\n\n\n\n\nIn 1-2 sentences, describe how median incomes across various major categories compare. Your description should also touch on where your own intended/declared major (yes, your major at Duke).\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-5",
    "href": "hw/hw-2.html#exercise-5",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 5",
    "text": "Exercise 5\nOne of the sections of the FiveThirtyEight story is “All STEM fields aren’t the same”. Let’s see if this is true. Once again, focus on undergraduates (major_income_undergrad) for this exercise.\n\n\nFirst, let’s create a new vector called stem_categories that lists the major categories that are considered STEM fields.\n\nstem_categories <- c(\n  \"Biology & Life Science\",\n  \"Computers & Mathematics\",\n  \"Engineering\",\n  \"Physical Sciences\"\n  )\n\nThen, fill in the partial code to create a new variable in our data frame indicating whether a major is STEM or not. Note that you need to figure out the logical operator that goes into ___. Double check that you have successfully created this variable by selecting the variables major_type and stem_categories.\n\nmajor_income_undergrad <- major_income_undergrad |>\n  mutate(major_type = if_else(major_category ___ stem_categories, \"STEM\", \"Not STEM\"))\n\n\n\n\n\n\nIn a single pipeline, determine which STEM majors’ median earnings are less than $55,000. Your answer should be a tibble with the columns major, major_type, and undergrad_median, arranged in order of descending undergrad_median.\n\n\n\n\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#exercise-6",
    "href": "hw/hw-2.html#exercise-6",
    "title": "HW 2 - Data wrangling",
    "section": "Exercise 6",
    "text": "Exercise 6\nFinally, we want to compare median incomes of STEM majors with and without a graduate degree in their major.\n\n\nTo do so, we will first join data that contains information on median incomes of those with undergraduate and graduate degrees. Join the major_income_undergrad and the major_income_grad data sets by major_code. Join them in such a way where only rows that include the same major_code from each data set are included. Name the new data set major_income.\n\n\n\n\n\nCreate a new variable called grad_multiplier – the ratio of median income of those with a graduate degree divided by median income of those with an undergraduate degree, for STEM majors. The result should be tibble with the variables major, grad_multiplier, grad_median, and undergrad_median. The results should be displayed in descending order of grad_multiplier and display the STEM majors with top 10 grad_multiplier.\n\n#\\ label: grad-multiplier\n\n\n\n\nDetermine the number of rows of major_income_undergrad and major_income_grad as well as major_income. How come they don’t all have the same number of rows?\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-2.html#submission",
    "href": "hw/hw-2.html#submission",
    "title": "HW 2 - Data wrangling",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-2.html#grading",
    "href": "hw/hw-2.html#grading",
    "title": "HW 2 - Data wrangling",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 5 points\nExercise 2: 5 points\nExercise 3: 9 points\nExercise 4: 10 points\nExercise 5: 6 points\nExercise 6: 10 points\nWorkflow + formatting: 5 points\nTotal: 50 points"
  },
  {
    "objectID": "hw/hw-3.html",
    "href": "hw/hw-3.html",
    "title": "HW 3 - Ethics + recap",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Friday, Oct 14 at 11:59pm ET."
  },
  {
    "objectID": "hw/hw-3.html#workflow-formatting",
    "href": "hw/hw-3.html#workflow-formatting",
    "title": "HW 3 - Ethics + recap",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse style guide.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-3.html#packages",
    "href": "hw/hw-3.html#packages",
    "title": "HW 3 - Ethics + recap",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, though you’re welcomed to also load other packages as needed.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "hw/hw-3.html#exercise-1",
    "href": "hw/hw-3.html#exercise-1",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 1",
    "text": "Exercise 1\nAll about Quarto:\n\n\nFor each of the character strings below, determine if the string is an proper code chunk label to use in a document when rendering to PDF. If not, explain why. You’re welcomed to try them out to check.\n\nChunk 1:\n\n#| label: label with spaces\n\nChunk 2:\n\n#| label: reaaaaaaaaaalllllllllyyyyy-long-label \n#|        with-line-breaks\n\nChunk 3:\n\n#| label: 1-label-starting-with-number\n\nChunk 4:\n\n#| label: label-with-dashes\n\n\nWhat values does each of the following chunk options take and what do they do?\n\neval\nerror\nwarning\necho\n\n\nWhat do the chunk options fig-height and fig-width do – what do they do when they’re set in a single code chunk and what do they do when they’re set in the document YAML on top?"
  },
  {
    "objectID": "hw/hw-3.html#exercise-2",
    "href": "hw/hw-3.html#exercise-2",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 2",
    "text": "Exercise 2\nAll about group_by():\nSuppose we have the following tiny data frame:\n\ndf <- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\ndf\n\n# A tibble: 5 × 3\n      x y     z    \n  <int> <chr> <chr>\n1     1 a     K    \n2     2 b     K    \n3     3 a     L    \n4     4 a     L    \n5     5 b     K    \n\n\na. What does the following code chunk do? Run it and analyze the result and articulate in words what group_by() does.\n\ndf |>\n  group_by(y)\n\nb. What does the following code chunk do? Run it and analyze the result and articulate in words what arrange() does. Also comment on how it’s different from the group_by() in part (a)?\n\ndf |>\n  arrange(y)\n\nc. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does.\n\ndf |>\n  group_by(y) |>\n  summarize(mean_x = mean(x))\n\nd. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. Then, comment on what the message says.\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x))\n\ne. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. How is the output different from the one in part (d).\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\nf. What do the following pipelines do? Run both and analyze their results and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x))\n\ndf |>\n  group_by(y, z) |>\n  mutate(mean_x = mean(x))\n\n\n\nRender, commit (with a descriptive and concise commit message), and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-3.html#exercise-3",
    "href": "hw/hw-3.html#exercise-3",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe following chart was shared by @GraphCrimes on Twitter on September 3, 2022.\n\n\n\n\n\nWhat is misleading about this graph?\nSuppose you wanted to recreate this plot, with improvements to avoid its misleading pitfalls from part (a). You would obviously need the data from the survey in order to be able to do that. How many observations would this data have? How many variables (at least) should it have, and what should those variables be?\nLoad the data for this survey from data/survation.csv. Confirm that the data match the percentages from the visualization. That is, calculate the percentages of public sector, private sector, don’t know for each of the services and check that they match the percentages from the plot.\nRecreate the visualization, and improve it. You only need to submit the improved version, not a recreation of the misleading graph exactly. Does the improved visualization look different than the original? Does it send a different message at a first glance?"
  },
  {
    "objectID": "hw/hw-3.html#exercise-4",
    "href": "hw/hw-3.html#exercise-4",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 4",
    "text": "Exercise 4\nA data scientist compiled data from several public sources (voter registration, political contributions, tax records) that were used to predict sexual orientation of individuals in a community. What ethical considerations arise that should guide use of such data sets?1\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-3.html#exercise-5",
    "href": "hw/hw-3.html#exercise-5",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 5",
    "text": "Exercise 5\nA data analyst received permission to post a data set that was scraped from a social media site. The full data set included name, screen name, email address, geographic location, IP (internet protocol) address, demographic profiles, and preferences for relationships. Why might it be problematic to post a deidentified form of this data set where name and email address were removed?2"
  },
  {
    "objectID": "hw/hw-3.html#exercise-6",
    "href": "hw/hw-3.html#exercise-6",
    "title": "HW 3 - Ethics + recap",
    "section": "Exercise 6",
    "text": "Exercise 6\nTo complete this exercise you will first need to watch the documentary Coded Bias. To do so, you either need to be on the Duke network or connected to the Duke VPN. Then go to https://find.library.duke.edu/catalog/DUKE009834953 and click on “View Online”. Once you watch the video, write a one paragraph reflection highlighting at least one thing that you already knew about (from the course prep materials) and at least one thing you learned from the movie as well as any other aspects of the documentary that you found interesting / enlightening.\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw-3.html#submission",
    "href": "hw/hw-3.html#submission",
    "title": "HW 3 - Ethics + recap",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-3.html#grading",
    "href": "hw/hw-3.html#grading",
    "title": "HW 3 - Ethics + recap",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 10 points\nExercise 2: 10 points\nExercise 3: 10 points\nExercise 4: 3 points\nExercise 5: 3 points\nExercise 6: 10 points\nWorkflow + formatting: 4 points\nTotal: 50 points"
  },
  {
    "objectID": "hw/hw-4.html",
    "href": "hw/hw-4.html",
    "title": "HW 4 - Scraping + recap",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Wednesday, Nov 2nd at 11:59pm ET."
  },
  {
    "objectID": "hw/hw-4.html#workflow-formatting",
    "href": "hw/hw-4.html#workflow-formatting",
    "title": "HW 4 - Scraping + recap",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse style guide.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw-4.html#packages",
    "href": "hw/hw-4.html#packages",
    "title": "HW 4 - Scraping + recap",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, though you’re welcomed to also load other packages as needed.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rvest)\nlibrary(robotstxt)\nlibrary(openintro)"
  },
  {
    "objectID": "hw/hw-4.html#exercise-1---data-scraping",
    "href": "hw/hw-4.html#exercise-1---data-scraping",
    "title": "HW 4 - Scraping + recap",
    "section": "Exercise 1 - Data Scraping",
    "text": "Exercise 1 - Data Scraping\n\nPlease justify, using the tools we’ve learning in this course, if you are allowed to scrape data from each of the following websites:\n\nhttps://www.espn.com/\nhttps://twitter.com/\nhttps://www.rottentomatoes.com\n\n# insert-code-here"
  },
  {
    "objectID": "hw/hw-4.html#exercise-2---rotten-tomatoes",
    "href": "hw/hw-4.html#exercise-2---rotten-tomatoes",
    "title": "HW 4 - Scraping + recap",
    "section": "Exercise 2 - Rotten Tomatoes",
    "text": "Exercise 2 - Rotten Tomatoes\nRotten Tomatoes is an American review-aggregation website for film. They give percentage scores for movies based on how “good” the movies are. They provide 2 scores:\n\n\n\n\n\n\n\n\nThe audience score, denoted by a popcorn bucket\n\n\n\nThe Tomatometer score represents the percentage of professional critic reviews that are positive for a given film\n\n\n\nWe are going to investigate the relationship between the audience score and tomatometer score between the Halloween movies. Please visit the following website to view the data we plan to scrape: https://www.rottentomatoes.com/franchise/halloween\n\nUsing Selector Gadget, scrape the tomato_score and audience_score and report the lengths of these vectors (using the length()) function. Hint: Their lengths should be equal.\nNext, run the following code:\n\n\npage <- read_html(\"https://www.rottentomatoes.com/franchise/halloween\")\n\ntitles_years <- page |>\n  html_nodes(\".franchise-media-list__h3\") |>\n  html_text2()\n  \nhalloween <- tibble(title_year = titles_years) |>\n  separate(title_year, into = c(\"title\", \"year\"), sep = \"\\\\(\" )\n\nIn 2-3 sentences, describe what the above code is doing. Make sure to articulate each step of both of the pipelines. Hint: Print out titles_years and halloween to see what these objects look like. This will help figure out what the code is doing. You should also try running each line of the pipeline individually to see their outputs.\nAdd Response\n\nAdd the columns tomato_score and audience_score from part (a) to your data frame called halloween that you created in part (b).\n\n\n#insert-code-here\n\n\nCreate an appropriate plot the assess the relationship between a movie’s audience score and their tomatometer score. In 2-3 sentences, comment on the relationship. Your plot should include appropriate labels.\n\n\n#insert-code-here"
  },
  {
    "objectID": "hw/hw-4.html#exercise-3---smoking-during-pregnancy---part-1",
    "href": "hw/hw-4.html#exercise-3---smoking-during-pregnancy---part-1",
    "title": "HW 4 - Scraping + recap",
    "section": "Exercise 3 - Smoking during pregnancy - Part 1",
    "text": "Exercise 3 - Smoking during pregnancy - Part 1\nWe are interested in the impact of smoking during pregnancy. Since it is not possible to run a randomized controlled experiment to investigate this impact, we will instead use a data set has been of interest to medical researchers who are studying the relation between habits and practices of expectant mothers and the birth of their children. This is a random sample of 1,000 cases from a data set released in 2014 by the state of North Carolina. The data set is called births14, and it is included in the openintro package you loaded at the beginning of the assignment.\n\nCreate a version of the births14 data set dropping observations where there are NAs for habit. You can call this version births14_habitgiven.\nPlotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions. Create an appropriate plot displaying the relationship between weight and habit. In 2-3 sentences, discuss the relationships observed.\nNow, fit a linear model that investigates the relationship between weight and habit. Provide the tidy summary output below.\nWrite the estimated least squares regression line below using proper notation.\n\nHint: If you need to type an equation using proper notation, type your answers in-between \\[                                                                                                                                \\]. You may use \\hat{example} to put a hat on a character."
  },
  {
    "objectID": "hw/hw-4.html#exercise-4---smoking-during-pregnacy---part-2",
    "href": "hw/hw-4.html#exercise-4---smoking-during-pregnacy---part-2",
    "title": "HW 4 - Scraping + recap",
    "section": "Exercise 4 - Smoking during pregnacy - Part 2",
    "text": "Exercise 4 - Smoking during pregnacy - Part 2\n\nAnother researcher is interested in assessing the relationship between babies’ weights and mothers’ ages. Fit another linear model to investigate this relationship. Provide the summary output below.\nIn 2-3 sentences, explain how the regression line to model these data is fit, i.e., based on what criteria R determines the regression line.\nInterpret the intercept in the context of the data and the research question. Is the intercept meaningful in this context? Why or why not?\nInterpret the slope in the context of the data and the research question."
  },
  {
    "objectID": "hw/hw-4.html#exercise-5---americas-neighborhood-pollster",
    "href": "hw/hw-4.html#exercise-5---americas-neighborhood-pollster",
    "title": "HW 4 - Scraping + recap",
    "section": "Exercise 5 - America’s Neighborhood Pollster",
    "text": "Exercise 5 - America’s Neighborhood Pollster\nSurveyUSA interviewed 886 North Carolina adults between Septermber 28, 2022 and October 2, 2022. This research was conducted online among a representative cross section of North Carolina adults, selected at random by Lucid Holdings LLC of New Orleans. We will look at the results from the following question:\n\nAre you optimistic or pessimistic about the economic outlook for your family over the next year?\n\nResponses were broken down into the following categories:\n\n\nVariable\nLevels\n\n\n\nAge\n18-49; 50+\n\n\nMood\nOptimistic; Pessimistic\n\n\n\n\nOf the 886 responses, 481 were between the ages of 18-49. Of the individuals that are between 18-49, 237 individuals responded that they were pessimistic. Of the individuals that are 50+, 164 claimed to be optimistic.\n\nFill in the code below to create a hypothetical two-way table to represent this situation.\n\ndata <- tibble( \n  age = c(),\n  mood = c(),\n  values = ()\n  )\n\ndata |>\n  pivot_wider( \n    names_from = ...,\n    values_from = ...\n  )\n\n\nUsing your table from part (a), calculate the probability that a randomly selected individual is 50+ and is pessimistic.\nUsing your table from part (a), calculate the probability that a randomly selected individual is optimistic.\nUsing your table from part (a), calculate the probability that a randomly selected 18-49 aged individual is optimistic.\nCreate an appropriate visualization to compare the the relationship between age and mood. Your plot should include appropriate labels."
  },
  {
    "objectID": "hw/hw-4.html#exercise-6---write-a-function",
    "href": "hw/hw-4.html#exercise-6---write-a-function",
    "title": "HW 4 - Scraping + recap",
    "section": "Exercise 6 - Write a function",
    "text": "Exercise 6 - Write a function\nSuppose you have two types of candy to give out on Halloween; Hershey’s bars and Starbursts. The probability that you give a random trick-or-treater who knocks on your door a Hershey’s bar is 0.5. With this information, create a function that chooses for you which type of candy you will give a trick-or-treater that knocks on your door. Your function should take a numerical value as an input and should give the numbers of Hershey’s bars and Starbursts in a 2x2 tibble with columns candy and n as an output.\nFor example, if you want to select candies for 3 trick or treaters, it might look something like this:\n\ntrick_or_treat(3)\n\nAnd the result might look something like this:\n\n# A tibble: 2 × 2\n  candy             n\n  <chr>         <int>\n1 Hershey's bar     2\n2 Starburst         1\n\nYour function should be able to display a table of counts for Hershey’s bars or Starbursts for any amount of people you expect to see on Halloween.\nWrite this function and test it with 15, 100, and 200 as inputs. You will note that every time you render your document the results will change. This is expected as you’re randomly sampling. (And later on in the course we’ll talk about how to make these numbers not change every time you render, for reproducibility!)\nTo create your function, please fill in the ___ below.\nHint: Think about what varies in your function as you define your input.\n\ntrick_or_treat <- function(___){ # input\n  candy_types <- c(\"___\", \"___\") # types of candy\n  tibble(candy = sample(___, size = ___, replace = ___)) |>\n    ___(___)\n}\n\ntrick_or_treat(___)\n\ntrick_or_treat(___)\n\ntrick_or_treat(___)"
  },
  {
    "objectID": "hw/hw-4.html#submission",
    "href": "hw/hw-4.html#submission",
    "title": "HW 4 - Scraping + recap",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw-4.html#grading",
    "href": "hw/hw-4.html#grading",
    "title": "HW 4 - Scraping + recap",
    "section": "Grading",
    "text": "Grading\nTOTAL: 50 pts\n----------------------\nEx 1: 6 pts\nEx 2: 9 pts\nEx 3: 8 pts\nEx 4: 8 pts\nEx 5: 9 pts\nEx 6: 5 pts\nWorkflow + formatting: 5 pts\n  - 1 pt: full points if at least three commits\n  - 1 pt: full point for linking HW pages on gradescope\n  - 2 pts: code style. Code should follow tidyverse style guidelines, and \n  narrative and text should not exceed the 80 character limit. Figures\n  should be resized properly with informative legends and labels. For minor \n  violations, provide a reminder (and no points off). For repeated\n  violations, take off 1 pt with note it will be more in the future. \n  Include a link to the tidyverse code style here: https://style.tidyverse.org/."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html",
    "href": "hw/hw3-suggested-answers.html",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "",
    "text": "Important\n\n\n\nThis homework is due Friday, Oct 14 at 11:59pm ET."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#workflow-formatting",
    "href": "hw/hw3-suggested-answers.html#workflow-formatting",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Workflow + formatting",
    "text": "Workflow + formatting\nMake sure to\n\nUpdate author name on your document.\nLabel all code chunks informatively and concisely.\nFollow the Tidyverse style guide.\nMake at least 3 commits.\nResize figures where needed, avoid tiny or huge plots.\nUse informative labels for plot axes, titles, etc.\nTurn in an organized, well formatted document."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#packages",
    "href": "hw/hw3-suggested-answers.html#packages",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization, though you’re welcomed to also load other packages as needed.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#exercise-1",
    "href": "hw/hw3-suggested-answers.html#exercise-1",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Exercise 1",
    "text": "Exercise 1\nAll about Quarto:\n\n\nFor each of the character strings below, determine if the string is an proper code chunk label to use in a document when rendering to PDF. If not, explain why. You’re welcomed to try them out to check.\n\nChunk 1:\n\n#| label: label with spaces\n\nChunk 2:\n\n#| label: reaaaaaaaaaalllllllllyyyyy-long-label \n#|        with-line-breaks\n\nChunk 3:\n\n#| label: 1-label-starting-with-number\n\nChunk 4:\n\n#| label: label-with-dashes\n\n\nSuggested Answer A code-chunk label with spaces, line breaks, and numbers that start the label are inappropriate and will cause an error when trying to render your document to a PDF. A label with dashes is appropriate and suggested in place of spaces.\n\n\nWhat values does each of the following chunk options take and what do they do?\n\neval\nerror\nwarning\necho\n\n\n\nSuggested Answer\neval - Takes True or False. This controls whether a code chunk runs when rendering a document.\nerror - Takes True or False. When set to false, prevents messages that are generated by code from appearing in the finished file.\nwarning - Takes True or False. When set to false, prevents warnings that are generated by code from appearing in the finished.\necho - Takes True or False. When set to false, prevents code, but not the results from appearing in the finished file.\n\nWhat do the chunk options fig-height and fig-width do – what do they do when they’re set in a single code chunk and what do they do when they’re set in the document YAML on top?\n\nSuggested Answer\nfig-height and fig-width change the height and width of an embedded figure in your rendered file within the code-chunk these arguments are given. When this is contained in the YAML, it changes the height and width of all figures in the document."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#exercise-2",
    "href": "hw/hw3-suggested-answers.html#exercise-2",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Exercise 2",
    "text": "Exercise 2\nAll about group_by():\nSuppose we have the following tiny data frame:\n\ndf <- tibble(\n  x = 1:5,\n  y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),\n  z = c(\"K\", \"K\", \"L\", \"L\", \"K\")\n)\ndf\n\n# A tibble: 5 × 3\n      x y     z    \n  <int> <chr> <chr>\n1     1 a     K    \n2     2 b     K    \n3     3 a     L    \n4     4 a     L    \n5     5 b     K    \n\n\na. What does the following code chunk do? Run it and analyze the result and articulate in words what group_by() does.\n\ndf |>\n  group_by(y)\n\nSuggested Answer\nThe argument group_by takes df and converts it into a grouped data frame where future operations are performed “by group” (a or b).\nb. What does the following code chunk do? Run it and analyze the result and articulate in words what arrange() does. Also comment on how it’s different from the group_by() in part (a)?\n\ndf |>\n  arrange(y)\n\nSuggested Answer\narrange orders the rows of df by the values of of y. It defaults to arrange the rows based on ordering the y column alpha-numerically.\nc. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does.\n\ndf |>\n  group_by(y) |>\n  summarize(mean_x = mean(x))\n\nSuggested Answer\nThe following code chunk converts it into a grouped data frame, then the mean of the values of x are calculated for each group determined by y.\nd. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. Then, comment on what the message says.\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x))\n\nSuggested Answer\nThe following code chunk converts df into a grouped data frame by both the values of y and the values of z. Then the mean of the values of x are calculated for each group determined by the combinations of y and z. The message summarise() has grouped output by ‘y’. You can override using the .groups argument is a reminder that we have grouped data and suggestes that the dplyr package (installed when we install tidyverse) drops the last group variable before making the calculations. However, the message does not have an impact on the final result, and can be viewed as a friendly reminder that our data are grouped.\ne. What does the following code chunk do? Run it and analyze the result and articulate in words what the pipeline does. How is the output different from the one in part (d).\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x), .groups = \"drop\")\n\nSuggested Answers\nThis code converts our data frame into a grouped data frame by the unique combinations of y and z. Then, the mean is calculated for each unique combination. The output is now different then part d, because our resulting data frame is no longer grouped by any variables thanks to the .groups = \"drop\" argument.\nf. What do the following pipelines do? Run both and analyze their results and articulate in words what each pipeline does. How are the outputs of the two pipelines different?\n\ndf |>\n  group_by(y, z) |>\n  summarize(mean_x = mean(x))\n\ndf |>\n  group_by(y, z) |>\n  mutate(mean_x = mean(x))\n\nSuggested Answers\nThe first code chunk converts df into a grouped data frame by both the values of y and the values of z. Then the mean of the values of x are calculated for each group determined by the combinations of y\nThe second code chunk creates a new variable called mean_x and adds it as a column to the existing data frame df. Five means are calculated, one for each row of our original data frame df. The means calculated are still by the grouped unique combinations of y and z.\n\n\nRender, commit (with a descriptive and concise commit message), and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#exercise-3",
    "href": "hw/hw3-suggested-answers.html#exercise-3",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Exercise 3",
    "text": "Exercise 3\nThe following chart was shared by @GraphCrimes on Twitter on September 3, 2022.\n\n\n\n\n\nWhat is misleading about this graph?\n\n*Suggested Answer**\nThis graph is misleading because the width of the bars are not the same across groups, despite displaying the same value. Additionally, the widths within sector are not to scale, making it seem that the difference between public, private, and don’t know are closer than the data would suggest.\n\nSuppose you wanted to recreate this plot, with improvements to avoid its misleading pitfalls from part (a). You would obviously need the data from the survey in order to be able to do that. How many observations would this data have? How many variables (at least) should it have, and what should those variables be?\n\nSuggested Answer\nThe total sample size is 1858 (from the caption of the plot). Additionally, we would need two variables to recreate the plot. These variables should be a services variable and sector variable.\n\nLoad the data for this survey from data/survation.csv. Confirm that the data match the percentages from the visualization. That is, calculate the percentages of public sector, private sector, don’t know for each of the services and check that they match the percentages from the plot.\n\n\nsurvation <- read_csv(\"data/survation.csv\")\n\nRows: 1858 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Royal Mail, Energy, Water, Rail\ndbl (1): ID\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nsurvation_longer <- survation |>\n  pivot_longer(\n    cols = -ID,\n    names_to = \"service\",\n    values_to = \"sector\"\n  )\nsurvation_longer |>\n  count(service, sector) |>\n  group_by(service) |>\n  mutate(prop = n / sum(n))\n\n# A tibble: 12 × 4\n# Groups:   service [4]\n   service    sector             n   prop\n   <chr>      <chr>          <int>  <dbl>\n 1 Energy     Don't know       130 0.0700\n 2 Energy     Private sector   112 0.0603\n 3 Energy     Public sector   1616 0.870 \n 4 Rail       Don't know        56 0.0301\n 5 Rail       Private sector    56 0.0301\n 6 Rail       Public sector   1746 0.940 \n 7 Royal Mail Don't know       149 0.0802\n 8 Royal Mail Private sector   130 0.0700\n 9 Royal Mail Public sector   1579 0.850 \n10 Water      Don't know        56 0.0301\n11 Water      Private sector    56 0.0301\n12 Water      Public sector   1746 0.940 \n\nsurvation_longer |>\n  mutate(\n    service = fct_relevel(service, \"Royal Mail\", \"Energy\", \"Water\", \"Rail\"),\n    sector = fct_rev(fct_relevel(sector, \"Public sector\", \"Private sector\", \"Don't know\"))\n    ) |>\n  group_by(service, sector) |>\n  summarise(cnt = n()) |>\n  mutate(freq = round(cnt / sum(cnt), 3))\n\n`summarise()` has grouped output by 'service'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 4\n# Groups:   service [4]\n   service    sector           cnt  freq\n   <fct>      <fct>          <int> <dbl>\n 1 Royal Mail Don't know       149  0.08\n 2 Royal Mail Private sector   130  0.07\n 3 Royal Mail Public sector   1579  0.85\n 4 Energy     Don't know       130  0.07\n 5 Energy     Private sector   112  0.06\n 6 Energy     Public sector   1616  0.87\n 7 Water      Don't know        56  0.03\n 8 Water      Private sector    56  0.03\n 9 Water      Public sector   1746  0.94\n10 Rail       Don't know        56  0.03\n11 Rail       Private sector    56  0.03\n12 Rail       Public sector   1746  0.94\n\n\n\nRecreate the visualization, and improve it. You only need to submit the improved version, not a recreation of the misleading graph exactly. Does the improved visualization look different than the original? Does it send a different message at a first glance?\n\n\n\n# A tibble: 12 × 4\n# Groups:   service [4]\n   service    sector             n   prop\n   <chr>      <chr>          <int>  <dbl>\n 1 Energy     Don't know       130 0.0700\n 2 Energy     Private sector   112 0.0603\n 3 Energy     Public sector   1616 0.870 \n 4 Rail       Don't know        56 0.0301\n 5 Rail       Private sector    56 0.0301\n 6 Rail       Public sector   1746 0.940 \n 7 Royal Mail Don't know       149 0.0802\n 8 Royal Mail Private sector   130 0.0700\n 9 Royal Mail Public sector   1579 0.850 \n10 Water      Don't know        56 0.0301\n11 Water      Private sector    56 0.0301\n12 Water      Public sector   1746 0.940 \n\n\n\n\n\nSuggested Answer\nYes, the improved visualization sends a much different message. Now, at first glance, it is more obvious that, regardless of service, most individuals voted that they should be handled in the public sector instead of the private or don’t know. Before, the differences within sector were less obvious due to poor scaling."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#exercise-4",
    "href": "hw/hw3-suggested-answers.html#exercise-4",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Exercise 4",
    "text": "Exercise 4\nA data scientist compiled data from several public sources (voter registration, political contributions, tax records) that were used to predict sexual orientation of individuals in a community. What ethical considerations arise that should guide use of such data sets?1\nSuggested Answers\nAWV - Ethical considerations include if individuals can be re-identified through the use of these data; If using these data are a breach of reasonable privacy; if the intent is harmful when analyzing these data.\n\n\nOnce again, render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#exercise-5",
    "href": "hw/hw3-suggested-answers.html#exercise-5",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Exercise 5",
    "text": "Exercise 5\nA data analyst received permission to post a data set that was scraped from a social media site. The full data set included name, screen name, email address, geographic location, IP (internet protocol) address, demographic profiles, and preferences for relationships. Why might it be problematic to post a deidentified form of this data set where name and email address were removed?2\nSuggested Answers\nYes. Screen name, email address, address, and geographic information all can be used to re-identify individuals within these data (see OKCupid example)."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#exercise-6",
    "href": "hw/hw3-suggested-answers.html#exercise-6",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Exercise 6",
    "text": "Exercise 6\nTo complete this exercise you will first need to watch the documentary Coded Bias. To do so, you either need to be on the Duke network or connected to the Duke VPN. Then go to https://find.library.duke.edu/catalog/DUKE009834953 and click on “View Online”. Once you watch the video, write a one paragraph reflection highlighting at least one thing that you already knew about (from the course prep materials) and at least one thing you learned from the movie as well as any other aspects of the documentary that you found interesting / enlightening.\nAWV\n\n\nRender, commit, and push one last time. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#submission",
    "href": "hw/hw3-suggested-answers.html#submission",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Submission",
    "text": "Submission\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials Duke Net ID and log in using your Net ID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your homework should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\nSelect the first page of your PDF submission to be associated with the “Workflow & formatting” question."
  },
  {
    "objectID": "hw/hw3-suggested-answers.html#grading",
    "href": "hw/hw3-suggested-answers.html#grading",
    "title": "HW 3 - Ethics + recap- Suggested Answers",
    "section": "Grading",
    "text": "Grading\n\nExercise 1: 10 points\nExercise 2: 10 points\nExercise 3: 10 points\nExercise 4: 3 points\nExercise 5: 3 points\nExercise 6: 10 points\nWorkflow + formatting: 4 points\nTotal: 50 points"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 199: Introduction to Data Science",
    "section": "",
    "text": "week\n      dow\n      date\n      what\n      topic\n      prepare\n      slides\n      ae\n      hw\n      hw_sa\n      lab\n      lab_sa\n      exam\n      project\n      notes\n    \n\n\n1\nM\n29 August\nLec 1\nWelcome to STA 199\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n31 August\nLec 2\nMeet the toolkit\n\n\n\n\n\n\n\n\n\nRelease Lab 0\n\n\n\nTh\n1 September\nLab 1\nHello R!\n\n\n\n\n\n\n\n\n\n\n\n\n2\nM\n5 September\nLec 3\nGrammar of graphics\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n7 September\nLec 4\nVisualizing various types of data\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n8 September\nLab 2\nData visualization\n\n\n\n\n\n\n\n\n\nRelease: Lab 1 / Release: HW 1\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3\nM\n12 September\nLec 5\nGrammar of data wrangling\n\n\n\n\n\n\n\n\n\nDue: Lab 1\n\n\n\nW\n14 September\nLec 6\nWorking with multiple data frames\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n15 September\nLab 3\nData wrangling\n\n\n\n\n\n\n\n\n\nRelease: Lab 2 / Due: HW 1 / Release: HW 2\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4\nM\n19 September\nLec 7\nTidying data\n\n\n\n\n\n\n\n\n\nDue: Lab 2\n\n\n\nW\n21 September\nLec 8\nData types and classes\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n22 September\nLab 4\nData tidying\n\n\n\n\n\n\n\n\n\nRelease: Lab 3 / Due HW 2\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5\nM\n26 September\nLec 9\nImporting and recoding data\n\n\n\n\n\n\n\n\n\nDue: Lab 3\n\n\n\nW\n28 September\nLec 10\nExam 1 Review\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n29 September\nLab\nNo lab - Work on Exam 1\n\n\n\n\n\n\n\n\n\nRelease Exam 1 at 12 p.m.\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6\nM\n3 October\nLec 11\nData science ethics 1\n\n\n\n\n\n\n\n\n\nDue Exam 1 at 2 p.m.\n\n\n\nW\n5 October\nLec 12\nData science ethics 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n6 October\nLab\nMerge Conflicts + Ethics\n\n\n\n\n\n\n\n\n\nRelease: Lab 4 / Release: HW 3\n\n\n7\nM\n10 October\nLec\nFall break\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n12 October\nLec 13\nWeb scraping\n\n\n\n\n\n\n\n\n\nDue: Lab 4\n\n\n\nTh\n13 October\nLab\nWork on project proposal\n\n\n\n\n\n\n\n\n\n\n\n\n\nF\n14 October\n\n\n\n\n\n\n\n\n\n\n\nDue: HW 3\n\n\n8\nM\n17 October\nLec 14\nFunctions + iteration\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n19 October\nLec 15\nThe language of models\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n20 October\nLab 5\nProbability + Simpson's Paradox\n\n\n\n\n\n\n\n\n\nRelease: Lab 5 / Due: Project proposal\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9\nM\n24 October\nLec 16\nModels with a single predictor\n\n\n\n\n\n\n\n\n\nDue: Lab 5\n\n\n\nW\n26 October\nLec 17\nModels with multiple predictors\n\n\n\n\n\n\n\n\n\nRelease: HW 4\n\n\n\nTh\n27 October\nLab 6\nPredicting a numerical outcome\n\n\n\n\n\n\n\n\n\nRelease: Lab 6\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10\nM\n31 October\nLec 18\nModels with multiple predictors + Overfitting\n\n\n\n\n\n\n\n\n\nDue: Lab 6\n\n\n\nW\n2 November\nLec 19\nLogistic regression\n\n\n\n\n\n\n\n\n\nDue: HW 4 / Release: HW 5\n\n\n\nTh\n3 November\nLab\nWork on project draft\n\n\n\n\n\n\n\n\n\nRelease: Lab\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11\nM\n7 November\nLec 20\nQuantifying uncertainty\n\n\n\n\n\n\n\n\n\nDue: Lab - project draft 1\n\n\n\nW\n9 November\nLec 21\nEstimation with bootstrap intervals\n\n\n\n\n\n\n\n\n\nDue: HW 5\n\n\n\nTh\n10 November\nLab 7\nPrediction and Bootstrapping\n\n\n\n\n\n\n\n\n\nRelease: Lab 7\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12\nM\n14 November\nLec 22\nHypothesis testing via simulation\n\n\n\n\n\n\n\n\n\nDue: Lab 7\n\n\n\nW\n16 November\nLec 23\nExam 2 Review\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n17 November\nLab\nNo lab - Work on Exam 2\n\n\n\n\n\n\n\n\n\nRelease Exam 2 at 12pm\n\n\n\nF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13\nM\n21 November\nLec 24\nInference with the Central Limit Theorem\n\n\n\n\n\n\n\n\n\nDue: Exam 2 at 2pm\n\n\n\nW\n23 November\nLecture\nNo Lec - Thanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n24 November\nLab\nNo lab - Thanksgiving\n\n\n\n\n\n\n\n\n\n\n\n\n14\nM\n28 November\nLec 25\nCustomizing Quarto reports and presentations\n\n\n\n\n\n\n\n\n\n\n\n\n\nT\n29 November\n\n\n\n\n\n\n\n\n\n\n\nDue: Project draft due (optional)\n\n\n\nW\n30 November\nLec 26\nCommunicating data science results effectively\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n1 December\nLab\nProject peer review\n\n\n\n\n\n\n\n\n\n\n\n\n15\nM\n5 December\nLec 25\nLooking further topic 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\n7 December\nLec 26\nLooking further topic 2\n\n\n\n\n\n\n\n\n\n\n\n\n\nTh\n8 December\nLab\nProject presentations\n\n\n\n\n\n\n\n\n\nDue: Project everything\n\n\n\nF\n9 December\n\n\n\n\n\n\n\n\n\n\n\nDue: HW 6 / Statistics experience"
  },
  {
    "objectID": "labs/lab-0.html",
    "href": "labs/lab-0.html",
    "title": "Lab 0 - Hello R!",
    "section": "",
    "text": "This lab will introduce you to the course computing workflow. The main goal is to reinforce our demo of R and RStudio, which we will be using throughout the course both to learn the statistical concepts discussed in the course and to analyze real data and come to informed conclusions.\nAn additional goal is to reinforce Git and GitHub, the collaboration and version control system that we will be using throughout the course.\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nTo make versioning simpler, this and the next lab are solo labs. In the future, you’ll learn about collaborating on GitHub and producing a single lab report for your lab team, but for now, concentrate on getting the basics down.\nBy the end of the lab, you will…"
  },
  {
    "objectID": "labs/lab-0.html#log-in-to-rstudio",
    "href": "labs/lab-0.html#log-in-to-rstudio",
    "title": "Lab 0 - Hello R!",
    "section": "Log in to RStudio",
    "text": "Log in to RStudio\n\nGo to https://cmgr.oit.duke.edu/containers and login with your Duke NetID and Password.\nClick STA198-199 to log into the Docker container. You should now see the RStudio environment.\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you haven’t yet done so, you will need to reserve a container for STA198-199 first."
  },
  {
    "objectID": "labs/lab-0.html#set-up-your-ssh-key",
    "href": "labs/lab-0.html#set-up-your-ssh-key",
    "title": "Lab 0 - Hello R!",
    "section": "Set up your SSH key",
    "text": "Set up your SSH key\nYou will authenticate GitHub using SSH. Below are an outline of the authentication steps; you are encouraged to follow along as your TA demonstrates the steps.\n\n\n\n\n\n\nNote\n\n\n\nYou only need to do this authentication process one time on a single system.\n\n\n\nType credentials::ssh_setup_github() into your console.\nR will ask “No SSH key found. Generate one now?” You should click 1 for yes.\nYou will generate a key. It will begin with “ssh-rsa….” R will then ask “Would you like to open a browser now?” You should click 1 for yes.\nYou may be asked to provide your GitHub username and password to log into GitHub. After entering this information, you should paste the key in and give it a name. You might name it in a way that indicates where the key will be used, e.g., sta199).\n\nYou can find more detailed instructions here if you’re interested."
  },
  {
    "objectID": "labs/lab-0.html#configure-git",
    "href": "labs/lab-0.html#configure-git",
    "title": "Lab 0 - Hello R!",
    "section": "Configure Git",
    "text": "Configure Git\nThere is one more thing we need to do before getting started on the assignment. Specifically, we need to configure your git so that RStudio can communicate with GitHub. This requires two pieces of information: your name and email address.\nTo do so, you will use the use_git_config() function from the usethis package.\nType the following lines of code in the console in RStudio filling in your name and the email address associated with your GitHub account.\nFor example, mine would be\n\nusethis::use_git_config(\n  user.name = \"ElijahMeyer3\", \n  user.email = \"esm70@duke.edu\"\n  )\n\nYou are now ready interact with GitHub via RStudio!"
  },
  {
    "objectID": "labs/lab-0.html#clone-the-repo-start-new-rstudio-project",
    "href": "labs/lab-0.html#clone-the-repo-start-new-rstudio-project",
    "title": "Lab 0 - Hello R!",
    "section": "Clone the repo & start new RStudio project",
    "text": "Clone the repo & start new RStudio project\n\nGo to the course organization at github.com/sta199-f22-2 organization on GitHub. Click on the repo with the prefix lab-0. It contains the starter documents you need to complete the lab.\nClick on the green CODE button, select Use SSH (this might already be selected by default, and if it is, you’ll see the text Clone with SSH). Click on the clipboard icon to copy the repo URL.\nIn RStudio, go to File ➛ New Project ➛Version Control ➛ Git.\nCopy and paste the URL of your assignment repo into the dialog box Repository URL. Again, please make sure to have SSH highlighted under Clone when you copy the address.\nClick Create Project, and the files from your GitHub repo will be displayed in the Files pane in RStudio.\nClick lab-0-datasaurus.qmd to open the template Quarto file. This is where you will write up your code and narrative for the lab."
  },
  {
    "objectID": "labs/lab-0.html#r-and-r-studio",
    "href": "labs/lab-0.html#r-and-r-studio",
    "title": "Lab 0 - Hello R!",
    "section": "R and R Studio",
    "text": "R and R Studio\nBelow are the components of the RStudio IDE.\n\nBelow are the components of a Quarto (.qmd) file."
  },
  {
    "objectID": "labs/lab-0.html#yaml",
    "href": "labs/lab-0.html#yaml",
    "title": "Lab 0 - Hello R!",
    "section": "YAML",
    "text": "YAML\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\n\n\n\n\n\n\nImportant\n\n\n\nOpen the Quarto (.qmd) file in your project, change the author name to your name, and render the document. Examine the rendered document."
  },
  {
    "objectID": "labs/lab-0.html#committing-changes",
    "href": "labs/lab-0.html#committing-changes",
    "title": "Lab 0 - Hello R!",
    "section": "Committing changes",
    "text": "Committing changes\nNow, go to the Git pane in your RStudio instance. This will be in the top right hand corner in a separate tab.\nIf you have made changes to your Rmd file, you should see it listed here. Click on it to select it in this list and then click on Diff. This shows you the difference between the last committed state of the document and its current state including changes. You should see deletions in red and additions in green.\nIf you’re happy with these changes, we’ll prepare the changes to be pushed to your remote repository. First, stage your changes by checking the appropriate box on the files you want to prepare. Next, write a meaningful commit message (for instance, “updated author name”) in the Commit message box. Finally, click Commit. Note that every commit needs to have a commit message associated with it.\nYou don’t have to commit after every change, as this would get quite tedious. You should commit states that are meaningful to you for inspection, comparison, or restoration.\nIn the first few assignments we will tell you exactly when to commit and in some cases, what commit message to use. As the semester progresses we will let you make these decisions.\nNow let’s make sure all the changes went to GitHub. Go to your GitHub repo and refresh the page. You should see your commit message next to the updated files. If you see this, all your changes are on GitHub and you’re good to go!"
  },
  {
    "objectID": "labs/lab-0.html#push-changes",
    "href": "labs/lab-0.html#push-changes",
    "title": "Lab 0 - Hello R!",
    "section": "Push changes",
    "text": "Push changes\nNow that you have made an update and committed this change, it’s time to push these changes to your repo on GitHub.\nIn order to push your changes to GitHub, you must have staged your commit to be pushed. click on Push."
  },
  {
    "objectID": "labs/lab-0.html#data-visualization-and-summary",
    "href": "labs/lab-0.html#data-visualization-and-summary",
    "title": "Lab 0 - Hello R!",
    "section": "Data visualization and summary",
    "text": "Data visualization and summary\n\nPlot y vs. x for the dino dataset. Then, calculate the correlation coefficient between x and y for this dataset.\n\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your Rmd document and successfully render it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data <- datasaurus_dozen |>\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |>, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: <-, assigns the name dino_data to the filtered data frame.\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(data = dino_data, mapping = aes(x = x, y = y)) +\n  geom_point()\n\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as \\(r\\) in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate \\(r\\) only if relevant. In this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear (it’s dinosaurial)!\nFor illustrative purposes only, let’s calculate the correlation coefficient between x and y.\n\n\n\n\n\n\nNote\n\n\n\nStart with `dino_data` and calculate a summary statistic that we will call `r` as the `cor`relation between `x` and `y`.\n\n\n\ndino_data |>\n  summarize(r = cor(x, y))\n\n\nThis is a good place to pause, render, and commit changes with the commit message “Added answer for Ex 2.”\nThen, push these changes when you’re done.\n\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\n\nThis is another good place to pause, render, and commit changes with the commit message “Added answer for Ex 3.”\nThen, push these changes when you’re done.\n\n\nPlot y vs. x for the circle dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\n\nYou should pause again, render, commit changes with the commit message “Added answer for Ex 4”.\nThen, push.\n\nFinally, let’s plot all datasets at once. In order to do this we will make use of faceting, given by the code below:\n\n\n\n\n\n\nNote\n\n\n\nFacet by the dataset variable, placing the plots in a 3 column grid, and don’t add a legend.\n\n\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset))+\n  geom_point()+\n  facet_wrap(~ dataset, ncol = 3) +\n  theme(legend.position = \"none\")\n\nAnd we can use the group_by function to generate all the summary correlation coefficients. We’ll go through these functions next week when we learn about data wrangling.\n\ndatasaurus_dozen |>\n  group_by(dataset) |>\n  summarize(r = cor(x, y)) \n\n\nInclude the faceted plot and the summary of the correlation coefficients in your lab write-up by including relevant code in R chunks (give them appropriate names). In the narrative below the code chunks, briefly comment on what you notice about the plots and the correlations between x and y values within each of them (one or two sentences is fine!).\n\nYou’re done with the data analysis exercises, but we’d like to do one more thing to customize the look of the report."
  },
  {
    "objectID": "labs/lab-0.html#resize-your-figures",
    "href": "labs/lab-0.html#resize-your-figures",
    "title": "Lab 0 - Hello R!",
    "section": "Resize your figures",
    "text": "Resize your figures\nWe can customize the output from a particular R chunk by including options in the header that will override any global settings.\n\nIn the R chunks you wrote for Exercises 2-5, customize the settings by modifying the options in the R chunks used to create those figures.\n\nFor Exercises 2, 3, and 4, we want square figures. We can use fig.height and fig.width in the options to adjust the height and width of figures. Modify the chunks in Exercises 2-4 to be as follows:\n\n```{r}\n#| label: ex2-chunk-label\n#| fig-height: 5\n#| fig-width: 5\n\n# Your code that created the figure\n```\n\nFor Exercise 5, modify your figure to have fig-height of 10 and fig-width of 6.\nNow, save and render.\nOnce you’ve created this PDF file, you’re done!\n\nCommit all remaining changes with the commit message “Done with Lab 1!”.\nThen push."
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1 - Data visualization",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Monday, Sep 12 at 11:59pm."
  },
  {
    "objectID": "labs/lab-1.html#packages",
    "href": "labs/lab-1.html#packages",
    "title": "Lab 1 - Data visualization",
    "section": "Packages",
    "text": "Packages\nWe will use the tidyverse package to create and customize plots in R.\n\nlibrary(tidyverse)\nlibrary(viridis)"
  },
  {
    "objectID": "labs/lab-1.html#data-lets-take-a-trip-to-the-midwest",
    "href": "labs/lab-1.html#data-lets-take-a-trip-to-the-midwest",
    "title": "Lab 1 - Data visualization",
    "section": "Data: Let’s take a trip to the Midwest",
    "text": "Data: Let’s take a trip to the Midwest\nThe data in this lab is in the midwest data frame. It is part of the ggplot2 R package, so the midwest data set is automatically loaded when you load the tidyverse package.\nThe data contains demographic characteristics of counties in the Midwest region of the United States.\nBecause the data set is part of the ggplot2 package, you can read documentation for the data set, including variable definitions by typing ?midwest in the console."
  },
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2 - Data wrangling",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Monday, Sep 19 at 11:59pm."
  },
  {
    "objectID": "labs/lab-2.html#warm-up",
    "href": "labs/lab-2.html#warm-up",
    "title": "Lab 2 - Data wrangling",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and render the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your `.qmd and .pdf files. If anything is missing, render, commit, and push again."
  },
  {
    "objectID": "labs/lab-2.html#packages",
    "href": "labs/lab-2.html#packages",
    "title": "Lab 2 - Data wrangling",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling. This package is already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "labs/lab-2.html#data",
    "href": "labs/lab-2.html#data",
    "title": "Lab 2 - Data wrangling",
    "section": "Data",
    "text": "Data\nThe dataset for this assignment can be found as a CSV (comma separated values) file in the data folder of your repository. You can read it in using the following.\n\nnobel <- read_csv(\"data/nobel.csv\")\n\nThe descriptions of the variables are as follows:\n\n\nid: ID number\n\nfirstname: First name of laureate\n\nsurname: Surname\n\nyear: Year prize won\n\ncategory: Category of prize\n\naffiliation: Affiliation of laureate\n\ncity: City of laureate in prize year\n\ncountry: Country of laureate in prize year\n\nborn_date: Birth date of laureate\n\ndied_date: Death date of laureate\n\ngender: Gender of laureate\n\nborn_city: City where laureate was born\n\nborn_country: Country where laureate was born\n\nborn_country_code: Code of country where laureate was born\n\ndied_city: City where laureate died\n\ndied_country: Country where laureate died\n\ndied_country_code: Code of country where laureate died\n\noverall_motivation: Overall motivation for recognition\n\nshare: Number of other winners award is shared with\n\nmotivation: Motivation for recognition\n\nIn a few cases the name of the city/country changed after laureate was given (e.g. in 1975 Bosnia and Herzegovina was called the Socialist Federative Republic of Yugoslavia). In these cases the variables below reflect a different name than their counterparts without the suffix _original.\n\n\nborn_country_original: Original country where laureate was born\n\nborn_city_original: Original city where laureate was born\n\ndied_country_original: Original country where laureate died\n\ndied_city_original: Original city where laureate died\n\ncity_original: Original city where laureate lived at the time of winning the award\n\ncountry_original: Original country where laureate lived at the time of winning the award"
  },
  {
    "objectID": "labs/lab-2.html#get-to-know-your-data",
    "href": "labs/lab-2.html#get-to-know-your-data",
    "title": "Lab 2 - Data wrangling",
    "section": "Get to know your data",
    "text": "Get to know your data\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?\n\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\n\nlaureates for whom country is available\nlaureates who are people as opposed to organizations (organizations are denoted with \"org\" as their gender)\nlaureates who are still alive (their died_date is NA)\n\n\n\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code."
  },
  {
    "objectID": "labs/lab-2.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "href": "labs/lab-2.html#most-living-nobel-laureates-were-based-in-the-us-when-they-won-their-prizes",
    "title": "Lab 2 - Data wrangling",
    "section": "Most living Nobel laureates were based in the US when they won their prizes",
    "text": "Most living Nobel laureates were based in the US when they won their prizes\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nnobel_living <- nobel_living |>\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science <- nobel_living |>\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the following exercises, work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your Quarto document, even though the next exercise doesn’t explicitly ask you to do so.\n\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.\n\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-2.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "href": "labs/lab-2.html#but-of-those-us-based-nobel-laureates-many-were-born-in-other-countries",
    "title": "Lab 2 - Data wrangling",
    "section": "But of those US-based Nobel laureates, many were born in other countries",
    "text": "But of those US-based Nobel laureates, many were born in other countries\n\nCreate a new variable called born_country_us in nobel_living_science that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?\n\n\n\n\n\n\n\nNote\n\n\n\nYou should be able to cheat borrow from code you used earlier to create the country_us variable.\n\n\n\n\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not. Create two visualizations with this new variable added:\n\nPlot 1: Segmented frequency bar plot\nPlot 2: Segmented relative frequency bar plot (Hint: Add position(\"fill\") to geom_bar().)\n\nHere are some instructions that apply to both of these visualizations:\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be two bars for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\nWhich of these visualizations is a better fit for answering the following question: “Do the data appear to support Buzzfeed’s claim that of those US-based Nobel laureates, many were born in other countries?” First, state which plot you’re using to answer the question. Then, answer the question, explaining your reasoning in 1-2 sentences.\n\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding.\n\n\n\nIn a single pipeline, filter the nobel_living_science data frame for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?\n\n\nNow is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3 - Data tidying",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due Monday, Sep 26 at 11:59pm."
  },
  {
    "objectID": "labs/lab-3.html#warm-up",
    "href": "labs/lab-3.html#warm-up",
    "title": "Lab 3 - Data tidying",
    "section": "Warm up",
    "text": "Warm up\nBefore we introduce the data, let’s warm up with some simple exercises.\n\nUpdate the YAML, changing the author name to your name, and render the document.\nCommit your changes with a meaningful commit message.\nPush your changes to GitHub.\nGo to your repo on GitHub and confirm that your changes are visible in your `.qmd and .pdf files. If anything is missing, render, commit, and push again."
  },
  {
    "objectID": "labs/lab-3.html#packages",
    "href": "labs/lab-3.html#packages",
    "title": "Lab 3 - Data tidying",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and the scales package for better plot labels. These packages are already installed for you. You can load it by running the following in your Console:\n\nlibrary(tidyverse)\nlibrary(scales)"
  },
  {
    "objectID": "labs/lab-3.html#data",
    "href": "labs/lab-3.html#data",
    "title": "Lab 3 - Data tidying",
    "section": "Data",
    "text": "Data\nThe datasets that you will work with in this dataset come from the Organization for Economic Co-Operation and Development (OECD), stats.oecd.org."
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due October 12th at 11:59pm."
  },
  {
    "objectID": "labs/lab-4.html#why-teams-rationale",
    "href": "labs/lab-4.html#why-teams-rationale",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Why Teams: Rationale",
    "text": "Why Teams: Rationale\nIn the real world, data scientists and statisticians often work in research teams. It is a skill to be able to communicate and work together on common projects. Thus, the remaining labs + your project will be team based.\nTeams work better when members have a common understanding of the team’s goals and expectations for collaboration. The purpose of this activity is to help your team making a plan for working together during lab and outside of the scheduled lab time.\nEach team member will have some ideas about how a team should operate. These ideas may be very different. This is your opportunity to share your thoughts and ideas to promote optimal team function and prevent misunderstandings in the future."
  },
  {
    "objectID": "labs/lab-4.html#team-name",
    "href": "labs/lab-4.html#team-name",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Team Name",
    "text": "Team Name\nDiscuss with your group a team name to be called. Your GitHub repos will be created for this team name moving forward. Report your team name to your Lab Leader before moving on."
  },
  {
    "objectID": "labs/lab-4.html#instructions",
    "href": "labs/lab-4.html#instructions",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Instructions",
    "text": "Instructions\nDiscuss each of the items below with all in-person team members.\nHave one person act as the recorder and type the team’s decisions in this document.\nBe sure the team agrees on an item before it is added to the document.\nOnce the document is complete, the recorder should render, commit, and push the team agreement to GitHub. All team members can refer to this lab document throughout the semester."
  },
  {
    "objectID": "labs/lab-4.html#team-agreement",
    "href": "labs/lab-4.html#team-agreement",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Team Agreement",
    "text": "Team Agreement\nWeekly meetings\nIdentify a 1 - 2 hour weekly block outside of lab where the team can meet to work on assignments. All team members should block off this time on their calendar in case the group needs to meet to finish lab or work on the project.\nMeeting “location”\nHow the team will meet to work together (e.g. in-person, Zoom, Facetime, Google Hangouts). Be sure every member is able to access the virtual meeting space, if needed. If you are unable to find a weekly time when the team can meet, briefly outline a plan to work on assignments outside of lab. Otherwise, you can delete this item.\nPrimary method of communication\nThe team’s primary method of communication outside of meetings (e.g. Slack, text messages, etc.)\nHow should someone notify the other members if they are unable to attend lab or a scheduled team meeting?\nBy when should everyone have their portion of the lab completed?\nKeep in mind your team may want to have time to review the lab before turning it in to make sure it is a cohesive write up.\nAny other items the team would like to discuss or plan.\nMissing Teammates\nIf you are missing teammates for today’s lab, it is your responsibility to reach out, say hello, and communicate with them that they must contribute to the above and below questions before submitting lab-04 to Gradescope. You can find their email in the teams repo. The link to the teams repo is located on our website on the teaching team tab."
  },
  {
    "objectID": "labs/lab-4.html#setup",
    "href": "labs/lab-4.html#setup",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Setup",
    "text": "Setup\n\nClone the repo and open the .qmd file.\nAssign the numbers 1, 2, 3, and 4 to each of the team members. If your team has fewer than 4 people, some people will need to have multiple numbers. If your team has more than 4 people, some people will need to share some numbers."
  },
  {
    "objectID": "labs/lab-4.html#lets-cause-a-merge-conflict",
    "href": "labs/lab-4.html#lets-cause-a-merge-conflict",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Let’s cause a merge conflict!",
    "text": "Let’s cause a merge conflict!\nOur goal is to see two different types of merges: first we’ll see a type of merge that git can’t figure out on its own how to do on its own (a merge conflict) and requires human intervention, then another type of where that git can figure out how to do without human intervention.\nDoing this will require some tight choreography, so pay attention!\nTake turns in completing the exercise, only one member at a time. Others should just watch, not doing anything on their own projects (this includes not even pulling changes!) until they are instructed to. If you feel like you won’t be able to resist the urge to touch your computer when it’s not your turn, we recommend putting your hands in your pockets or sitting on them!\nBefore starting: everyone should have the repo cloned and know which role number(s) they are.\nRole 1:\n\nChange the team name to your actual team name.\nrender, commit, push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 2:\n\nChange the team name to some other word.\nRender, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict.\nClear the merge conflict by editing the document to choose the correct/preferred change.\nRender.\n\nClick the Stage checkbox for all files in your Git tab. Make sure they all have check marks, not filled-in boxes.\ncommit and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 3:\n\nChange the a label of the first code chunk\nRender, commit, push. You should get an error.\nPull. No merge conflicts should occur, but you should see a message about merging.\nNow push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nRole 4:\n\nChange the label of the first code chunk to something other than previous role did.\nRender, commit, push. You should get an error.\nPull. Take a look at the document with the merge conflict. Clear the merge conflict by choosing the correct/preferred change. render, and push.\n\n🛑 Make sure the previous role has finished before moving on to the next step.\nEveryone: Pull, and observe the changes in your document."
  },
  {
    "objectID": "labs/lab-4.html#tips-for-collaborating-via-github",
    "href": "labs/lab-4.html#tips-for-collaborating-via-github",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Tips for collaborating via GitHub",
    "text": "Tips for collaborating via GitHub\n\nAlways pull first before you start working.\nResolve a merge conflict (render and push) before continuing your work. Never do new work while resolving a merge conflict.\nRender, commit, and push often to minimize merge conflicts and/or to make merge conflicts easier to resolve.\nIf you find yourself in a situation that is difficult to resolve, ask questions ASAP. Don’t let it linger and get bigger."
  },
  {
    "objectID": "labs/lab-4.html#packages",
    "href": "labs/lab-4.html#packages",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization.\n\nlibrary(tidyverse)\n\nSince the exercises for this week are short it’s possible not every team member will get to commit and push during the workshop. However each team member should review what was created, fix typos, make edits for better presentation, etc. either during or after the workshop, and before the deadline.\nNote: Everyone should intellectually contribute to every question. However, no two teammates should work on the same question at the same time below."
  },
  {
    "objectID": "labs/lab-4.html#data",
    "href": "labs/lab-4.html#data",
    "title": "Lab 4 - Merge Conflicts - Ethics",
    "section": "Data",
    "text": "Data\nIn this lab you’ll construct the data set!"
  },
  {
    "objectID": "labs/lab-5.html",
    "href": "labs/lab-5.html",
    "title": "Lab 5 - Probability and Simpson’s Paradox",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due October 24th at 11:59pm."
  },
  {
    "objectID": "labs/lab-5.html#exercise-1---probability-and-you",
    "href": "labs/lab-5.html#exercise-1---probability-and-you",
    "title": "Lab 5 - Probability and Simpson’s Paradox",
    "section": "Exercise 1 - Probability and You",
    "text": "Exercise 1 - Probability and You\nWe use probabilities all the time when making decisions. As a group, provide two real world examples of when you’ve used probability to make decisions in your every day life. Think critically. Be creative."
  },
  {
    "objectID": "labs/lab-5.html#exercise-2---risk-of-coronary-heart-disease",
    "href": "labs/lab-5.html#exercise-2---risk-of-coronary-heart-disease",
    "title": "Lab 5 - Probability and Simpson’s Paradox",
    "section": "Exercise 2 - Risk of coronary heart disease",
    "text": "Exercise 2 - Risk of coronary heart disease\nThis data set is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. We want to examine the relationship between various health characteristics and the risk of having heart disease. Load in the data set called education-disease and answer the following questions below.\n\n# insert-code-here\n\nNote: Show your work by writing your answer as a fraction to potentially receive partial credit. For example, if your numerator is the combination of two values, show the addition to obtain these values. Example: (1+4) / 10 = 0.5.\n\nHow many levels of education are there in these data? How many levels of disease are there?\nConvert the data to a 4x3 data table where each cell is the number of people falling into each combination of Disease and Education. Hint: use count and pivot_wider.\n\n\n# insert-code-here\n\nUsing your data table from part b, answer the remaining questions.\n\nWhat is the probability of a random individual being high risk for cardiovascular disease?\nWhat is the probability of a random individual having high school or GED education and not being high risk for cardiovascular disease?\nWhat is the probability that a random individual who is already high risk for cardiovascular disease has a college education?\n\n\nIf you haven’t yet done so, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-5.html#exercise-3---computer-store",
    "href": "labs/lab-5.html#exercise-3---computer-store",
    "title": "Lab 5 - Probability and Simpson’s Paradox",
    "section": "Exercise 3 - Computer store",
    "text": "Exercise 3 - Computer store\nIn a computer store, 30% of the computers in stock are laptops and 70% are desktops. Five percent of the laptops are on sale, while 10% of the desktops are on sale.\n\nFill in the code below to create a hypothetical two-way table to represent this situation. Assume the total number of computers is 1000.\n\n\ndata <- tibble( \n  Type = c(),\n  Sale = c(),\n  values = ()\n  )\n\ndata |>\n  pivot_wider( \n    names_from = ...,\n    values_from = ....)\n\n\nCalculate the probability of that a randomly selected computer will be a desktop, given that the computer is on sale.\nIn your own words, explain what this probability means.\n\n\nProblems adapted from Mind on Statistics, 5th Ed. By Utts and Heckard\n\n\nIf you haven’t yet done so, now is a good time to render, commit, and push. Make sure that you commit and push all changed documents and your Git pane is completely empty before proceeding."
  },
  {
    "objectID": "labs/lab-5.html#exercise-4---bike-rentals",
    "href": "labs/lab-5.html#exercise-4---bike-rentals",
    "title": "Lab 5 - Probability and Simpson’s Paradox",
    "section": "Exercise 4 - Bike rentals",
    "text": "Exercise 4 - Bike rentals\nBike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. You are tasked to investigate the relationship between the temperature outside and the number of bikes rented in the Washington DC area between the years 2011 and 2022. You will be investigating data for the months June, July, September, and November.\nBelow is a list of variables and their definitions:\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\nseason\nnumerical representation of Summer, Fall, Winter, and Spring\n\n\nyear\nnumerical representation of 2011 (0) or 2012 (1)\n\n\nmnth\nmonth in which data were collected\n\n\nholiday\nindicator variable if data were collected on a holiday\n\n\nweekday\nnumerical representation of day of week\n\n\ntemp\ntemperature in Celsius\n\n\ncnt\ncount of bike rentals\n\n\n\n\nRead in the data. Then, create a scatter plot that investigates the relationship between the number of bikes rented and the temperature outside. Include a straight line of best fit to help discuss the discovered relationship. Summarize your findings in 2-3 sentences.\n\n\nbike <- read_csv(\"data/bike.csv\")\n\n\n\n\n\nAnother researcher suggests to look at the relationship between bikes rented and temperature by each of the four months of interest. Recreate your plot in part a, and color the points by month. Include a straight line for each of the four months to help discuss each month’s relationship between bikes rented and temperature. In 3-4 sentences, summarize your findings.\n\n\n\n\nPlease watch the following video on Simpson’s Paradox here. After you do, please answer the following questions.\n\nIn your own words, summarize Simpson’s Paradox in 2-3 sentences.\nCompare and contrast your findings from part (a) and part (b). What’s different?\nThink critically about your answer to part d. What other context from this study could be creating this paradox? That is, identify a potential confounding variable in this study. Be sure to justify how your example could be a potential confounding variable by relating it back to both bike rentals and temperature.\n\n\n\nData subset from Progress in Artificial Intelligence, 2013."
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6 - Single Predictor",
    "section": "",
    "text": "Learning Goals\n– Use tidymodels framework to build a linear model and estimate regression parameters\n– Visualize your linear model\nIntro\nParasites can cause infectious disease – but not all animals are affected by the same parasites. Some parasites are present in a multitude of species and others are confined to a single host. It is hypothesized that closely related hosts are more likely to share the same parasites. More specifically, it is thought that closely related hosts will live in similar environments and have similar genetic makeup that coincides with optimal conditions for the same parasite to flourish.\nIn this lab we will see how much evolutionary history predicts parasite similarity.\nThe Data\nToday’s dataset comes from an Ecology Letters paper by Cooper at al. (2012) entitled “Phylogenetic host specificity and understanding parasite sharing in primates” located here. The goal of the paper was to identify the ability of evolutionary history and ecological traits to characterize parasite host specificity.\nEach row of the data contains two species, species1 and species2.\nSubsequent columns describe metrics that compare the species:\n– divergence_time: how many (millions) of years ago the two species diverged. i.e. how many million years ago they were the same species.\n– distance: geodesic distance between species geographic range centroids (in kilometers)\n– BMdiff: difference in body mass between the two species (in grams)\n– precdiff: difference in mean annual precipitation across the two species geographic ranges (mm)\n– parsim: a measure of parasite similarity (proportion of parasites shared between species, ranges from 0 to 1.)\nThe data are available in parasites.csv in the data folder.\nPackages\nWe’ll use the tidyverse package for much of the data wrangling and visualization.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nExercises\n\n\n\n\n\n\nImportant\n\n\n\nPick another member of the team write the answer to Exercise 1. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\nTo get started, load the data and save the data frame as parasites.\nLet’s start by examining the relationship between divergence_time and parsim.\n1.(a) Based on the goals of the analysis, what is the response variable?\n\nVisualize the relationship between the two variables. Be sure to put informative axes labels and a title.\nUse the visualization to describe the relationship between the two variables.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 1 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 2. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n2.(a) Write the regression equation using proper notation.\n\nInterpret the slope and the intercept in the context of the data.\nRecreate the visualization from Exercise 1, this time adding a regression line to the visualization.\nWhat do you notice about the prediction (regression) line that may be strange, particularly for very large divergence times?\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 2 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 3. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n3.(a) Using mutate, crate a new variable that transforms the variable parsim from being between 0 and 1, so that it can range between (−∞,+∞). i.e. Create a new variable transformed_parsim that is calculated as log(parsim/(1-parsim)). Add this variable to your data frame. This will be better suited for fitting a regression model (and interpreting predicted values!).\nNote: log in R represents taking the nautral log\n\nThen, visualize the relationship between divergence_time and transformed_parsim. Be sure to put informative axes labels and a title. Add a regression line to your visualization.\nWrite a 1-2 sentence description of what you observe in the visualization.\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 3 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 4. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\n\nWhich variable is the strongest individual predictor of parasite similarity between species? To answer this question, begin by fitting a linear regression model to each pair of variables. Do not report the model outputs in a tidy format but save each one as dt_model, dist_model, BM_model and prec_model, respectively.\n\n– divergence_time and transformed_parsim\n– distance and transformed_parsim\n– BMdiff and transformed_parsim\n– precdiff and transformed_parsim\n\nReport the slops for each of these models. Use proper notation.\nTo answer our question of interest, would it be useful to compare the slopes in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 4 renders, commits, and pushes, another team member should pull their changes and render the document. Then, they should write the answer to Exercise 5. All others should contribute to the discussion but only one person should type up the answer, render the document, commit, and push to GitHub. All others should not touch the document.\n\n\n\nNow, what if calculated \\(R^2\\) to help answer our question? To compare the explanatory power of each individual predictor, we will look at \\(R^2\\) between the models. \\(R^2\\) is a measure of how much of the variability in the response variable is explained by the model.\n\nAs you may have guessed from the name \\(R^2\\) can be calculated by squaring the correlation when we have a simple linear regression model. The correlation r takes values -1 to 1, therefore, \\(R^2\\) takes values 0 to 1. Intuitively, if r=1 or −1, then \\(R^2\\)=1, indicating the model is a perfect fit for the data. If r≈0 then \\(R^2\\)≈0, indicating the model is a very bad fit for the data.\nYou can calculate \\(R^2\\) using the glance function. For example, you can calculate \\(R^2\\) for dt_model using the code glance(dt_model)$r.squared.\n\nCalculate and report \\(R^2\\) for each model fit in the previous exercise.\nTo answer our question of interest, would it be useful to compare the \\(R^2\\) in each model to choose the variable that is the strongest predictor of parasite similarity? Why or why not?\n\n\n\n\n\n\n\nImportant\n\n\n\nAfter the team member working on Exercise 5 renders, commits, and pushes, all other team members should pull the changes and render the document. Finally, a team member different than the one responsible for typing up responses to Exercise 5 should do the last task outlined below.\n\n\nSubmission\n\n\n\n\n\n\nWarning\n\n\n\nBefore you wrap up the assignment, make sure all documents are updated on your GitHub repo. We will be checking these to make sure you have been practicing how to render and push changes.\nYou must turn in a PDF file to the Gradescope page by the submission deadline to be considered “on time”.\nMake sure your data are tidy! That is, your code should not be running off the pages and spaced properly. See: https://style.tidyverse.org/ggplot2.html.\n\n\nTo submit your assignment:\n\nGo to http://www.gradescope.com and click Log in in the top right corner.\nClick School Credentials \\(\\rightarrow\\) Duke NetID and log in using your NetID credentials.\nClick on your STA 199 course.\nClick on the assignment, and you’ll be prompted to submit it.\nMark all the pages associated with exercise. All the pages of your lab should be associated with at least one question (i.e., should be “checked”). If you do not do this, you will be subject to lose points on the assignment.\n\nSelect the first page of your .pdf submission to be associated with the “Workflow & formatting” question.\nGrading\n\n\nComponent\nPoints\n\n\n\nEx 1\n8\n\n\nEx 2\n14\n\n\nEx 3\n8\n\n\nEx 4\n8\n\n\nEx 4\n7\n\n\nWorkflow & formatting\n5\n\n\nTotal\n50\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe “Workflow & formatting” component assesses the reproducible workflow. This includes:\n\nhaving at least 3 informative commit messages\nlabeling the code chunks\nhaving readable code that does not exceed 80 characters, i.e., we can read all your code in the rendered PDF\neach team member contributing to the repo with commits at least once\nthe issue being closed with a commit message"
  },
  {
    "objectID": "labs/lab-project-draft.html",
    "href": "labs/lab-project-draft.html",
    "title": "Lab - Project draft",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due November 7th."
  },
  {
    "objectID": "labs/lab-project-draft.html#proposal-feedback-review",
    "href": "labs/lab-project-draft.html#proposal-feedback-review",
    "title": "Lab - Project draft",
    "section": "Proposal feedback review",
    "text": "Proposal feedback review\n\nAs a team, review all feedback left in Gradescope for your proposal.\nMake decision about which dataset you will use for your project and going forward write up your analysis in report.qmd. Additionally, report which data set you plan to use to your lab instructor."
  },
  {
    "objectID": "labs/lab-project-draft.html#project-draft",
    "href": "labs/lab-project-draft.html#project-draft",
    "title": "Lab - Project draft",
    "section": "Project draft",
    "text": "Project draft\n\n\n\n\n\n\nImportant\n\n\n\nYour next project related deadline is Fri, Nov 7 at 11:59pm. Your project draft, written in report.qmd, must be pushed to GitHub by that time. You will lose push access to your repo at that time until your draft has been reviewed. Once again, you will receive feedback as issues on your GitHub repository.\n\n\n\nReview https://sta199-f22-2.github.io/project-description.html#draft for requirements for the project draft.\nStart working on your draft! Make good use of the time with your TA during lab.\nOnce you complete your draft but before you finalize it:\n\nIn report.qmd set echo: false in the YAML of your document. Read through your draft completely and make sure everything makes sense without the code visible, and make any edits as needed. Then, set echo: true again before submitting. (For your draft we want to see your code so we can provide feedback on it. For your final report we will ask you to hide it again.)\n\nUpdate your index.qmd:\n\nUpdate the title field with your team name.\nAdd your abstract.\n\n\nUpdate your About page (about.qmd) with information on your team."
  },
  {
    "objectID": "labs/lab-project-draft.html#quarto-options",
    "href": "labs/lab-project-draft.html#quarto-options",
    "title": "Lab - Project draft",
    "section": "Quarto options",
    "text": "Quarto options\n\n\n\n\n\n\nNote\n\n\n\nMuch of what is listed in this section is optional, but we recommend reviewing them as a team and deciding on which ones you want to use/include in your project.\n\n\nTheming\nYou can see your deployed project website at the URL listed in your project repo.\n\nYou can pick a theme from https://quarto.org/docs/output-formats/html-themes.html.\nYou can update the theme of your project by changing the theme field in the _quarto.yml file.\nRender the website from the Build tab and commit and push your changes.\nFootnotes\nTo add a footnote, make sure you’re in the Visual editor mode in RStudio and click on Insert > Footnote.1 One you add your footnote, click outside of the footnote area, anywhere else in your document, to go back to editing your document.\nCross references\nYou can add cross references to your figures and tables so that you can refer to them like “Figure 1 shows that …” or “As seen in Table 1, …” instead of “the figure below” or “the table below”. To do this, you need to label the code chunks for those figures and tables in a special way (with fig- and tbl- suffixes, respectively) and add captions to them.\nFigures\nFor example, Figure 1 shows a positive and moderately strong relationship between fuel efficiency of cars (measured as miles/gallon) and their displacement.\n\n```{r}\n#| label: fig-mtcars-plot\n#| fig-cap: \"Fuel efficiency of cars vs. their displacement.\"\n\nggplot(mtcars, aes(x = disp, y = mpg)) +\n  geom_point()\n```\n\n\n\nFigure 1: Fuel efficiency of cars vs. their displacement.\n\n\n\n\nWhat you’re not seeing in the text above is that we didn’t type Figure 1 in the text, but instead referenced this figure with @fig-mtcars-plot:\n\nFor example, @fig-mtcars-plot shows a positive and moderately strong relationship between fuel efficiency of cars (measured as miles/gallon) and their displacement.\n\nTables\nAnd Table 1 shows the output of the linear regression for predicting fuel efficiency from displacement.\nNote that we piped the result of the tidy() function (which outputs a tibble) into the kable() function from the knitr package to turn it into a table. Quarto needs this last step to know that this code chunk produces a table that can be formatted and cross referenced as such.\n\n```{r}\n#| label: tbl-mpg-disp\n#| tbl-cap: \"Linear regression model for predicting fuel efficiency from displacement.\"\n\nlinear_reg() |>\n  fit(mpg ~ disp, data = mtcars) |>\n  tidy() |>\n  knitr::kable()\n```\n\n\n\nTable 1: Linear regression model for predicting fuel efficiency from displacement.\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n29.5998548\n1.2297195\n24.070411\n0\n\n\ndisp\n-0.0412151\n0.0047118\n-8.747151\n0\n\n\n\n\n\n\nOnce again, what you’re not seeing in the text above is that we didn’t type Table 1 in the text, but instead referenced this table with @tbl-mpg-disp.\n\nAnd @tbl-mpg-disp shows the output of the linear regression for predicting fuel efficiency from displacement.\n\nCitations\nYou can use Quarto’s built-in citation and bibliography features for your citations. For example …"
  },
  {
    "objectID": "labs/lab-project-proposal.html",
    "href": "labs/lab-project-proposal.html",
    "title": "Lab - Project Proposal",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due October 20th at 11:59pm."
  },
  {
    "objectID": "labs/lab-project-proposal.html#data-sets-that-can-not-be-used",
    "href": "labs/lab-project-proposal.html#data-sets-that-can-not-be-used",
    "title": "Lab - Project Proposal",
    "section": "Data sets that can not be used",
    "text": "Data sets that can not be used\n– Data sets that have been used for class examples or assignments.\n– Data sets from Kaggle.\n– Data sets analyzed in another course.\nThere will be limits on the number of groups that can use a given data set, so I encourage you to be creative!\nSome resources that may be helpful:\n– R Data Sources for Regression Analysis\n– FiveThirtyEight\n– TidyTuesday\nAdditions:\n– World Health Organization\n– The National Bureau of Economic Research\n– International Monetary Fund\n– General Social Survey\n– United Nations Data\n– United Nations Statistics Division\n– U.K. Data\n– U.S. Data\n– U.S. Census Data\n– European Statistics\n– Statistics Canada\n– Pew Research\n– UNICEF\n– CDC\n– World Bank\n– Election Studies\nAll analyses must be done in RStudio, and your final written report and analysis must be reproducible. This means that you must create a Quarto document attached to a GitHub repository that will create your written report exactly upon rendering."
  },
  {
    "objectID": "labs/lab-project-proposal.html#introduction-and-data",
    "href": "labs/lab-project-proposal.html#introduction-and-data",
    "title": "Lab - Project Proposal",
    "section": "Introduction and Data",
    "text": "Introduction and Data\n(a) Choose three substantially different data sets you are interested in analyzing. You must scrape at least 1 data set for your project proposal. For each, identify the components below.\nFor each data set, include the following:\n– Identify the source of the data,\n– When and how it was originally collected (by the original data curator, not necessarily how you found the data)\n– A brief description of the observations"
  },
  {
    "objectID": "labs/lab-project-proposal.html#research-question",
    "href": "labs/lab-project-proposal.html#research-question",
    "title": "Lab - Project Proposal",
    "section": "Research question",
    "text": "Research question\n(b) Your research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nTarget population.\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following\n– A well thought out formulated research question. You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.\n– Describe the research topic along with a concise statement of your hypotheses.\n– Identify the types of variables in your research question. Categorical? Quantitative?"
  },
  {
    "objectID": "labs/lab-project-proposal.html#data-set",
    "href": "labs/lab-project-proposal.html#data-set",
    "title": "Lab - Project Proposal",
    "section": "Data set",
    "text": "Data set\n(c) For each data set, include the following\n– Use the glimpse function to provide a glimpse of the data set.\n– Place the file containing your data in the data folder of the project repo\n\nNotes\n– It is critical to check feedback on your project proposal. Even if you earn a 10, it may not mean that your proposal is perfect.\n– You must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback."
  },
  {
    "objectID": "labs/lab-proposal.html",
    "href": "labs/lab-proposal.html",
    "title": "Lab - Project Proposal",
    "section": "",
    "text": "Important\n\n\n\nThis lab is due October 20th at 11:59pm."
  },
  {
    "objectID": "labs/lab-proposal.html#data-sets-that-can-not-be-used",
    "href": "labs/lab-proposal.html#data-sets-that-can-not-be-used",
    "title": "Lab - Project Proposal",
    "section": "Data sets that can not be used",
    "text": "Data sets that can not be used\n– Data sets that have been used for class examples or assignments.\n– Data sets from Kaggle.\n– Data sets analyzed in another course.\nThere will be limits on the number of groups that can use a given data set, so I encourage you to be creative!\nSome resources that may be helpful:\n– R Data Sources for Regression Analysis\n– FiveThirtyEight\n– TidyTuesday\nAdditions:\n– World Health Organization\n– The National Bureau of Economic Research\n– International Monetary Fund\n– General Social Survey\n– United Nations Data\n– United Nations Statistics Division\n– U.K. Data\n– U.S. Data\n– U.S. Census Data\n– European Statistics\n– Statistics Canada\n– Pew Research\n– UNICEF\n– CDC\n– World Bank\n– Election Studies\nAll analyses must be done in RStudio, and your final written report and analysis must be reproducible. This means that you must create a Quarto document attached to a GitHub repository that will create your written report exactly upon rendering."
  },
  {
    "objectID": "labs/lab-proposal.html#introduction-and-data",
    "href": "labs/lab-proposal.html#introduction-and-data",
    "title": "Lab - Project Proposal",
    "section": "Introduction and Data",
    "text": "Introduction and Data\n(a) Choose three substantially different data sets you are interested in analyzing. You must scrape at least 1 data set for your project proposal. For each, identify the components below.\nFor each data set, include the following:\n– Identify the source of the data,\n– When and how it was originally collected (by the original data curator, not necessarily how you found the data)\n– A brief description of the observations"
  },
  {
    "objectID": "labs/lab-proposal.html#research-question",
    "href": "labs/lab-proposal.html#research-question",
    "title": "Lab - Project Proposal",
    "section": "Research question",
    "text": "Research question\n(b) Your research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nTarget population.\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following\n– A well thought out formulated research question. You may include more than one research question if you want to receive feedback on different ideas for your project. However, 1 per data set is required.\n– Describe the research topic along with a concise statement of your hypotheses.\n– Identify the types of variables in your research question. Categorical? Quantitative?"
  },
  {
    "objectID": "labs/lab-proposal.html#data-set",
    "href": "labs/lab-proposal.html#data-set",
    "title": "Lab - Project Proposal",
    "section": "Data set",
    "text": "Data set\n(c) For each data set, include the following\n– Use the glimpse function to provide a glimpse of the data set.\n– Place the file containing your data in the data folder of the project repo\n\nNotes\n– It is critical to check feedback on your project proposal. Even if you earn a 10, it may not mean that your proposal is perfect.\n– You must use one of the data sets in the proposal for the final project, unless instructed otherwise when given feedback."
  },
  {
    "objectID": "prepare/08-31.html",
    "href": "prepare/08-31.html",
    "title": "Prepare",
    "section": "",
    "text": "Watch: Meet the toolkit\nRead:\n\nR for Data Science: Chapter 1 - Introduction\nIntro to Modern Data Science: Chapter 1 - Hello data\n\nIf you haven’t yet done so:\n\nJoin the course Slack using the invitation link in your email.\nComplete the Getting to know you survey.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "prepare/09-05.html",
    "href": "prepare/09-05.html",
    "title": "Prepare",
    "section": "",
    "text": "Read:\n\nR4DS: Chp 2 - Data visualization - Sections 2.1 and 2.4\n\nIf you haven’t yet done so:\n\nEdit the GitHub username document (on Sakai) to ensure your name is correct\nRead the syllabus!\nComplete the Getting to know you survey\nGet a GitHub account if you don’t have one (some advice for choosing a username here)\nJoin the course Slack using the invitation link in your email.\nReserve a STA 198-199 container at https://cmgr.oit.duke.edu/containers."
  },
  {
    "objectID": "prepare/09-07.html",
    "href": "prepare/09-07.html",
    "title": "Prepare",
    "section": "",
    "text": "Read:\n\nIMS: Chp 4 - Exploring categorical data\nIMS: Chp 5 - Exploring numerical data\n\nWatch:\n\nVisualizing numerical data\nVisualizing categorical data"
  },
  {
    "objectID": "prepare/09-08.html",
    "href": "prepare/09-08.html",
    "title": "Prepare",
    "section": "",
    "text": "Read:\n\nR4DS: Chp 2 - Data visualization - Sections 2.5 - 2.10\n\nWatch:\n\nData and visualization\nVisualising data with ggplot2"
  },
  {
    "objectID": "prepare/09-19.html",
    "href": "prepare/09-19.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-21.html",
    "href": "prepare/09-21.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-22.html",
    "href": "prepare/09-22.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR4DS: Chp 6 - Data tidying (Sections 6.1 and 6.2)\nTidy Data by Hadley Wickham"
  },
  {
    "objectID": "prepare/09-26.html",
    "href": "prepare/09-26.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-28.html",
    "href": "prepare/09-28.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/09-29.html",
    "href": "prepare/09-29.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nR4DS: Chp 14 - Numbers (Sections 14.1, 14.2, and 14.4)\nR4DS: Chp 15 - Strings (Sections 15.1 - 15.3)"
  },
  {
    "objectID": "prepare/10-03-p2.html",
    "href": "prepare/10-03-p2.html",
    "title": "Prepare",
    "section": "",
    "text": "The Guardian - Cambridge Analytica whistleblower\nJoy Buolamwini - How I’m fighting bias in algorithms\nCathy O’Neil - Weapons of Math Destruction\nSafiya Umoja Noble - Imagining a Future Free from the Algorithms of Oppression\nKristian Lum - What’s An Algorithm Got To Do With It"
  },
  {
    "objectID": "prepare/10-03.html",
    "href": "prepare/10-03.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nModern Data Science with R: Chp 8\n\n⌨️ Watch:\n\nMisrepresentation\nOptional (but highly recommended) videos:\n\nAlberto Cairo - How charts lie"
  },
  {
    "objectID": "prepare/10-05.html",
    "href": "prepare/10-05.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-12.html",
    "href": "prepare/10-12.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-17.html",
    "href": "prepare/10-17.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-19.html",
    "href": "prepare/10-19.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/10-20.html",
    "href": "prepare/10-20.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS: Chp 2 - Study Design\n\n📖 Read (Optional / Recommended):\n\nIS: Chp 23 - Probability (Section 23.1 - 23.2) ::: callout-note Videos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class. :::"
  },
  {
    "objectID": "prepare/10-24.html",
    "href": "prepare/10-24.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS :: Chp 7 - Linear regression with a single predictor\n\n⌨️ Watch:\n\nUnit 4 - Deck 2: Fitting and interpreting models\nUnit 4 - Deck 3: Modelling nonlinear relationships\n\n::: callout-note Videos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class. :::"
  },
  {
    "objectID": "prepare/10-26.html",
    "href": "prepare/10-26.html",
    "title": "Prepare",
    "section": "",
    "text": "📖 Read:\n\nIMS :: Chp 8 - Linear regression with multiple predictors\n\n⌨️ Watch:\n\nUnit 4 - Deck 4: Models with multiple predictors\nUnit 4 - Deck 5: More models with multiple predictors\n\n::: callout-note Videos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class. :::"
  },
  {
    "objectID": "prepare/10-31.html",
    "href": "prepare/10-31.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/11-02.html",
    "href": "prepare/11-02.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/9-12.html",
    "href": "prepare/9-12.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/9-14.html",
    "href": "prepare/9-14.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "prepare/9-15.html",
    "href": "prepare/9-15.html",
    "title": "Prepare",
    "section": "",
    "text": "Note\n\n\n\nVideos use the “old school” pipe (%>%) but we’ll be using the newer (|>) pipe operator in class."
  },
  {
    "objectID": "project-description.html",
    "href": "project-description.html",
    "title": "Project description",
    "section": "",
    "text": "Proposal due Thur, Oct 20\nDraft 1 due M, Nov 7\nDraft 2 due Tue, Nov 29 (optional)\nPeer review due Wed, Nov 30\nPresentation + slides and final GitHub repo due Mon, Dec 5\nPresentation comments due Thu, Dec 8\nFinal report due Thu, Dec 8"
  },
  {
    "objectID": "project-description.html#criteria-for-datasets",
    "href": "project-description.html#criteria-for-datasets",
    "title": "Project description",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 500 observations (or approved by me)\nAt least 8 columns (or approved by me)\nAt least 6 of the columns must be useful and unique explanatory variables (or approved by me)\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in any course materials, or any derivation of data that has been used in course materials.\nWe strongly recommend curating at least one of your datasets via web scraping.\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements."
  },
  {
    "objectID": "project-description.html#resources-for-datasets",
    "href": "project-description.html#resources-for-datasets",
    "title": "Project description",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)"
  },
  {
    "objectID": "project-description.html#proposal-components",
    "href": "project-description.html#proposal-components",
    "title": "Project description",
    "section": "Proposal components",
    "text": "Proposal components\nFor each data set, include the following:\n\nIntroduction and data\nFor each data set:\n\nIdentify the source of the data.\nState when and how it was originally collected (by the original data curator, not necessarily how you found the data).\nWrite a brief description of the observations.\nAddress ethical concerns about the data, if any.\n\n\n\nResearch question\nYour research question should contain at least three variables, and should be a mix of categorical and quantitative variables. When writing a research question, please think about the following:\n\nWhat is your target population?\nIs the question original?\nCan the question be answered?\n\nFor each data set, include the following:\n\nA well formulated research question. (You may include more than one research question if you want to receive feedback on different ideas for your project. However, one per data set is required.)\nStatement on why this question is important.\nA description of the research topic along with a concise statement of your hypotheses on this topic.\nIdentify the types of variables in your research question. Categorical? Quantitative?\n\n\n\nGlimpse of data\nFor each data set:\n\nPlace the file containing your data in the data folder of the project repo.\nUse the glimpse() function to provide a glimpse of the data set."
  },
  {
    "objectID": "project-description.html#proposal-grading",
    "href": "project-description.html#proposal-grading",
    "title": "Project description",
    "section": "Proposal grading",
    "text": "Proposal grading\n\n\n\nTotal\n10 pts\n\n\n\n\nIntroduction and data\n3\n\n\nResearch question\n3\n\n\nGlimpse of data\n3\n\n\nWorkflow and formatting\n1\n\n\n\nEach component will be graded as follows:\n\nMeets expectations (full credit): All required elements are completed and are accurate. The narrative is written clearly, all tables and visualizations are nicely formatted, and the work would be presentable in a professional setting.\nClose to expectations (half credit): There are some elements missing and/or inaccurate. There are some issues with formatting.\nDoes not meet expectations (no credit): Major elements missing. Work is not neatly formatted and would not be presentable in a professional setting.\n\nIt is critical to check feedback on your project proposal. Even if you earn full credit, it may not mean that your proposal is perfect."
  },
  {
    "objectID": "project-description.html#draft-components",
    "href": "project-description.html#draft-components",
    "title": "Project description",
    "section": "Draft components",
    "text": "Draft components\n\nIntroduction and data\nThe introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and hypotheses.\nThen identify the source of the data, when and how it was collected, the cases, a general description of relevant variables.\n\n\nMethodology\nThe methodology section should include visualizations and summary statistics relevant to your research question. You should also justify the choice of statistical method(s) used to answer your research question.\n\n\nResults\nShowcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not better."
  },
  {
    "objectID": "project-description.html#draft-grading",
    "href": "project-description.html#draft-grading",
    "title": "Project description",
    "section": "Draft grading",
    "text": "Draft grading\nYour first draft will be reviewed and graded by your TAs. We recommend you incorporate their suggestions into your second (optional) draft before the second round of feedback by your peers."
  },
  {
    "objectID": "project-description.html#process-and-questions",
    "href": "project-description.html#process-and-questions",
    "title": "Project description",
    "section": "Process and questions",
    "text": "Process and questions\nSpend ~30 mins to review each team’s project.\n\nFind your team name on the Reviewer 1 and Reviewer 2 columns.\nFor each of the columns, find the name of the team to review in the Team being reviewed column. You should already have access to this team’s repo.\nOpen the repo of the team you’re reviewing, read their project draft, and browser around the rest of their repo.\nThen, go to the Issues tab in that repo, click on New issue, and click on Get started for the Peer review issue. Fill out this issue, answering the following questions:\n\nPeer review by: [NAME OF TEAM DOING THE REVIEW]\nNames of team members that participated in this review: [FULL NAMES OF TEAM MEMBERS DOING THE REVIEW]\nDescribe the goal of the project.\nDescribe the data used or collected, if any. If the proposal does not include the use of a specific dataset, comment on whether the project would be strengthened by the inclusion of a dataset.\nDescribe the approaches, tools, and methods that will be used.\nIs there anything that is unclear from the proposal?\nProvide constructive feedback on how the team might be able to improve their project. Make sure your feedback includes at least one comment on the statistical modeling aspect of the project, but do feel free to comment on aspects beyond the modeling.\nWhat aspect of this project are you most interested in and would like to see highlighted in the presentation.\nProvide constructive feedback on any issues with file and/or code organization.\n(Optional) Any further comments or feedback?"
  },
  {
    "objectID": "project-description.html#peer-review-grading",
    "href": "project-description.html#peer-review-grading",
    "title": "Project description",
    "section": "Peer review grading",
    "text": "Peer review grading\nPeer reviews will be graded on the extent to which it comprehensively and constructively addresses the components of the partner team’s report: the research context and motivation, exploratory data analysis, and any inference, modeling, or conclusions."
  },
  {
    "objectID": "project-description.html#report-components",
    "href": "project-description.html#report-components",
    "title": "Project description",
    "section": "Report components",
    "text": "Report components\n\nIntroduction and data\nThis section includes an introduction to the project motivation, data, and research question. Describe the data and definitions of key variables. It should also include some exploratory data analysis. All of the EDA won’t fit in the paper, so focus on the EDA for the response variable and a few other interesting variables and relationships.\n\nGrading criteria\nThe research question and motivation are clearly stated in the introduction, including citations for the data source and any external research. The data are clearly described, including a description about how the data were originally collected and a concise definition of the variables relevant to understanding the report. The data cleaning process is clearly described, including any decisions made in the process (e.g., creating new variables, removing observations, etc.) The explanatory data analysis helps the reader better understand the observations in the data along with interesting and relevant relationships between the variables. It incorporates appropriate visualizations and summary statistics.\n\n\n\nMethodology\nThis section includes a brief description of your modeling process. Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.\n\nGrading criteria\nThe analysis steps are appropriate for the data and research question. The group used a thorough and careful approach to select the final model; the approach is clearly described in the report. The model selection process took into account potential interaction effects and addressed any violations in model conditions. The model conditions and diagnostics are thoroughly and accurately assessed for their model. If violations of model conditions are still present, there was a reasonable attempt to address the violations based on the course content.\n\n\n\nResults\nThis is where you will output the final model with any relevant model fit statistics.\nDescribe the key results from the model. The goal is not to interpret every single variable in the model but rather to show that you are proficient in using the model output to address the research questions, using the interpretations to support your conclusions. Focus on the variables that help you answer the research question and that provide relevant context for the reader.\n\nGrading criteria\nThe model fit is clearly assessed, and interesting findings from the model are clearly described. Interpretations of model coefficients are used to support the key findings and conclusions, rather than merely listing the interpretation of every model coefficient. If the primary modeling objective is prediction, the model’s predictive power is thoroughly assessed.\n\n\n\nDiscussion\nIn this section you’ll include a summary of what you have learned about your research question along with statistical arguments supporting your conclusions. In addition, discuss the limitations of your analysis and provide suggestions on ways the analysis could be improved. Any potential issues pertaining to the reliability and validity of your data and appropriateness of the statistical analysis should also be discussed here. Lastly, this section will include ideas for future work.\n\nGrading criteria\nOverall conclusions from analysis are clearly described, and the model results are put into the larger context of the subject matter and original research question. There is thoughtful consideration of potential limitations of the data and/or analysis, and ideas for future work are clearly described.\n\n\n\nOrganization + formatting\nThis is an assessment of the overall presentation and formatting of the written report.\n\nGrading criteria\nThe report neatly written and organized with clear section headers and appropriately sized figures with informative labels. Numerical results are displayed with a reasonable number of digits, and all visualizations are neatly formatted. All citations and links are properly formatted. If there is an appendix, it is reasonably organized and easy for the reader to find relevant information. All code, warnings, and messages are suppressed. The main body of the written report (not including the appendix) is no longer than 10 pages."
  },
  {
    "objectID": "project-description.html#report-grading",
    "href": "project-description.html#report-grading",
    "title": "Project description",
    "section": "Report grading",
    "text": "Report grading\nThe written report is worth 40 points, broken down as follows\n\n\n\nTotal\n40 pts\n\n\n\n\nIntroduction/data\n6 pts\n\n\nMethodology\n10 pts\n\n\nResults\n14 pts\n\n\nDiscussion\n6 pts\n\n\nOrganization + formatting\n4 pts"
  },
  {
    "objectID": "project-description.html#slides",
    "href": "project-description.html#slides",
    "title": "Project description",
    "section": "Slides",
    "text": "Slides\nIn addition to the written report, your team will also create presentation slides and record a video presentation that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and discuss the primary conclusions. These slides should serve as a brief visual addition to your written report and will be graded for content and quality.\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.). We recommend choosing an option that’s easy to collaborate with, e.g., Google Slides.\n\n\n\n\n\n\nNote\n\n\n\nYou can also use Quarto to make your slides! While we won’t be covering making slides with Quarto in the class, we would be happy to help you with it in office hours. It’s no different than writing other documents with Quarto, so the learning curve will not be steep!\n\n\nThe slide deck should have no more than 6 content slides + 1 title slide. Here is a suggested outline as you think through the slides; you do not have to use this exact format for the 6 slides.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3: Highlights from EDA\nSlide 4-5: Inference/modeling/other analysis\nSlide 6: Conclusions + future work"
  },
  {
    "objectID": "project-description.html#presentation",
    "href": "project-description.html#presentation",
    "title": "Project description",
    "section": "Presentation",
    "text": "Presentation\nPresentations will take place in class during the last lab of the semester. The presentation must be no longer than 5 minutes. You can choose to present live in class (recommended) or pre-record a video to be shown in class. Either way you must attend the lab session for the Q&A following your presentation.\nIf you choose to pre-record your presentation, you may use can use any platform that works best for your group to record your presentation. Below are a few resources on recording videos:\n\nRecording presentations in Zoom\nApple Quicktime for screen recording\nWindows 10 built-in screen recording functionality\nKap for screen recording\n\nOnce your video is ready, upload the video to Warpwire or another video platform (e.g., YouTube), then add a link to your video in your repo README.\nTo upload your video to Warpwire:\n\nClick the Warpwire tab in the course Sakai site.\nClick the “+” and select “Upload files”.\nLocate the video on your computer and click to upload.\nOnce you’ve uploaded the video to Warpwire, click to share the video and copy the video’s URL. You will need this when you post the video in the discussion forum."
  },
  {
    "objectID": "project-description.html#reproducibility-organization",
    "href": "project-description.html#reproducibility-organization",
    "title": "Project description",
    "section": "Reproducibility + organization",
    "text": "Reproducibility + organization\nAll written work (with exception of presentation slides) should be reproducible, and the GitHub repo should be neatly organized.\nPoints for reproducibility + organization will be based on the reproducibility of the written report and the organization of the project GitHub repo. The repo should be neatly organized as described above, there should be no extraneous files, all text in the README should be easily readable."
  },
  {
    "objectID": "project-description.html#teamwork",
    "href": "project-description.html#teamwork",
    "title": "Project description",
    "section": "Teamwork",
    "text": "Teamwork\nYou will be asked to fill out a survey where you rate the contribution and teamwork of each team member by assigning a contribution percentage for each team member. Filling out the survey is a prerequisite for getting credit on the team member evaluation. If you are suggesting that an individual did less than half the expected contribution given your team size (e.g., for a team of four students, if a student contributed less than 12.5% of the total effort), please provide some explanation. If any individual gets an average peer score indicating that this was the case, their grade will be assessed accordingly and penalties may apply beyond the teamwork component of the grade.\nIf you have concerns with the teamwork and/or contribution from any team members, please email me by the project presentation deadline. You only need to email me if you have concerns. Otherwise, I will assume everyone on the team equally contributed and will receive full credit for the teamwork portion of the grade."
  },
  {
    "objectID": "project-description.html#grading-summary",
    "href": "project-description.html#grading-summary",
    "title": "Project description",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort."
  },
  {
    "objectID": "project-description.html#late-work-policy",
    "href": "project-description.html#late-work-policy",
    "title": "Project description",
    "section": "Late work policy",
    "text": "Late work policy\nThere is no late work accepted on this project. Be sure to turn in your work early to avoid any technological mishaps."
  },
  {
    "objectID": "project-tips-resources.html",
    "href": "project-tips-resources.html",
    "title": "Project tips + resources",
    "section": "",
    "text": "To be posted."
  },
  {
    "objectID": "slides/01-welcome-199.html#syllabus",
    "href": "slides/01-welcome-199.html#syllabus",
    "title": "Welcome to STA 199",
    "section": "Syllabus",
    "text": "Syllabus\nsta199-f22-2.github.io/"
  },
  {
    "objectID": "slides/01-welcome-199.html#goals-for-day-1",
    "href": "slides/01-welcome-199.html#goals-for-day-1",
    "title": "Welcome to STA 199",
    "section": "Goals for Day 1",
    "text": "Goals for Day 1\n\nGet to know the professor & ta\nGet to know each other\nCourse overview\nRegister with GitHub & Slack\nIntroduce R + start thinking about data"
  },
  {
    "objectID": "slides/01-welcome-199.html#who-am-i",
    "href": "slides/01-welcome-199.html#who-am-i",
    "title": "Welcome to STA 199",
    "section": "Who Am I?",
    "text": "Who Am I?"
  },
  {
    "objectID": "slides/01-welcome-199.html#who-are-you",
    "href": "slides/01-welcome-199.html#who-are-you",
    "title": "Welcome to STA 199",
    "section": "Who Are You?",
    "text": "Who Are You?\nPlease share with your neighbors:\n\nMajor\nYear\nWhy you taking the course\nWhat other courses are you taking\nAnything else"
  },
  {
    "objectID": "slides/01-welcome-199.html#our-classroom",
    "href": "slides/01-welcome-199.html#our-classroom",
    "title": "Welcome to STA 199",
    "section": "Our Classroom",
    "text": "Our Classroom\n\nCommunity\nCommunication\nRespect"
  },
  {
    "objectID": "slides/01-welcome-199.html#what-is-data-science",
    "href": "slides/01-welcome-199.html#what-is-data-science",
    "title": "Welcome to STA 199",
    "section": "What is data science?",
    "text": "What is data science?\n“Data science is a concept to unify statistics, data analysis, machine learning and their related methods in order to understand and analyze actual phenomena with data. It employs techniques and theories drawn from many fields within the context of mathematics, statistics, information science, and computer science.”\n-Wikipedia"
  },
  {
    "objectID": "slides/01-welcome-199.html#examples-of-data-science",
    "href": "slides/01-welcome-199.html#examples-of-data-science",
    "title": "Welcome to STA 199",
    "section": "Examples of data science",
    "text": "Examples of data science\n\nIdentification and prediction of disease\nTargeted advertising\nSupply chain optimization\nSports recruitment + strategist\nThe list goes on and on….."
  },
  {
    "objectID": "slides/01-welcome-199.html#jobs",
    "href": "slides/01-welcome-199.html#jobs",
    "title": "Welcome to STA 199",
    "section": "Jobs",
    "text": "Jobs"
  },
  {
    "objectID": "slides/01-welcome-199.html#jobs-1",
    "href": "slides/01-welcome-199.html#jobs-1",
    "title": "Welcome to STA 199",
    "section": "Jobs",
    "text": "Jobs"
  },
  {
    "objectID": "slides/01-welcome-199.html#data-literacy",
    "href": "slides/01-welcome-199.html#data-literacy",
    "title": "Welcome to STA 199",
    "section": "Data literacy",
    "text": "Data literacy"
  },
  {
    "objectID": "slides/01-welcome-199.html#course-objectives",
    "href": "slides/01-welcome-199.html#course-objectives",
    "title": "Welcome to STA 199",
    "section": "Course objectives",
    "text": "Course objectives\n\nLearn to explore, visualize, and analyze data in a reproducible and shareable manner\nGain experience in data wrangling, exploratory data analysis, predictive modeling, and data visualization\nWork on problems and case studies inspired by and based on real-world questions and data\nLearn to effectively communicate results through written assignments and final project presentation"
  },
  {
    "objectID": "slides/01-welcome-199.html#some-of-what-you-will-learn",
    "href": "slides/01-welcome-199.html#some-of-what-you-will-learn",
    "title": "Welcome to STA 199",
    "section": "Some of what you will learn",
    "text": "Some of what you will learn\n\n\n\n\n\n– Fundamentals of R\n– Data visualization\n– Web scraping\n– Version control with GitHub\n\n– Reproducible reports with Quarto\n– Regression and classification\n– Statistical inference"
  },
  {
    "objectID": "slides/01-welcome-199.html#r---figures",
    "href": "slides/01-welcome-199.html#r---figures",
    "title": "Welcome to STA 199",
    "section": "R - figures",
    "text": "R - figures\n\n\n\n\n\n\n\n\n\n\nFigure 1: Example R Figures"
  },
  {
    "objectID": "slides/01-welcome-199.html#r---apps",
    "href": "slides/01-welcome-199.html#r---apps",
    "title": "Welcome to STA 199",
    "section": "R - apps",
    "text": "R - apps"
  },
  {
    "objectID": "slides/01-welcome-199.html#r",
    "href": "slides/01-welcome-199.html#r",
    "title": "Welcome to STA 199",
    "section": "R",
    "text": "R\n\n\n\n\n\n\nNote\n\n\n This is a new language"
  },
  {
    "objectID": "slides/01-welcome-199.html#workflow",
    "href": "slides/01-welcome-199.html#workflow",
    "title": "Welcome to STA 199",
    "section": "Workflow",
    "text": "Workflow\nBefore Class\n\nWatch lecture content videos\n\nDuring Class\n\nWarm up question\nMix of lecture and interaction"
  },
  {
    "objectID": "slides/01-welcome-199.html#please-bring-your-laptops-if-able",
    "href": "slides/01-welcome-199.html#please-bring-your-laptops-if-able",
    "title": "Welcome to STA 199",
    "section": "Please bring your laptops if able",
    "text": "Please bring your laptops if able"
  },
  {
    "objectID": "slides/01-welcome-199.html#activities-and-assessments",
    "href": "slides/01-welcome-199.html#activities-and-assessments",
    "title": "Welcome to STA 199",
    "section": "Activities and assessments",
    "text": "Activities and assessments\n\nHomework: Individual assignments combining conceptual and computational skills.\nLabs: Individual or team assignments focusing on computational skills.\nExams: Two take-home exams.\nFinal Project: Team project presented during the final exam period.\nApplication Exercises: Exercises worked on during the live lecture session.\nStatistics Experiences: Engage with statistics outside of the classroom and reflect on your experience."
  },
  {
    "objectID": "slides/01-welcome-199.html#lab",
    "href": "slides/01-welcome-199.html#lab",
    "title": "Welcome to STA 199",
    "section": "Lab",
    "text": "Lab\n\nFocus on computing using R tidyverse syntax\nApply concepts from lecture to case study scenarios\nWork on labs individually or in teams of 3 - 4"
  },
  {
    "objectID": "slides/01-welcome-199.html#textbooks-and-readings",
    "href": "slides/01-welcome-199.html#textbooks-and-readings",
    "title": "Welcome to STA 199",
    "section": "Textbooks and readings",
    "text": "Textbooks and readings\n\nR for Data Science by Grolemund & Wickham (2nd ed. O’Reilly)\nIntroduction to Modern Statistics by Cetinkaya-Rundel & Hardin (1st ed. OpenIntro)"
  },
  {
    "objectID": "slides/01-welcome-199.html#where-to-find-help-in-the-course",
    "href": "slides/01-welcome-199.html#where-to-find-help-in-the-course",
    "title": "Welcome to STA 199",
    "section": "Where to find help in the course",
    "text": "Where to find help in the course\n\nAttend Office hours to meet with a member of the teaching team\nEmail me to set up a time: esm70@duke.edu"
  },
  {
    "objectID": "slides/01-welcome-199.html#academic-resource-center",
    "href": "slides/01-welcome-199.html#academic-resource-center",
    "title": "Welcome to STA 199",
    "section": "Academic Resource Center",
    "text": "Academic Resource Center\nThe Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke.\nServices include:\n– Learning Consultations\n– Peer Tutoring and Study Groups\n– ADHD/LD Coaching, Outreach Workshops and more\nContact the ARC at ARC@duke.edu or call 919-684-5917 to schedule an appointment."
  },
  {
    "objectID": "slides/01-welcome-199.html#create-a-github-account-why",
    "href": "slides/01-welcome-199.html#create-a-github-account-why",
    "title": "Welcome to STA 199",
    "section": "Create a GitHub account (Why?)",
    "text": "Create a GitHub account (Why?)\nGitHub, Inc., is an Internet hosting service for software development and version control."
  },
  {
    "objectID": "slides/01-welcome-199.html#create-a-github-account",
    "href": "slides/01-welcome-199.html#create-a-github-account",
    "title": "Welcome to STA 199",
    "section": "Create a GitHub account",
    "text": "Create a GitHub account\nPlease do this before the Getting to know you survey\nGo to https://github.com/, and create an account (unless you already have one).\nSome tips from Happy Git with R.\n– Incorporate your actual name! – Reuse your username from other contexts if you can, e. g., Twitter or Slack. – Pick a username you will be comfortable revealing to your future boss. – Be as unique as possible in as few characters as possible. Shorter is better than longer. – Avoid words with special meaning in programming (e.g. NA)."
  },
  {
    "objectID": "slides/01-welcome-199.html#slack",
    "href": "slides/01-welcome-199.html#slack",
    "title": "Welcome to STA 199",
    "section": "Slack",
    "text": "Slack\nPlease click the Slack link located here or in Sakai announcements to be a part of the discussions!"
  },
  {
    "objectID": "slides/01-welcome-199.html#r-studio",
    "href": "slides/01-welcome-199.html#r-studio",
    "title": "Welcome to STA 199",
    "section": "R-Studio",
    "text": "R-Studio\n– Reserve a STA198-1991 RStudio container – Go to https://vm-manage.oit.duke.edu/containers – Click Reserve Container for the STA198-199 container"
  },
  {
    "objectID": "slides/01-welcome-199.html#our-turn",
    "href": "slides/01-welcome-199.html#our-turn",
    "title": "Welcome to STA 199",
    "section": "Our Turn",
    "text": "Our Turn\nClone a repo so you have access to the qmd"
  },
  {
    "objectID": "slides/01-welcome-199.html#for-wednesday",
    "href": "slides/01-welcome-199.html#for-wednesday",
    "title": "Welcome to STA 199",
    "section": "For Wednesday",
    "text": "For Wednesday\n– We’ll start talking about the computing toolkit\n– Watch videos for Wednesday\n– Complete Getting to Know You Survey\nPlease bring laptop to class if able for next time!\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-thursday-prep",
    "href": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-thursday-prep",
    "title": "Welcome to STA 199",
    "section": "GitHub Commands: Pull Commit Push (Thursday Prep)",
    "text": "GitHub Commands: Pull Commit Push (Thursday Prep)"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-thursday-prep-1",
    "href": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-thursday-prep-1",
    "title": "Welcome to STA 199",
    "section": "GitHub Commands: Pull Commit Push (Thursday Prep)",
    "text": "GitHub Commands: Pull Commit Push (Thursday Prep)"
  },
  {
    "objectID": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-thursday-prep-2",
    "href": "slides/02-Meet-the-toolkit.html#github-commands-pull-commit-push-thursday-prep-2",
    "title": "Welcome to STA 199",
    "section": "GitHub Commands: Pull Commit Push (Thursday Prep)",
    "text": "GitHub Commands: Pull Commit Push (Thursday Prep)"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#goals-for-today",
    "href": "slides/03-Grammer-of-Graphics.html#goals-for-today",
    "title": "Grammer of Graphics",
    "section": "Goals for today",
    "text": "Goals for today\n– Think about what to do (and not to do) with visualizations\n– Understand the fundamentals of ggplot\n– Build appropriate visualizations\n– More practice with R"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#announcements",
    "href": "slides/03-Grammer-of-Graphics.html#announcements",
    "title": "Grammer of Graphics",
    "section": "Announcements",
    "text": "Announcements\n– Turn in AE’s via GitHub (will go over today)\n– Will turn in Lab 1 via GitHub (Thursday)\n– Release HW 1 Wednesday (Turned in on Gradescope: Being set up now)"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#prepare-reading-questions",
    "href": "slides/03-Grammer-of-Graphics.html#prepare-reading-questions",
    "title": "Grammer of Graphics",
    "section": "Prepare Reading Questions",
    "text": "Prepare Reading Questions\nhttps://app.sli.do/event/g6fnKCDuZ1sw8NKiZTu3Rb"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#reading-highlights",
    "href": "slides/03-Grammer-of-Graphics.html#reading-highlights",
    "title": "Grammer of Graphics",
    "section": "Reading Highlights",
    "text": "Reading Highlights\n– Sometimes you’ll run the code and nothing happens. Check the left-hand of your console: if it’s a +, it means that R doesn’t think you’ve typed a complete expression and it’s waiting for you to finish it."
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#examining-data-visualization",
    "href": "slides/03-Grammer-of-Graphics.html#examining-data-visualization",
    "title": "Grammer of Graphics",
    "section": "Examining data visualization",
    "text": "Examining data visualization\n\n\n\n\n\nDiscuss the following for the visualization.\n– What is the visualization trying to show?\n– What is effective, i.e. what is done well?\n– What is ineffective, i.e. what could be improved?\n– What are you curious about after looking at the visualization?\n\n\n\n−+\n04:00\n\n\n\n\n\n\n\nSource: Twitter"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#ae-02-starwars",
    "href": "slides/03-Grammer-of-Graphics.html#ae-02-starwars",
    "title": "Grammer of Graphics",
    "section": "ae-02-starwars",
    "text": "ae-02-starwars\n\nGo to the course GitHub org and find your ae-02-starwars (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today (Thursday by 11:59p ET)."
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#exercises-2.3.1",
    "href": "slides/03-Grammer-of-Graphics.html#exercises-2.3.1",
    "title": "Grammer of Graphics",
    "section": "Exercises 2.3.1",
    "text": "Exercises 2.3.1"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#match-the-variables-to-plots",
    "href": "slides/03-Grammer-of-Graphics.html#match-the-variables-to-plots",
    "title": "Grammer of Graphics",
    "section": "Match the variables to plots",
    "text": "Match the variables to plots\n\n\n– 1 categorical variable, 1 quantitative variable (often ordinal)\n– 2 quantitative variables\n– 1 quantitative variable\n\n\n\n−+\n04:00\n\n\n\n\n– geom_histogram\n– geom_point\n– geom_bar"
  },
  {
    "objectID": "slides/03-Grammer-of-Graphics.html#recap-of-ae",
    "href": "slides/03-Grammer-of-Graphics.html#recap-of-ae",
    "title": "Grammer of Graphics",
    "section": "Recap of AE",
    "text": "Recap of AE\n– Construct plots with ggplot().\n– Layers of ggplots are separated by +s.\n– The formula is (almost) always as follows:\n\nggplot(DATA, aes(x = X-VAR, y = Y-VAR, ...)) +\n  geom_XXX()\n\n– Aesthetic attributes of a geometries (color, size, transparency, etc.) can be mapped to variables in the data or set by the user.\n– Use facet_wrap() when faceting (creating small multiples) by one variable and facet_grid() when faceting by two variables.\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#checklist",
    "href": "slides/04-Visualizing-various-types-of-data.html#checklist",
    "title": "Visualizing various types of data",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n– Go to the course GitHub org and find your ae-03-penguins (repo name will be suffixed with your GitHub name).\n– Clone the repo in your container, open the Quarto document in the repo\n– Reach out if you have questions"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#warm-up-exercises-2.3.1",
    "href": "slides/04-Visualizing-various-types-of-data.html#warm-up-exercises-2.3.1",
    "title": "Visualizing various types of data",
    "section": "Warm up: Exercises 2.3.1",
    "text": "Warm up: Exercises 2.3.1"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#questions-from-chp-4---exploring-categorical-data-chp-5---exploring-numerical-data",
    "href": "slides/04-Visualizing-various-types-of-data.html#questions-from-chp-4---exploring-categorical-data-chp-5---exploring-numerical-data",
    "title": "Visualizing various types of data",
    "section": "Questions from Chp 4 - Exploring categorical data / Chp 5 - Exploring numerical data",
    "text": "Questions from Chp 4 - Exploring categorical data / Chp 5 - Exploring numerical data\nhttps://app.sli.do/event/mX7kxXxd49tL4VS9iwCa2T"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#how-to-turn-aes-via-github",
    "href": "slides/04-Visualizing-various-types-of-data.html#how-to-turn-aes-via-github",
    "title": "Visualizing various types of data",
    "section": "How to turn AE’s via Github",
    "text": "How to turn AE’s via Github\n– render, commit, and push\n\nIf you made any changes since the last render, render again to get the final version of the AE.\nCheck the box next to each document in the Git tab (this is called “staging” the changes). Commit the changes you made using an simple and informative message.\nUse the green arrow to push your changes to your repo on GitHub.\nCheck your repo on GitHub and see the updated files. Once your updated files are in your repo on GitHub, you’re good to go!"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#the-variables-dictate-the-plot",
    "href": "slides/04-Visualizing-various-types-of-data.html#the-variables-dictate-the-plot",
    "title": "Visualizing various types of data",
    "section": "The variables dictate the plot",
    "text": "The variables dictate the plot\n– Assess the relationship between height and weight\n– Investigate the distribution of scores on exam 1\n– Explore 2022 temperatures between Montana and North Carolina\n– Examine if drinking coffee or not impacts the amount of sleep you get (above recommended, at recommended, below recommended)"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#the-variables-dictate-the-plot-1",
    "href": "slides/04-Visualizing-various-types-of-data.html#the-variables-dictate-the-plot-1",
    "title": "Visualizing various types of data",
    "section": "The variables dictate the plot",
    "text": "The variables dictate the plot\n\nAssess the relationship between height and weight - geom_point()\nInvestigate the distribution of scores on exam 1 - geom_histogram() / geom_boxplot\nExplore 2022 temperatures between Montana and North Carolina - geom_histogram / geom_boxplot (with changes in the aes!)\nExamine if drinking coffee or not impacts the amount of sleep you get (above recommended, at recommended, below recommended) - geom_bar (with changes in the aes!)"
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#ae-03",
    "href": "slides/04-Visualizing-various-types-of-data.html#ae-03",
    "title": "Visualizing various types of data",
    "section": "ae-03",
    "text": "ae-03\n\nGo to the course GitHub org and find your ae-03 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/04-Visualizing-various-types-of-data.html#recap-of-ae",
    "href": "slides/04-Visualizing-various-types-of-data.html#recap-of-ae",
    "title": "Visualizing various types of data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nPick geoms based on data types.\nSet appropriate binwidths for histograms.\nTurn off legends when they provide redundant information with show.legend = FALSE.\nTake control of your labels\nUse color to your advantage. https://ggplot2.tidyverse.org/reference/ggtheme.html & https://ggplot2.tidyverse.org/reference/scale_viridis.html\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#checklist",
    "href": "slides/05-grammar-of-data-wrangling.html#checklist",
    "title": "Grammar of data wrangling",
    "section": "Checklist",
    "text": "Checklist\n– Clone your ae-04 repo.\n– Turn in Lab 1 via Gradescope\n– Reach out (OH should all be updated)\n– Reminder: AEs due Thursday and Saturday 11:59; Labs due Monday; HWs due in 1 week from assigned"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#goals",
    "href": "slides/05-grammar-of-data-wrangling.html#goals",
    "title": "Grammar of data wrangling",
    "section": "Goals",
    "text": "Goals\n\nUnderstand why we need to manipulate data\nCalculate summary measures for data sets\nManipulate the format of data\nPractice with tidyverse functions"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#cant-commit",
    "href": "slides/05-grammar-of-data-wrangling.html#cant-commit",
    "title": "Grammar of data wrangling",
    "section": "Can’t Commit?",
    "text": "Can’t Commit?"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#margins",
    "href": "slides/05-grammar-of-data-wrangling.html#margins",
    "title": "Grammar of data wrangling",
    "section": "Margins",
    "text": "Margins\nIn addition, the code should not exceed the 80 character limit, so that all the code can be read when you render to PDF. To help with this, you can add a vertical line at 80 characters by clicking “Tools” “Global Options” “Code” “Display”, then set “Margin Column” to 80, and click “Apply”."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#code-chunk-labels",
    "href": "slides/05-grammar-of-data-wrangling.html#code-chunk-labels",
    "title": "Grammar of data wrangling",
    "section": "Code Chunk Labels",
    "text": "Code Chunk Labels\n– Informative names can help when navigating code.\n– Informative names do not show up in Rendered documents (and that’s okay!)"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#r4ds-chp-4---data-transformation",
    "href": "slides/05-grammar-of-data-wrangling.html#r4ds-chp-4---data-transformation",
    "title": "Grammar of data wrangling",
    "section": "R4DS: Chp 4 - Data transformation",
    "text": "R4DS: Chp 4 - Data transformation\nhttps://app.sli.do/event/56i17rXu3VTsLVtwRZCX9w"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#warm-up",
    "href": "slides/05-grammar-of-data-wrangling.html#warm-up",
    "title": "Grammar of data wrangling",
    "section": "Warm up",
    "text": "Warm up\n\n\n\nWhat is the difference between long and wide data?"
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#ae-04",
    "href": "slides/05-grammar-of-data-wrangling.html#ae-04",
    "title": "Grammar of data wrangling",
    "section": "ae-04",
    "text": "ae-04\n\nGo to the course GitHub org and find your ae-04 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/05-grammar-of-data-wrangling.html#recap-of-ae",
    "href": "slides/05-grammar-of-data-wrangling.html#recap-of-ae",
    "title": "Grammar of data wrangling",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nWe can transform data to learn more about what’s going on\nPipe operator allows us to step through the process and combine multiple functions together\nData are messy. This are valuable tools to tell the story you want\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#checklist",
    "href": "slides/06-working-with-multiple-data-frames.html#checklist",
    "title": "Working with multiple data frames",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n– Clone ae-05\n– Watch ae-04 video + turn in ae-04 by Thursday 11:59pm\n– Turn in hw1 by Thursday 11:59pm on Gradescope"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#r4ds-chp-20---joins---sections-20.1---20.4",
    "href": "slides/06-working-with-multiple-data-frames.html#r4ds-chp-20---joins---sections-20.1---20.4",
    "title": "Working with multiple data frames",
    "section": "R4DS: Chp 20 - Joins - Sections 20.1 - 20.4",
    "text": "R4DS: Chp 20 - Joins - Sections 20.1 - 20.4\n– Any questions from prepare materials?\n\n\nClone your ae-04 repo."
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#announcements",
    "href": "slides/06-working-with-multiple-data-frames.html#announcements",
    "title": "Working with multiple data frames",
    "section": "Announcements",
    "text": "Announcements\nVideos\n– Requesting videos for missed classes\nAEs\n– Ae: 80% rule + keys posted after deadline\nHomework + Labs\n– Late work policy\n– Drop 1"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#joining-datasets",
    "href": "slides/06-working-with-multiple-data-frames.html#joining-datasets",
    "title": "Working with multiple data frames",
    "section": "Joining datasets",
    "text": "Joining datasets\nData merging is the process of combining two or more data sets into a single data set. Most often, this process is necessary when you have raw data stored in multiple files, worksheets, or data tables, that you want to analyze together."
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#ae-05",
    "href": "slides/06-working-with-multiple-data-frames.html#ae-05",
    "title": "Working with multiple data frames",
    "section": "AE-05",
    "text": "AE-05\nClone ae-05"
  },
  {
    "objectID": "slides/06-working-with-multiple-data-frames.html#recap-of-ae",
    "href": "slides/06-working-with-multiple-data-frames.html#recap-of-ae",
    "title": "Working with multiple data frames",
    "section": "Recap of AE",
    "text": "Recap of AE\n– This is important! Data are messy!\n– Think carfully about the join you use\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/07-tidying-data.html#checklist",
    "href": "slides/07-tidying-data.html#checklist",
    "title": "Tidying data",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n\nOpen your ae-06 project in RStudio (that you already started on Tuesday), render your document, and commit and push.\nAny questions from prepare materials? Go to slido. You can also upvote others’ questions.\nLab 02 Due Tonight.\nStart Early. Render Often. Ask Questions.\nGroups are coming after Exam 1."
  },
  {
    "objectID": "slides/07-tidying-data.html#goals",
    "href": "slides/07-tidying-data.html#goals",
    "title": "Tidying data",
    "section": "Goals:",
    "text": "Goals:\n– Understand pivot_longer\n– ggplot practice\n– Practice re-creating graphs\n– “New” functions: if_else / scale_continuous_x"
  },
  {
    "objectID": "slides/07-tidying-data.html#warm-up-tidying-datasets",
    "href": "slides/07-tidying-data.html#warm-up-tidying-datasets",
    "title": "Tidying data",
    "section": "Warm Up: Tidying datasets",
    "text": "Warm Up: Tidying datasets\nWhat makes a dataset “tidy”?\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "slides/07-tidying-data.html#tidy-data",
    "href": "slides/07-tidying-data.html#tidy-data",
    "title": "Tidying data",
    "section": "Tidy Data",
    "text": "Tidy Data\nThere are three interrelated rules that make a dataset tidy:\n\nEach variable is a column; each column is a variable.\nEach observation is row; each row is an observation.\nEach value is a cell; each cell is a single value."
  },
  {
    "objectID": "slides/07-tidying-data.html#ae-06",
    "href": "slides/07-tidying-data.html#ae-06",
    "title": "Tidying data",
    "section": "ae-06",
    "text": "ae-06\n\nGo to the course GitHub org and find your ae-06 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/07-tidying-data.html#recap-of-ae",
    "href": "slides/07-tidying-data.html#recap-of-ae",
    "title": "Tidying data",
    "section": "Recap of AE",
    "text": "Recap of AE\n\nWhen pivoting longer, variable names that turn into values are characters by default. If you need them to be in another format, you need to explicitly make that transformation, which you can do so within the pivot_longer() function.\nYou can tweak a plot forever, but at some point the tweaks are likely not very productive. However, you should always be critical of defaults (however pretty they might be) and see if you can improve the plot to better portray your data / results / what you want to communicate.\npivot_wider() which makes datasets wider by increasing columns and reducing rows. pivot_wider() has the opposite interface to pivot_longer(): we need to provide the existing columns that define the values (values_from) and the column name (names_from).\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/08-tidying-data.html#checklist",
    "href": "slides/08-tidying-data.html#checklist",
    "title": "Types and Classes",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n\nOpen your ae-07 project in RStudio.\nHW2 Due Tomorrow.\nExam 1 is coming (next week!)"
  },
  {
    "objectID": "slides/08-tidying-data.html#announcements",
    "href": "slides/08-tidying-data.html#announcements",
    "title": "Types and Classes",
    "section": "Announcements",
    "text": "Announcements\n– Regrade requests\n– Be detailed\n– Ask clarification questions in Slack\n– Single pipeline"
  },
  {
    "objectID": "slides/08-tidying-data.html#goals",
    "href": "slides/08-tidying-data.html#goals",
    "title": "Types and Classes",
    "section": "Goals:",
    "text": "Goals:\n– Understand how R treats data\n– ggplot practice\n– Practice re-creating graphs"
  },
  {
    "objectID": "slides/08-tidying-data.html#prep-questions",
    "href": "slides/08-tidying-data.html#prep-questions",
    "title": "Types and Classes",
    "section": "Prep Questions",
    "text": "Prep Questions\nSlido"
  },
  {
    "objectID": "slides/08-tidying-data.html#warm-up-types-of-variables",
    "href": "slides/08-tidying-data.html#warm-up-types-of-variables",
    "title": "Types and Classes",
    "section": "Warm Up: Types of variables",
    "text": "Warm Up: Types of variables\n\n\n\n−+\n03:00\n\n\n\nCategorical or quantitative?\n– Zipcode\n– Ounces of water drank\n– Height of students (measured tall / short)\n– Hours spent playing video games"
  },
  {
    "objectID": "slides/08-tidying-data.html#types-and-classes",
    "href": "slides/08-tidying-data.html#types-and-classes",
    "title": "Types and Classes",
    "section": "Types and Classes",
    "text": "Types and Classes\n– Type is how an object is stored in memory.\n\ndouble: a real number stored in “double-precision floatint point format.”\ninteger: an integer (positive or negative).\n\n– Class is metadata about the object that can determine how common functions operate on that object."
  },
  {
    "objectID": "slides/08-tidying-data.html#types-and-classes-1",
    "href": "slides/08-tidying-data.html#types-and-classes-1",
    "title": "Types and Classes",
    "section": "Types and Classes",
    "text": "Types and Classes\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nChanging the type of a variable changes it’s class, and how functions oberate on the object. We will get practice with this in the application exercise."
  },
  {
    "objectID": "slides/08-tidying-data.html#ae-07",
    "href": "slides/08-tidying-data.html#ae-07",
    "title": "Types and Classes",
    "section": "ae-07",
    "text": "ae-07\n\nGo to the course GitHub org and find your ae-07 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/08-tidying-data.html#recap-of-ae",
    "href": "slides/08-tidying-data.html#recap-of-ae",
    "title": "Types and Classes",
    "section": "Recap of AE",
    "text": "Recap of AE\n– logical: a logical value.\n– integer: an integer (positive or negative).\n– double: a real number stored in “double-precision floatint point format.”\n– character: a sequence of characters, called a “string” in other programming languages\nMore information can be found here: https://statsandr.com/blog/data-types-in-r/\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/09-data-import.html#checklist",
    "href": "slides/09-data-import.html#checklist",
    "title": "Data Import",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n\nOpen your ae-08 project in RStudio.\nLab-03 Due Tonight.\nExam 1 is coming (This week!)"
  },
  {
    "objectID": "slides/09-data-import.html#exam-study-tips",
    "href": "slides/09-data-import.html#exam-study-tips",
    "title": "Data Import",
    "section": "Exam Study Tips",
    "text": "Exam Study Tips\n– Take notes that you can reference\n– Go back through feedback\n– Revisit AEs\n– Review keys\n– Ask questions"
  },
  {
    "objectID": "slides/09-data-import.html#survey",
    "href": "slides/09-data-import.html#survey",
    "title": "Data Import",
    "section": "Survey",
    "text": "Survey\n– Review\n– Feedback"
  },
  {
    "objectID": "slides/09-data-import.html#regrades",
    "href": "slides/09-data-import.html#regrades",
    "title": "Data Import",
    "section": "Regrades",
    "text": "Regrades\n– What they are\nand are not…"
  },
  {
    "objectID": "slides/09-data-import.html#goals",
    "href": "slides/09-data-import.html#goals",
    "title": "Data Import",
    "section": "Goals",
    "text": "Goals\n– Understand how to export data files\n– Understand multiple ways to read in data\n– “New” functions: str_detect and fill\n– Review"
  },
  {
    "objectID": "slides/09-data-import.html#prep-questions",
    "href": "slides/09-data-import.html#prep-questions",
    "title": "Data Import",
    "section": "Prep Questions",
    "text": "Prep Questions\nSlido-Exam\nSlido-Reading"
  },
  {
    "objectID": "slides/09-data-import.html#warm-up",
    "href": "slides/09-data-import.html#warm-up",
    "title": "Data Import",
    "section": "Warm Up",
    "text": "Warm Up\nWhy should we bother with writing code to edit data rather than just editing the Excel file?\nWhat is the difference between read.csv and read_csv?"
  },
  {
    "objectID": "slides/09-data-import.html#read.csv-vs-read_csv",
    "href": "slides/09-data-import.html#read.csv-vs-read_csv",
    "title": "Data Import",
    "section": "read.csv vs read_csv",
    "text": "read.csv vs read_csv"
  },
  {
    "objectID": "slides/09-data-import.html#ae-08",
    "href": "slides/09-data-import.html#ae-08",
    "title": "Data Import",
    "section": "ae-08",
    "text": "ae-08\n– Go to the course GitHub org and find your ae-08 (repo name will be suffixed with your GitHub name).\n– Clone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\n– Render, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/09-data-import.html#recap-of-ae",
    "href": "slides/09-data-import.html#recap-of-ae",
    "title": "Data Import",
    "section": "Recap of AE",
    "text": "Recap of AE"
  },
  {
    "objectID": "slides/09-data-import.html#recap-of-ae-1",
    "href": "slides/09-data-import.html#recap-of-ae-1",
    "title": "Data Import",
    "section": "Recap of AE",
    "text": "Recap of AE\n– There are also special functions to work with dates and times! See preperation reading.\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/10-exam-review.html#checklist",
    "href": "slides/10-exam-review.html#checklist",
    "title": "Exam Review",
    "section": "Checklist",
    "text": "Checklist\n– Clone exam review repo\n– Prepare for exam 1"
  },
  {
    "objectID": "slides/10-exam-review.html#exam-logistics",
    "href": "slides/10-exam-review.html#exam-logistics",
    "title": "Exam Review",
    "section": "Exam Logistics",
    "text": "Exam Logistics\n– This is an individual exam (No Slack / No TAs / No Instructor)\n– Clarification questions are welcome. Debuging is not:\nWhat’s a tiny bit of help vs. what’s help to get unstuck\nThere would be no equivalent to this in an in person exam\nIf a student truly is stuck because of a reason not in their control, we wouldn’t penalize them anyway\n– Turn in via PDF. If you fail to do so, we will grade your latest commit and issue a penalty\n– Cite any code you obtain outside of the course materials\n– Look at what’s rendered!"
  },
  {
    "objectID": "slides/10-exam-review.html#office-hours",
    "href": "slides/10-exam-review.html#office-hours",
    "title": "Exam Review",
    "section": "Office Hours",
    "text": "Office Hours\n– Friday 10:00 - 11:00AM"
  },
  {
    "objectID": "slides/10-exam-review.html#goals",
    "href": "slides/10-exam-review.html#goals",
    "title": "Exam Review",
    "section": "Goals",
    "text": "Goals\n– Pivots\n– Joins\n– Relationship Discussion\n– Data wrangling with dplyr"
  },
  {
    "objectID": "slides/10-exam-review.html#warm-up",
    "href": "slides/10-exam-review.html#warm-up",
    "title": "Exam Review",
    "section": "Warm up",
    "text": "Warm up\nSuppose you and another researcher collected data on coffee separately. You collect the data on the left, and they collect the data on the right. Based on the question asked, identify the appropriate join function to join these two data together.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n– Add a column to your data set called special to indicate which months had speical drink offers.\n– Add a column to your data set called special to indicate which months had speical drink offers. Only include months in your data set that had specials."
  },
  {
    "objectID": "slides/10-exam-review.html#left_join",
    "href": "slides/10-exam-review.html#left_join",
    "title": "Exam Review",
    "section": "left_join",
    "text": "left_join"
  },
  {
    "objectID": "slides/10-exam-review.html#inner_join",
    "href": "slides/10-exam-review.html#inner_join",
    "title": "Exam Review",
    "section": "inner_join",
    "text": "inner_join"
  },
  {
    "objectID": "slides/10-exam-review.html#pivot-wider-and-longer",
    "href": "slides/10-exam-review.html#pivot-wider-and-longer",
    "title": "Exam Review",
    "section": "Pivot Wider and Longer",
    "text": "Pivot Wider and Longer\nWith a wide structure, each person (observational unit) has one observation (row) and a separate column contains data for each measurement. With a long structure, each person (observational unit) has multiple observations; one measurement per row."
  },
  {
    "objectID": "slides/10-exam-review.html#the-data",
    "href": "slides/10-exam-review.html#the-data",
    "title": "Exam Review",
    "section": "The data",
    "text": "The data"
  },
  {
    "objectID": "slides/10-exam-review.html#the-code",
    "href": "slides/10-exam-review.html#the-code",
    "title": "Exam Review",
    "section": "The code",
    "text": "The code\n\nbabies <- babies |>\npivot_longer(\ncols = -c(“id”, “sex”),\nnames_to = “months”,\nnames_prefix = “weight_”,\nvalues_to = “weight”\n)"
  },
  {
    "objectID": "slides/10-exam-review.html#the-code---answers",
    "href": "slides/10-exam-review.html#the-code---answers",
    "title": "Exam Review",
    "section": "The code - answers",
    "text": "The code - answers\n– The second argument to the pivot_longer() function is the cols argument. You should pass the name of the columns you want to make longer to the cols argument.\n– The third argument to the pivot_longer() function is the names_to argument. You should pass the names_to argument a character string or character vector that tells pivot_longer() what you want to name the column that will contain the previous column names that were pivoted.\n– The fourth argument to the pivot_longer() function is the names_prefix argument. You should pass the names_prefix argument a regular expression that tells pivot_longer() what to remove from the start of each of the previous column names that we pivoted.\n– The eighth argument (we left the 5th, 6th, and 7th arguments at their default values) to the pivot_longer() function is the values_to argument. You should pass the values_to argument a character string or character vector that tells pivot_longer() what you want to name the column that will contain the values from the columns that were pivoted."
  },
  {
    "objectID": "slides/10-exam-review.html#in-action",
    "href": "slides/10-exam-review.html#in-action",
    "title": "Exam Review",
    "section": "In action",
    "text": "In action\n{Long to Wide + Wide to Long}"
  },
  {
    "objectID": "slides/10-exam-review.html#long-data-to-wide",
    "href": "slides/10-exam-review.html#long-data-to-wide",
    "title": "Exam Review",
    "section": "long data to wide",
    "text": "long data to wide"
  },
  {
    "objectID": "slides/10-exam-review.html#pivot-wider",
    "href": "slides/10-exam-review.html#pivot-wider",
    "title": "Exam Review",
    "section": "pivot-wider",
    "text": "pivot-wider\nbabies <- babies_long |>\npivot_wider(\nnames_from = “months”,\nvalues_from = “weight)\n)"
  },
  {
    "objectID": "slides/10-exam-review.html#relationships",
    "href": "slides/10-exam-review.html#relationships",
    "title": "Exam Review",
    "section": "Relationships",
    "text": "Relationships\nHow we talk about graphs…."
  },
  {
    "objectID": "slides/10-exam-review.html#scatterplot",
    "href": "slides/10-exam-review.html#scatterplot",
    "title": "Exam Review",
    "section": "Scatterplot",
    "text": "Scatterplot"
  },
  {
    "objectID": "slides/10-exam-review.html#interactions",
    "href": "slides/10-exam-review.html#interactions",
    "title": "Exam Review",
    "section": "Interactions",
    "text": "Interactions"
  },
  {
    "objectID": "slides/10-exam-review.html#boxplot",
    "href": "slides/10-exam-review.html#boxplot",
    "title": "Exam Review",
    "section": "Boxplot",
    "text": "Boxplot"
  },
  {
    "objectID": "slides/10-exam-review.html#barplot",
    "href": "slides/10-exam-review.html#barplot",
    "title": "Exam Review",
    "section": "Barplot",
    "text": "Barplot\n\n\n\n\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/11-data-ethics.html#checklist",
    "href": "slides/11-data-ethics.html#checklist",
    "title": "Lecture 11 - Data Ethics",
    "section": "Checklist",
    "text": "Checklist\n– Clone exam data ethics\n– Breath a little! The exam is over :)"
  },
  {
    "objectID": "slides/11-data-ethics.html#announcements",
    "href": "slides/11-data-ethics.html#announcements",
    "title": "Lecture 11 - Data Ethics",
    "section": "Announcements",
    "text": "Announcements\n– Exams graded by Friday\n– Groups are coming"
  },
  {
    "objectID": "slides/11-data-ethics.html#goals",
    "href": "slides/11-data-ethics.html#goals",
    "title": "Lecture 11 - Data Ethics",
    "section": "Goals",
    "text": "Goals\n– Understand causality\n– Understand how to improve graphs\naxes\nscales\nuncertainty\n– Think about data\n– Be a skeptic\n– Practice in R"
  },
  {
    "objectID": "slides/11-data-ethics.html#section",
    "href": "slides/11-data-ethics.html#section",
    "title": "Lecture 11 - Data Ethics",
    "section": "",
    "text": "– What questions do you have?\n– What do you wonder?"
  },
  {
    "objectID": "slides/11-data-ethics.html#the-study",
    "href": "slides/11-data-ethics.html#the-study",
    "title": "Lecture 11 - Data Ethics",
    "section": "The Study",
    "text": "The Study\n– 5 men and 11 women showed up, aged 19 to 67.\n– Frank randomly assigned the subjects to one of three diet groups. One group followed a low-carbohydrate diet. Another followed the same low-carb diet plus a daily 1.5 oz. bar of dark chocolate. And the rest, a control group, were instructed to make no changes to their current diet.\n– They weighed themselves each morning for 21 days, and the study finished with a final round of questionnaires and blood tests."
  },
  {
    "objectID": "slides/11-data-ethics.html#the-great-chocolate-hoak",
    "href": "slides/11-data-ethics.html#the-great-chocolate-hoak",
    "title": "Lecture 11 - Data Ethics",
    "section": "The Great Chocolate Hoak",
    "text": "The Great Chocolate Hoak\n“If you measure a large number of things about a small number of people, you are almost guaranteed to get a”statistically significant” result. Our study included 18 different measurements—weight, cholesterol, sodium, blood protein levels, sleep quality, well-being, etc.—from 15 people. . . .”\n“It was, in fact, a fairly typical study for the field of diet research. Which is to say: It was terrible science. The results are meaningless, and the health claims that the media blasted out to millions of people around the world are utterly unfounded.”"
  },
  {
    "objectID": "slides/11-data-ethics.html#original-study",
    "href": "slides/11-data-ethics.html#original-study",
    "title": "Lecture 11 - Data Ethics",
    "section": "Original study",
    "text": "Original study\nMoore, Steven C., et al. “Association of leisure-time physical activity with risk of 26 types of cancer in 1.44 million adults.” JAMA internal medicine 176.6 (2016): 816-825.\n\nVolunteers were asked about their physical activity level over the preceding year.\nHalf exercised less than about 150 minutes per week, half exercised more.\nCompared to the bottom 10% of exercisers, the top 10% had lower rates of esophageal, liver, lung, endometrial, colon, and breast cancer.\nResearchers found no association between exercising and 13 other cancers (e.g. pancreatic, ovarian, and brain)."
  },
  {
    "objectID": "slides/11-data-ethics.html#the-takeaway",
    "href": "slides/11-data-ethics.html#the-takeaway",
    "title": "Lecture 11 - Data Ethics",
    "section": "The Takeaway",
    "text": "The Takeaway\n– Be a skeptic\n– Ask questions\n– Let the data tell the story, don’t tell the data for the story\n– Most studies should not claim causality"
  },
  {
    "objectID": "slides/11-data-ethics.html#section-3",
    "href": "slides/11-data-ethics.html#section-3",
    "title": "Lecture 11 - Data Ethics",
    "section": "",
    "text": "– What does this graph represent?\n– What are the story of these data?\n– Is the graph misleading?\n– How could you improve this graph?"
  },
  {
    "objectID": "slides/11-data-ethics.html#how-woul-you-fix-this-graph",
    "href": "slides/11-data-ethics.html#how-woul-you-fix-this-graph",
    "title": "Lecture 11 - Data Ethics",
    "section": "How woul you fix this graph?",
    "text": "How woul you fix this graph?"
  },
  {
    "objectID": "slides/11-data-ethics.html#whats-wrong-with-this-graph",
    "href": "slides/11-data-ethics.html#whats-wrong-with-this-graph",
    "title": "Lecture 11 - Data Ethics",
    "section": "What’s wrong with this graph?",
    "text": "What’s wrong with this graph?"
  },
  {
    "objectID": "slides/11-data-ethics.html#what-is-uncertainty",
    "href": "slides/11-data-ethics.html#what-is-uncertainty",
    "title": "Lecture 11 - Data Ethics",
    "section": "What is uncertainty?",
    "text": "What is uncertainty?\n– “How sure are you of your conclusions?”"
  },
  {
    "objectID": "slides/11-data-ethics.html#what-is-uncertainty-1",
    "href": "slides/11-data-ethics.html#what-is-uncertainty-1",
    "title": "Lecture 11 - Data Ethics",
    "section": "What is uncertainty?",
    "text": "What is uncertainty?\nThere are many reasons why a data analysis might still leave us in a position of uncertainty\n– We don’t have population data\n– Measurement error\n– Reporting error"
  },
  {
    "objectID": "slides/11-data-ethics.html#quick-example",
    "href": "slides/11-data-ethics.html#quick-example",
    "title": "Lecture 11 - Data Ethics",
    "section": "Quick Example",
    "text": "Quick Example\n\n\n\n\n\n\nFlip 1: Heads\nFlip 2: Heads\nFlip 3: Tails\nFlip 4: Heads"
  },
  {
    "objectID": "slides/11-data-ethics.html#section-7",
    "href": "slides/11-data-ethics.html#section-7",
    "title": "Lecture 11 - Data Ethics",
    "section": "",
    "text": "Suppose a researcher was interested in how diet impacted chicken weight? They assigned 5 chickens to 1 of 4 different diets. Here are the reported median weights of the 4 groups of chickens:\n– Diet 1: 160 grams\n– Diet 2: 225 grams\n– Diet 3: 280 grams\n– Diet 4: 245 grams\n\nSo Diet 4 causes heavier chickens? Other reasons?"
  },
  {
    "objectID": "slides/11-data-ethics.html#section-9",
    "href": "slides/11-data-ethics.html#section-9",
    "title": "Lecture 11 - Data Ethics",
    "section": "",
    "text": "So the answer is No! …. No?"
  },
  {
    "objectID": "slides/11-data-ethics.html#section-11",
    "href": "slides/11-data-ethics.html#section-11",
    "title": "Lecture 11 - Data Ethics",
    "section": "",
    "text": "The Art of Skepticism in a Data-Driven World\n\nby Carl Bergstrom and Jevin West"
  },
  {
    "objectID": "slides/11-data-ethics.html#section-12",
    "href": "slides/11-data-ethics.html#section-12",
    "title": "Lecture 11 - Data Ethics",
    "section": "",
    "text": "Getting Smarter about Visual Information\n\nby Alberto Cairo"
  },
  {
    "objectID": "slides/11-data-ethics.html#for-next-time-dont-do-this",
    "href": "slides/11-data-ethics.html#for-next-time-dont-do-this",
    "title": "Lecture 11 - Data Ethics",
    "section": "For Next Time: Don’t do this",
    "text": "For Next Time: Don’t do this\n“It looks like we can scrape student ID and email information. What type of project can we do with this?”\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/12-data-privacy.html#checklist",
    "href": "slides/12-data-privacy.html#checklist",
    "title": "Data Ethics 2",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-11-ethics-privacy"
  },
  {
    "objectID": "slides/12-data-privacy.html#announcements",
    "href": "slides/12-data-privacy.html#announcements",
    "title": "Data Ethics 2",
    "section": "Announcements",
    "text": "Announcements\nLab Group Instructions:\n– You can find your groups in the teams repo after class.\n– You may only switch groups under extreme circumstances (working with friends does not count)\n– View group number before Lab 04. This will make it easier for TAs to seat / group you."
  },
  {
    "objectID": "slides/12-data-privacy.html#goals",
    "href": "slides/12-data-privacy.html#goals",
    "title": "Data Ethics 2",
    "section": "Goals",
    "text": "Goals\n\nThink\nData Ethics\nData privacy\nBias"
  },
  {
    "objectID": "slides/12-data-privacy.html#section",
    "href": "slides/12-data-privacy.html#section",
    "title": "Data Ethics 2",
    "section": "",
    "text": "Every time we use apps, websites, and devices, our data is being collected and used or sold to others. More importantly, decisions are made by law enforcement, financial institutions, and governments based on data that directly affect the lives of people."
  },
  {
    "objectID": "slides/12-data-privacy.html#warm-up-what-are-you-okay-with",
    "href": "slides/12-data-privacy.html#warm-up-what-are-you-okay-with",
    "title": "Data Ethics 2",
    "section": "Warm up: What are you okay with?",
    "text": "Warm up: What are you okay with?\n\nName\nAge\nEmail\nPhone Number\nList of every video you watch\nList of every video you comment on\nHow you type: speed, accuracy\nHow long you spend on different content\nList of all your private messages (date, time, person sent to)\nInfo about your photos (how it was taken, where it was taken (GPS), when it was taken)\nBrowsing history"
  },
  {
    "objectID": "slides/12-data-privacy.html#ok-cupid-data-breach",
    "href": "slides/12-data-privacy.html#ok-cupid-data-breach",
    "title": "Data Ethics 2",
    "section": "OK Cupid data breach",
    "text": "OK Cupid data breach\n– In 2016, researchers published data of 70,000 OkCupid users—including usernames, political leanings, drug usage, and intimate sexual details\n– Researchers didn’t release the real names and pictures of OKCupid users, but their identities could easily be uncovered from the details provided, e.g. usernames\n\nSome may object to the ethics of gathering and releasing this data. However, all the data found in the dataset are or were already publicly available, so releasing this dataset merely presents it in a more useful form.\n\n\nResearchers Emil Kirkegaard and Julius Daugbjerg Bjerrekær"
  },
  {
    "objectID": "slides/12-data-privacy.html#question",
    "href": "slides/12-data-privacy.html#question",
    "title": "Data Ethics 2",
    "section": "Question",
    "text": "Question\nIn analysis of data that individuals willingly shared publicly on a given platform (e.g. social media), how do you make sure you don’t violate reasonable expectations of privacy?"
  },
  {
    "objectID": "slides/12-data-privacy.html#questions-for-you",
    "href": "slides/12-data-privacy.html#questions-for-you",
    "title": "Data Ethics 2",
    "section": "Questions for you",
    "text": "Questions for you\n\nShould you scrape these data?\nHow do you not violate reasonable expectations of privacy?"
  },
  {
    "objectID": "slides/12-data-privacy.html#intended-use",
    "href": "slides/12-data-privacy.html#intended-use",
    "title": "Data Ethics 2",
    "section": "Intended use",
    "text": "Intended use\n– Name\n– Age\n– Email\n– Phone Number\n– How long you spend on different content\n– List of all your private messages (date, time, person sent to)\n– Info about your photos (how it was taken, where it was taken (GPS), when it was taken)\n– Browsing history\n\nTargeted ads\nCandidate for a job (Amazon has done this)\nPredict your race to map votes (This is being done)"
  },
  {
    "objectID": "slides/12-data-privacy.html#gettysburg-activity-representative-words-of-word-length",
    "href": "slides/12-data-privacy.html#gettysburg-activity-representative-words-of-word-length",
    "title": "Data Ethics 2",
    "section": "Gettysburg Activity: Representative words of word length",
    "text": "Gettysburg Activity: Representative words of word length\n\n\n\n\n\n\n\n−+\n00:30"
  },
  {
    "objectID": "slides/12-data-privacy.html#question-of-interest",
    "href": "slides/12-data-privacy.html#question-of-interest",
    "title": "Data Ethics 2",
    "section": "Question of Interest",
    "text": "Question of Interest\nWhat is the typical word length in the Gettysburg Address?\n– Using R, calculate the mean word length of your 10 words."
  },
  {
    "objectID": "slides/12-data-privacy.html#population-word-length",
    "href": "slides/12-data-privacy.html#population-word-length",
    "title": "Data Ethics 2",
    "section": "Population Word Length",
    "text": "Population Word Length\nWrite down the population mean word length\nWrite down the mean of your 10 words\nWere you close? How about the rest of the class?\nAre humans bias? How does this activity relate to bias in algorithms?"
  },
  {
    "objectID": "slides/12-data-privacy.html#bias",
    "href": "slides/12-data-privacy.html#bias",
    "title": "Data Ethics 2",
    "section": "Bias",
    "text": "Bias\nBias is a disproportionate weight in favor of or against an idea or thing\n\nWe all have bias\nBias can be a part of science and research"
  },
  {
    "objectID": "slides/12-data-privacy.html#facial-recognition",
    "href": "slides/12-data-privacy.html#facial-recognition",
    "title": "Data Ethics 2",
    "section": "Facial Recognition",
    "text": "Facial Recognition"
  },
  {
    "objectID": "slides/12-data-privacy.html#parting-thoughts",
    "href": "slides/12-data-privacy.html#parting-thoughts",
    "title": "Data Ethics 2",
    "section": "Parting Thoughts",
    "text": "Parting Thoughts\n\nAsk questions\nSlow down\nThink critically\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/13-web-scraping.html#while-you-wait-for-class-to-begin",
    "href": "slides/13-web-scraping.html#while-you-wait-for-class-to-begin",
    "title": "Web scraping",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\n\n\nIf you haven’t yet done so: Install a Chrome browser and the SelectorGadget extension:\n\nChrome\nSelectorGadget\n\nClone your ae-12 project from GitHub, render your document, update your name, and commit and push."
  },
  {
    "objectID": "slides/13-web-scraping.html#announcements",
    "href": "slides/13-web-scraping.html#announcements",
    "title": "Web scraping",
    "section": "Announcements",
    "text": "Announcements\n\nIf you missed lab last week, make sure to get in touch with your team before tomorrow’s lab\nLab is due 11:59 on Thursday – only one submission per team, whoever submits it for the team must tag all teammates\nHW 3 is due at 11:59 on Friday"
  },
  {
    "objectID": "slides/13-web-scraping.html#scraping-the-web-what-why",
    "href": "slides/13-web-scraping.html#scraping-the-web-what-why",
    "title": "Web scraping",
    "section": "Scraping the web: what? why?",
    "text": "Scraping the web: what? why?\n\nIncreasing amount of data is available on the web\nThese data are provided in an unstructured format: you can always copy&paste, but it’s time-consuming and prone to errors\nWeb scraping is the process of extracting this information automatically and transform it into a structured dataset\nTwo different scenarios:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy).\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files."
  },
  {
    "objectID": "slides/13-web-scraping.html#hypertext-markup-language",
    "href": "slides/13-web-scraping.html#hypertext-markup-language",
    "title": "Web scraping",
    "section": "Hypertext Markup Language",
    "text": "Hypertext Markup Language\n\nMost of the data on the web is still largely available as HTML\nIt is structured (hierarchical / tree based), but it’s often not available in a form useful for analysis (flat / tidy).\n\n<html>\n  <head>\n    <title>This is a title</title>\n  </head>\n  <body>\n    <p align=\"center\">Hello world!</p>\n  </body>\n</html>"
  },
  {
    "objectID": "slides/13-web-scraping.html#rvest",
    "href": "slides/13-web-scraping.html#rvest",
    "title": "Web scraping",
    "section": "rvest",
    "text": "rvest\n\n\n\nThe rvest package makes basic processing and manipulation of HTML data straight forward\nIt’s designed to work with pipelines built with |>\nrvest.tidyverse.org"
  },
  {
    "objectID": "slides/13-web-scraping.html#core-rvest-functions",
    "href": "slides/13-web-scraping.html#core-rvest-functions",
    "title": "Web scraping",
    "section": "Core rvest functions",
    "text": "Core rvest functions\n\nread_html() - Read HTML data from a url or character string (actually from the xml2 package, but most often used along with other rvest functions)\nhtml_element() / html_elements() - Select a specified element(s) from HTML document\nhtml_table() - Parse an HTML table into a data frame\nhtml_text() - Extract text from an element\nhtml_text2() - Extract text from an element and lightly format it to match how text looks in the browser\nhtml_name() - Extract elements’ names\nhtml_attr() / html_attrs() - Extract a single attribute or all attributes"
  },
  {
    "objectID": "slides/13-web-scraping.html#opinion-articles-in-the-chronicle",
    "href": "slides/13-web-scraping.html#opinion-articles-in-the-chronicle",
    "title": "Web scraping",
    "section": "Opinion articles in The Chronicle",
    "text": "Opinion articles in The Chronicle\n\nGo to https://www.dukechronicle.com/section/opinion\nScroll to the bottom and choose page 1\n\n\n\n\nHow many articles are on the page?\nTake a look at the URL. How can you change the number of articles displayed by modifying the URL? Try displaying 100 articles."
  },
  {
    "objectID": "slides/13-web-scraping.html#ae-12",
    "href": "slides/13-web-scraping.html#ae-12",
    "title": "Web scraping",
    "section": "ae-12",
    "text": "ae-12\n\n\n\nGo to the course GitHub org and find your ae-12 (repo name will be suffixed with your GitHub name).\nClone the repo in your container, open the Quarto document in the repo, and follow along and complete the exercises.\nRender, commit, and push your edits by the AE deadline – 3 days from today."
  },
  {
    "objectID": "slides/13-web-scraping.html#recap",
    "href": "slides/13-web-scraping.html#recap",
    "title": "Web scraping",
    "section": "Recap",
    "text": "Recap\n\nUse the SelectorGadget identify tags for elements you want to grab\nUse rvest to first read the whole page (into R) and then parse the object you’ve read in to the elements you’re interested in\nPut the components together in a data frame (a tibble) and analyze it like you analyze any other data"
  },
  {
    "objectID": "slides/13-web-scraping.html#a-new-r-workflow",
    "href": "slides/13-web-scraping.html#a-new-r-workflow",
    "title": "Web scraping",
    "section": "A new R workflow",
    "text": "A new R workflow\n\nWhen working in a Quarto document, your analysis is re-run each time you knit\nIf web scraping in a Quarto document, you’d be re-scraping the data each time you knit, which is undesirable (and not nice)!\nAn alternative workflow:\n\nUse an R script to save your code\nSaving interim data scraped using the code in the script as CSV or RDS files\nUse the saved data in your analysis in your Quarto document"
  },
  {
    "objectID": "slides/13-web-scraping.html#ethics-can-you-vs-should-you",
    "href": "slides/13-web-scraping.html#ethics-can-you-vs-should-you",
    "title": "Web scraping",
    "section": "Ethics: “Can you?” vs “Should you?”",
    "text": "Ethics: “Can you?” vs “Should you?”\n\n\n\n\n\n\n\nSource: Brian Resnick, Researchers just released profile data on 70,000 OkCupid users without permission, Vox."
  },
  {
    "objectID": "slides/13-web-scraping.html#can-you-vs-should-you",
    "href": "slides/13-web-scraping.html#can-you-vs-should-you",
    "title": "Web scraping",
    "section": "“Can you?” vs “Should you?”",
    "text": "“Can you?” vs “Should you?”"
  },
  {
    "objectID": "slides/13-web-scraping.html#challenges-unreliable-formatting",
    "href": "slides/13-web-scraping.html#challenges-unreliable-formatting",
    "title": "Web scraping",
    "section": "Challenges: Unreliable formatting",
    "text": "Challenges: Unreliable formatting\n\n\n\n\n\n\n\nalumni.duke.edu/news/notable-alumni"
  },
  {
    "objectID": "slides/13-web-scraping.html#challenges-data-broken-into-many-pages",
    "href": "slides/13-web-scraping.html#challenges-data-broken-into-many-pages",
    "title": "Web scraping",
    "section": "Challenges: Data broken into many pages",
    "text": "Challenges: Data broken into many pages"
  },
  {
    "objectID": "slides/13-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "href": "slides/13-web-scraping.html#workflow-screen-scraping-vs.-apis",
    "title": "Web scraping",
    "section": "Workflow: Screen scraping vs. APIs",
    "text": "Workflow: Screen scraping vs. APIs\nTwo different scenarios for web scraping:\n\nScreen scraping: extract data from source code of website, with html parser (easy) or regular expression matching (less easy)\nWeb APIs (application programming interface): website offers a set of structured http requests that return JSON or XML files\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/14-functions-iteration.html#checklist",
    "href": "slides/14-functions-iteration.html#checklist",
    "title": "Functions + Iteration",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-13"
  },
  {
    "objectID": "slides/14-functions-iteration.html#announcements",
    "href": "slides/14-functions-iteration.html#announcements",
    "title": "Functions + Iteration",
    "section": "Announcements",
    "text": "Announcements\n– No Homework this week\n– Project Proposal Due Thursday"
  },
  {
    "objectID": "slides/14-functions-iteration.html#reminder",
    "href": "slides/14-functions-iteration.html#reminder",
    "title": "Functions + Iteration",
    "section": "Reminder",
    "text": "Reminder\n– Merge conflicts can be avoided if you pull before making changes\n– Refer to previous lab for steps on how to fix “simple” merge conflicts\n– If conflicts continue to pile up….. save locally and “restart”"
  },
  {
    "objectID": "slides/14-functions-iteration.html#goals",
    "href": "slides/14-functions-iteration.html#goals",
    "title": "Functions + Iteration",
    "section": "Goals",
    "text": "Goals\n– Review R (Finish ae-12)\n– What is a function?\n– How can we write them?\n– Why should we write them?\n– Review web scraping"
  },
  {
    "objectID": "slides/14-functions-iteration.html#warm-up---temperature-function",
    "href": "slides/14-functions-iteration.html#warm-up---temperature-function",
    "title": "Functions + Iteration",
    "section": "Warm up - Temperature Function",
    "text": "Warm up - Temperature Function\nTo convert temperatures in degrees Fahrenheit to Celsius, subtract 32 and multiply by .5556 (or 5/9).\nWrite a function in R that can take an input of a Fahrenheit temperature and output a temperature in Celsius."
  },
  {
    "objectID": "slides/14-functions-iteration.html#why-we-need-functions",
    "href": "slides/14-functions-iteration.html#why-we-need-functions",
    "title": "Functions + Iteration",
    "section": "Why we need functions?",
    "text": "Why we need functions?"
  },
  {
    "objectID": "slides/14-functions-iteration.html#iteration",
    "href": "slides/14-functions-iteration.html#iteration",
    "title": "Functions + Iteration",
    "section": "Iteration",
    "text": "Iteration\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/15-models.html#checklist",
    "href": "slides/15-models.html#checklist",
    "title": "Models",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-14"
  },
  {
    "objectID": "slides/15-models.html#announcements",
    "href": "slides/15-models.html#announcements",
    "title": "Models",
    "section": "Announcements",
    "text": "Announcements\n– Project Proposal Due Thursday"
  },
  {
    "objectID": "slides/15-models.html#goals",
    "href": "slides/15-models.html#goals",
    "title": "Models",
    "section": "Goals",
    "text": "Goals\n– Introduce the idea of modeling\n– Why we model?\n– What a model is?\n– Correlation\n– Introduction to probability (maybe)"
  },
  {
    "objectID": "slides/15-models.html#warm-up",
    "href": "slides/15-models.html#warm-up",
    "title": "Models",
    "section": "Warm up",
    "text": "Warm up\n\n– What is the relationship?\n– What is your best guess for a car’s MPG that weighs 5000 pounds?"
  },
  {
    "objectID": "slides/15-models.html#what-is-a-statistical-model",
    "href": "slides/15-models.html#what-is-a-statistical-model",
    "title": "Models",
    "section": "What is a statistical model?",
    "text": "What is a statistical model?\n– Statistical modeling is the process of applying statistical analysis to a data set.\n– A statistical model is a mathematical representation of observed data."
  },
  {
    "objectID": "slides/15-models.html#vocab---response-variable",
    "href": "slides/15-models.html#vocab---response-variable",
    "title": "Models",
    "section": "Vocab - Response variable",
    "text": "Vocab - Response variable"
  },
  {
    "objectID": "slides/15-models.html#vocab---explanatory-variable",
    "href": "slides/15-models.html#vocab---explanatory-variable",
    "title": "Models",
    "section": "Vocab - Explanatory variable",
    "text": "Vocab - Explanatory variable"
  },
  {
    "objectID": "slides/15-models.html#probability-1",
    "href": "slides/15-models.html#probability-1",
    "title": "Models",
    "section": "Probability",
    "text": "Probability\n\nA random process is one in which the outcome is unpredictable. We encounter random processes every day: will it rain today? how many minutes will pass until receiving your next text message? will the Packers win the Super Bowl?\nThe probability of an event is the long-run proportion of times the event would occur if the random process were repeated indefinitely (under identical conditions)."
  },
  {
    "objectID": "slides/15-models.html#types-of-probabilities",
    "href": "slides/15-models.html#types-of-probabilities",
    "title": "Models",
    "section": "Types of Probabilities",
    "text": "Types of Probabilities\n– Single Event\n– Conditional\n– And"
  },
  {
    "objectID": "slides/15-models.html#notation",
    "href": "slides/15-models.html#notation",
    "title": "Models",
    "section": "Notation",
    "text": "Notation\nWe will denote “events” by upper case letters near the beginning of the alphabet\n– P(A)\n– P(A|B)\n– P(A U B)"
  },
  {
    "objectID": "slides/15-models.html#examples",
    "href": "slides/15-models.html#examples",
    "title": "Models",
    "section": "Examples",
    "text": "Examples\nWe often calculate probabilities using a table. Consider the following example:\n\n\n\n\nCured\nNot-Cured\nTotals\n\n\nNew Drug\n145\n250\n395\n\n\nStandard Drug\n300\n305\n605\n\n\n\n445\n555\n1,000\n\n\n\n\nWhat is the probability of \\(A\\)?\nWhat is the probability of \\(B^c\\)\nWhat is the probability of \\(B\\) and \\(A\\)?\nWhat is the probability of \\(B\\) given \\(A\\)?"
  },
  {
    "objectID": "slides/15-models.html#example",
    "href": "slides/15-models.html#example",
    "title": "Models",
    "section": "Example",
    "text": "Example\nAs a student at Duke University, suppose your first class on Mondays is in Old Chemistry at 8:00am and you commute to school. From past experience, you know that there is a 20% chance of finding an open parking spot in Lot 6. Otherwise, you have to park in Lot 18. If you find a spot in Lot 6, you only have a 5% chance of being late to class. However, if you have to park in Lot 18, you have a 15% chance of being late to class."
  },
  {
    "objectID": "slides/15-models.html#step-1",
    "href": "slides/15-models.html#step-1",
    "title": "Models",
    "section": "Step 1",
    "text": "Step 1\n“you know that there is a 20% chance of finding an open parking spot in Lot 6.”"
  },
  {
    "objectID": "slides/15-models.html#step-2",
    "href": "slides/15-models.html#step-2",
    "title": "Models",
    "section": "Step 2",
    "text": "Step 2\n“if you park in Lot 6, the probability of being late to class is 5%; if you park in Log 18, the probability of being late to class is 15%."
  },
  {
    "objectID": "slides/15-models.html#step-3",
    "href": "slides/15-models.html#step-3",
    "title": "Models",
    "section": "Step 3",
    "text": "Step 3\n\n\n\n\nLate to class\nNot late to class\nTotals\n\n\n\n\nLot 6\n10\n190\n200\n\n\nLot 18\n120\n680\n800\n\n\n\n130\n870\n1,000\n\n\n\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/16-single-pred.html#checklist",
    "href": "slides/16-single-pred.html#checklist",
    "title": "Models",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-15"
  },
  {
    "objectID": "slides/16-single-pred.html#announcements",
    "href": "slides/16-single-pred.html#announcements",
    "title": "Models",
    "section": "Announcements",
    "text": "Announcements\n– Lab Feedback"
  },
  {
    "objectID": "slides/16-single-pred.html#goals",
    "href": "slides/16-single-pred.html#goals",
    "title": "Models",
    "section": "Goals",
    "text": "Goals\n– Modeling with single predictors\n– How to write equations\n– Interpret Slopes\n– Interpret Intercepts"
  },
  {
    "objectID": "slides/16-single-pred.html#warm-up---correlation-vs-causation",
    "href": "slides/16-single-pred.html#warm-up---correlation-vs-causation",
    "title": "Models",
    "section": "Warm Up - Correlation vs Causation",
    "text": "Warm Up - Correlation vs Causation"
  },
  {
    "objectID": "slides/16-single-pred.html#review---why-we-model",
    "href": "slides/16-single-pred.html#review---why-we-model",
    "title": "Models",
    "section": "Review - Why we Model?",
    "text": "Review - Why we Model?"
  },
  {
    "objectID": "slides/16-single-pred.html#review---why-we-model-1",
    "href": "slides/16-single-pred.html#review---why-we-model-1",
    "title": "Models",
    "section": "Review - Why we Model?",
    "text": "Review - Why we Model?\n– Prediction\n– Mathematical Model of Relationships"
  },
  {
    "objectID": "slides/16-single-pred.html#review---how-are-models-fit",
    "href": "slides/16-single-pred.html#review---how-are-models-fit",
    "title": "Models",
    "section": "Review - How are Models Fit?",
    "text": "Review - How are Models Fit?"
  },
  {
    "objectID": "slides/16-single-pred.html#review---how-are-models-fit-1",
    "href": "slides/16-single-pred.html#review---how-are-models-fit-1",
    "title": "Models",
    "section": "Review - How are Models Fit?",
    "text": "Review - How are Models Fit?"
  },
  {
    "objectID": "slides/16-single-pred.html#review---how-are-models-fit-2",
    "href": "slides/16-single-pred.html#review---how-are-models-fit-2",
    "title": "Models",
    "section": "Review - How are Models Fit?",
    "text": "Review - How are Models Fit?\n\n\nWhat about in the categorical case?"
  },
  {
    "objectID": "slides/16-single-pred.html#how-we-model---linear-case",
    "href": "slides/16-single-pred.html#how-we-model---linear-case",
    "title": "Models",
    "section": "How we model - linear case",
    "text": "How we model - linear case\nlinear_reg() |>\nset_engine(“lm”) |>\nfit(y ~ x , data = data-set ) |>\n\ntidy()"
  },
  {
    "objectID": "slides/16-single-pred.html#in-summary",
    "href": "slides/16-single-pred.html#in-summary",
    "title": "Models",
    "section": "In Summary",
    "text": "In Summary\n– “For a 1 unit increase in x….”\n– On Average: Property of least squares regression- Line goes through the mean of x and y\n– Practice writing out equations: Population and Sample level\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/17-multiple-pred.html#checklist",
    "href": "slides/17-multiple-pred.html#checklist",
    "title": "Multiple Predictors",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-16\n– Review context of ae-15 for warm up question"
  },
  {
    "objectID": "slides/17-multiple-pred.html#announcements",
    "href": "slides/17-multiple-pred.html#announcements",
    "title": "Multiple Predictors",
    "section": "Announcements",
    "text": "Announcements\n– Lab Feedback\n– Project Repos Coming"
  },
  {
    "objectID": "slides/17-multiple-pred.html#goals",
    "href": "slides/17-multiple-pred.html#goals",
    "title": "Multiple Predictors",
    "section": "Goals",
    "text": "Goals\n– Finish categorical single predictor\n– Model with multiple predictors\n– Adjusted R-squared"
  },
  {
    "objectID": "slides/17-multiple-pred.html#warm-up",
    "href": "slides/17-multiple-pred.html#warm-up",
    "title": "Multiple Predictors",
    "section": "Warm Up",
    "text": "Warm Up\nRecall that we ended last class by modeling the relationship between a penguin’s body mass and the insland they were recorded on. Using the following output, write the estimated model below:"
  },
  {
    "objectID": "slides/17-multiple-pred.html#further",
    "href": "slides/17-multiple-pred.html#further",
    "title": "Multiple Predictors",
    "section": "Further",
    "text": "Further\n– What if we want to account for both their flipper length and island?\n– Would a different model explain more variation in the response body mass?"
  },
  {
    "objectID": "slides/17-multiple-pred.html#modeling-more-than-one-variable",
    "href": "slides/17-multiple-pred.html#modeling-more-than-one-variable",
    "title": "Multiple Predictors",
    "section": "Modeling More Than one Variable",
    "text": "Modeling More Than one Variable\n– Multiple linear regression is used to estimate the relationship between two or more explanatory variables and one response variable.\n– we want to predict the value of a variable based on the value of two or more other variables\n– “account for X1 and assess the relationship between X2 and Y” - main effects\n– “does X1’s relationship with Y change based on X2”"
  },
  {
    "objectID": "slides/17-multiple-pred.html#in-summary",
    "href": "slides/17-multiple-pred.html#in-summary",
    "title": "Multiple Predictors",
    "section": "In Summary",
    "text": "In Summary\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/18-mlr.2.html#checklist",
    "href": "slides/18-mlr.2.html#checklist",
    "title": "Multiple Predictors",
    "section": "Checklist",
    "text": "Checklist\n– Clone ae-17\n– If you do not have ae-17 go here: https://github.com/sta199-f22-2/ae-17"
  },
  {
    "objectID": "slides/18-mlr.2.html#announcements",
    "href": "slides/18-mlr.2.html#announcements",
    "title": "Multiple Predictors",
    "section": "Announcements",
    "text": "Announcements\n– Lab Feedback (Check it regardless of your grade)\n– HW4 Question 2"
  },
  {
    "objectID": "slides/18-mlr.2.html#goals",
    "href": "slides/18-mlr.2.html#goals",
    "title": "Multiple Predictors",
    "section": "Goals",
    "text": "Goals\n– Overfitting\n– “New” function in R\nSummary on Regression\n– Why we model data?\n– Can I write out models?\n– Can I interpret model output?\n– Do I understand the difference between models?"
  },
  {
    "objectID": "slides/18-mlr.2.html#warm-up",
    "href": "slides/18-mlr.2.html#warm-up",
    "title": "Multiple Predictors",
    "section": "Warm Up",
    "text": "Warm Up\nDiscuss the difference between the two models below. Which model would you prefer to fit to model these data? Why?"
  },
  {
    "objectID": "slides/18-mlr.2.html#overfitting",
    "href": "slides/18-mlr.2.html#overfitting",
    "title": "Multiple Predictors",
    "section": "Overfitting",
    "text": "Overfitting\n– Overfitting is a concept in data science, which occurs when a statistical model fits exactly against its data.\n– This doesn’t make sense if are goal is to predict!"
  },
  {
    "objectID": "slides/18-mlr.2.html#why-we-use-regression",
    "href": "slides/18-mlr.2.html#why-we-use-regression",
    "title": "Multiple Predictors",
    "section": "Why we use regression",
    "text": "Why we use regression\n\nPredict the value of our response\nEstimate the effect of some explanatory variable on the response (examine the relationship)\nMake inference about some larger population (coming later)"
  },
  {
    "objectID": "slides/18-mlr.2.html#when-and-why-we-use-regression",
    "href": "slides/18-mlr.2.html#when-and-why-we-use-regression",
    "title": "Multiple Predictors",
    "section": "When and why we use regression",
    "text": "When and why we use regression\n\nQuantitative Response\nDoes it make sense"
  },
  {
    "objectID": "slides/18-mlr.2.html#extension-coming-later",
    "href": "slides/18-mlr.2.html#extension-coming-later",
    "title": "Multiple Predictors",
    "section": "Extension (Coming Later)",
    "text": "Extension (Coming Later)\nTo test hypotheses and make conclusions, certain assumptions need to be met….\n– Normality of Residuals\n– Linearity\n– Independence\n– Constant Variance"
  },
  {
    "objectID": "slides/18-mlr.2.html#adjusted-r-squared",
    "href": "slides/18-mlr.2.html#adjusted-r-squared",
    "title": "Multiple Predictors",
    "section": "Adjusted R-squared",
    "text": "Adjusted R-squared"
  },
  {
    "objectID": "slides/18-mlr.2.html#modeling-more-than-one-variable",
    "href": "slides/18-mlr.2.html#modeling-more-than-one-variable",
    "title": "Multiple Predictors",
    "section": "Modeling More Than One Variable",
    "text": "Modeling More Than One Variable\n– Multiple linear regression is used to estimate the relationship between two or more explanatory variables and one response variable.\n– we want to predict the value of a variable based on the value of two or more other variables\n– “account for X1 and assess the relationship between X2 and Y” - main effects\n– “does X1’s relationship with Y change based on X2”"
  },
  {
    "objectID": "slides/18-mlr.2.html#logistic-regression",
    "href": "slides/18-mlr.2.html#logistic-regression",
    "title": "Multiple Predictors",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n– What if the response variable is categorical?\n\n\n\n🔗 sta199-f22-2.github.io"
  },
  {
    "objectID": "slides/LabSurveySlide.html#while-you-wait-for-class-to-begin",
    "href": "slides/LabSurveySlide.html#while-you-wait-for-class-to-begin",
    "title": "Lab Extra Credit Survey",
    "section": "While you wait for class to begin…",
    "text": "While you wait for class to begin…\nStudy Participation + exam extra credit opportunity:\n– Options: But the researchers would appreciate your participation!\n– Go here or at bit.ly/sta199-learning-study-1 to fill out the survey.\n– I will not see your responses.\n–I will get a list of who filled out the survey from Duke Learning Innovations and use that to award +4 points of extra credit for Exam 1.\n\n\n\n🔗 sta199-f22-2.github.io"
  }
]